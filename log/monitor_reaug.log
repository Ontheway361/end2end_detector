----------------Environment Versions----------------
- Python    : 3.7.3 
- PyTorch   : 1.1.0
- TorchVison: 0.3.0
- GPU_device: True
----------------------------------------------------
Parallel mode was going ...
Model loading was finished ...
After data augmentation, 72773 rows added.
After data augmentation,   0 rows added.
Data loading was finished ...
epoch :  1|30, iter : 200|1138,  loss : 1.0242
epoch :  1|30, iter : 400|1138,  loss : 0.7538
epoch :  1|30, iter : 600|1138,  loss : 0.6161
epoch :  1|30, iter : 800|1138,  loss : 0.5273
epoch :  1|30, iter : 1000|1138,  loss : 0.4686
acc : 0.8072, precision : 0.4451, recall : 0.4580, f1_score : 0.4515
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8362    0.7562    0.7942     45524
           1     0.8936    0.9326    0.9127    100022

    accuracy                         0.8774    145546
   macro avg     0.8649    0.8444    0.8534    145546
weighted avg     0.8757    0.8774    0.8756    145546

[[34423 11101]
 [ 6743 93279]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9740    0.9676    0.9708     36457
           1     0.9685    0.9713    0.9699     36316
           2     0.9701    0.9696    0.9698     36457
           3     0.9674    0.9714    0.9694     36316

    accuracy                         0.9700    145546
   macro avg     0.9700    0.9700    0.9700    145546
weighted avg     0.9700    0.9700    0.9700    145546

[[35277   297   511   372]
 [  248 35274   303   491]
 [  431   351 35348   327]
 [  264   499   275 35278]]
-------------------------------------------------------------------------------------
train_loss : 0.4373
eval_loss : 0.3651
acc : 0.9850, precision : 0.9542, recall : 0.9577, f1_score : 0.9560
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.7871    0.9560    0.8634      9674
           1     0.9781    0.8838    0.9285     21515

    accuracy                         0.9062     31189
   macro avg     0.8826    0.9199    0.8960     31189
weighted avg     0.9189    0.9062    0.9083     31189

[[ 9248   426]
 [ 2501 19014]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9852    0.9938    0.9895      7745
           1     0.9864    0.9608    0.9735      7789
           2     0.9980    0.9704    0.9840      7869
           3     0.9538    0.9969    0.9749      7786

    accuracy                         0.9804     31189
   macro avg     0.9809    0.9805    0.9805     31189
weighted avg     0.9809    0.9804    0.9805     31189

[[7697   30    6   12]
 [  25 7484    7  273]
 [  84   58 7636   91]
 [   7   15    2 7762]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.33 mins
**************** | sota | loss : 0.3651 | f1_score : 0.9560 | ****************
epoch :  2|30, iter : 200|1138,  loss : 0.2070
epoch :  2|30, iter : 400|1138,  loss : 0.2001
epoch :  2|30, iter : 600|1138,  loss : 0.1946
epoch :  2|30, iter : 800|1138,  loss : 0.1920
epoch :  2|30, iter : 1000|1138,  loss : 0.1888
acc : 0.8215, precision : 0.4845, recall : 0.4826, f1_score : 0.4836
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9275    0.9271    0.9273     45524
           1     0.9668    0.9670    0.9669    100022

    accuracy                         0.9545    145546
   macro avg     0.9472    0.9470    0.9471    145546
weighted avg     0.9545    0.9545    0.9545    145546

[[42204  3320]
 [ 3299 96723]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9931    0.9937    0.9934     36457
           1     0.9942    0.9939    0.9941     36316
           2     0.9933    0.9940    0.9936     36457
           3     0.9946    0.9937    0.9941     36316

    accuracy                         0.9938    145546
   macro avg     0.9938    0.9938    0.9938    145546
weighted avg     0.9938    0.9938    0.9938    145546

[[36227    50   130    50]
 [   56 36094    66   100]
 [  134    39 36237    47]
 [   60   120    49 36087]]
-------------------------------------------------------------------------------------
train_loss : 0.1889
eval_loss : 0.2128
acc : 0.9879, precision : 0.9841, recall : 0.9445, f1_score : 0.9639
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9312    0.9407    0.9359      9674
           1     0.9732    0.9688    0.9710     21515

    accuracy                         0.9601     31189
   macro avg     0.9522    0.9547    0.9535     31189
weighted avg     0.9602    0.9601    0.9601     31189

[[ 9100   574]
 [  672 20843]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9964    0.9919    0.9941      7745
           1     0.9983    0.9868    0.9925      7789
           2     0.9494    0.9970    0.9726      7869
           3     0.9968    0.9624    0.9793      7786

    accuracy                         0.9845     31189
   macro avg     0.9852    0.9845    0.9846     31189
weighted avg     0.9851    0.9845    0.9846     31189

[[7682    5   53    5]
 [   6 7686   81   16]
 [  18    3 7845    3]
 [   4    5  284 7493]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.21 mins
**************** | sota | loss : 0.2128 | f1_score : 0.9639 | ****************
epoch :  3|30, iter : 200|1138,  loss : 0.1703
epoch :  3|30, iter : 400|1138,  loss : 0.1728
epoch :  3|30, iter : 600|1138,  loss : 0.1711
epoch :  3|30, iter : 800|1138,  loss : 0.1686
epoch :  3|30, iter : 1000|1138,  loss : 0.1676
acc : 0.8225, precision : 0.4876, recall : 0.4866, f1_score : 0.4871
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9343    0.9366    0.9355     45524
           1     0.9711    0.9700    0.9706    100022

    accuracy                         0.9596    145546
   macro avg     0.9527    0.9533    0.9530    145546
weighted avg     0.9596    0.9596    0.9596    145546

[[42636  2888]
 [ 2996 97026]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9940    0.9953    0.9946     36457
           1     0.9957    0.9953    0.9955     36316
           2     0.9948    0.9945    0.9947     36457
           3     0.9953    0.9947    0.9950     36316

    accuracy                         0.9950    145546
   macro avg     0.9950    0.9950    0.9950    145546
weighted avg     0.9950    0.9950    0.9950    145546

[[36285    32    97    43]
 [   49 36147    40    80]
 [  122    33 36256    46]
 [   48    91    52 36125]]
-------------------------------------------------------------------------------------
train_loss : 0.1684
eval_loss : 0.2606
acc : 0.9865, precision : 0.9576, recall : 0.9637, f1_score : 0.9606
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8414    0.9639    0.8985      9674
           1     0.9826    0.9183    0.9494     21515

    accuracy                         0.9324     31189
   macro avg     0.9120    0.9411    0.9239     31189
weighted avg     0.9388    0.9324    0.9336     31189

[[ 9325   349]
 [ 1758 19757]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9893    0.9901    0.9897      7745
           1     0.9838    0.9990    0.9913      7789
           2     0.9987    0.9861    0.9924      7869
           3     0.9959    0.9924    0.9941      7786

    accuracy                         0.9919     31189
   macro avg     0.9919    0.9919    0.9919     31189
weighted avg     0.9919    0.9919    0.9919     31189

[[7668   60    3   14]
 [   2 7781    5    1]
 [  79   13 7760   17]
 [   2   55    2 7727]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.61 mins
epoch :  4|30, iter : 200|1138,  loss : 0.1634
epoch :  4|30, iter : 400|1138,  loss : 0.1628
epoch :  4|30, iter : 600|1138,  loss : 0.1613
epoch :  4|30, iter : 800|1138,  loss : 0.1639
epoch :  4|30, iter : 1000|1138,  loss : 0.1621
acc : 0.8221, precision : 0.4865, recall : 0.4848, f1_score : 0.4857
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9381    0.9379    0.9380     45524
           1     0.9717    0.9718    0.9718    100022

    accuracy                         0.9612    145546
   macro avg     0.9549    0.9549    0.9549    145546
weighted avg     0.9612    0.9612    0.9612    145546

[[42696  2828]
 [ 2818 97204]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9948    0.9951    0.9950     36457
           1     0.9959    0.9958    0.9959     36316
           2     0.9953    0.9950    0.9951     36457
           3     0.9956    0.9956    0.9956     36316

    accuracy                         0.9954    145546
   macro avg     0.9954    0.9954    0.9954    145546
weighted avg     0.9954    0.9954    0.9954    145546

[[36280    49    90    38]
 [   45 36163    36    72]
 [   99    33 36275    50]
 [   47    66    47 36156]]
-------------------------------------------------------------------------------------
train_loss : 0.1617
eval_loss : 0.1705
acc : 0.9911, precision : 0.9820, recall : 0.9656, f1_score : 0.9737
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9121    0.9663    0.9384      9674
           1     0.9844    0.9581    0.9711     21515

    accuracy                         0.9607     31189
   macro avg     0.9483    0.9622    0.9548     31189
weighted avg     0.9620    0.9607    0.9610     31189

[[ 9348   326]
 [  901 20614]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9968    0.9934    0.9951      7745
           1     0.9864    0.9982    0.9923      7789
           2     0.9991    0.9850    0.9920      7869
           3     0.9907    0.9963    0.9935      7786

    accuracy                         0.9932     31189
   macro avg     0.9932    0.9932    0.9932     31189
weighted avg     0.9933    0.9932    0.9932     31189

[[7694   35    2   14]
 [   2 7775    3    9]
 [  19   49 7751   50]
 [   4   23    2 7757]]
-------------------------------------------------------------------------------------
Single epoch cost time : 7.51 mins
**************** | sota | loss : 0.1705 | f1_score : 0.9737 | ****************
epoch :  5|30, iter : 200|1138,  loss : 0.1657
epoch :  5|30, iter : 400|1138,  loss : 0.1590
epoch :  5|30, iter : 600|1138,  loss : 0.1545
epoch :  5|30, iter : 800|1138,  loss : 0.1534
epoch :  5|30, iter : 1000|1138,  loss : 0.1524
acc : 0.8230, precision : 0.4890, recall : 0.4866, f1_score : 0.4878
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9382    0.9416    0.9399     45524
           1     0.9734    0.9718    0.9726    100022

    accuracy                         0.9623    145546
   macro avg     0.9558    0.9567    0.9562    145546
weighted avg     0.9624    0.9623    0.9624    145546

[[42864  2660]
 [ 2822 97200]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9959    0.9961    0.9960     36457
           1     0.9964    0.9963    0.9964     36316
           2     0.9961    0.9962    0.9961     36457
           3     0.9963    0.9961    0.9962     36316

    accuracy                         0.9962    145546
   macro avg     0.9962    0.9962    0.9962    145546
weighted avg     0.9962    0.9962    0.9962    145546

[[36316    38    70    33]
 [   38 36183    34    61]
 [   70    29 36318    40]
 [   40    62    39 36175]]
-------------------------------------------------------------------------------------
train_loss : 0.1525
eval_loss : 0.1779
acc : 0.9895, precision : 0.9646, recall : 0.9742, f1_score : 0.9694
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9122    0.9451    0.9284      9674
           1     0.9749    0.9591    0.9669     21515

    accuracy                         0.9548     31189
   macro avg     0.9436    0.9521    0.9477     31189
weighted avg     0.9555    0.9548    0.9550     31189

[[ 9143   531]
 [  880 20635]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9966    0.9969    0.9968      7745
           1     0.9982    0.9947    0.9965      7789
           2     0.9972    0.9961    0.9966      7869
           3     0.9944    0.9987    0.9965      7786

    accuracy                         0.9966     31189
   macro avg     0.9966    0.9966    0.9966     31189
weighted avg     0.9966    0.9966    0.9966     31189

[[7721    6   12    6]
 [   4 7748    7   30]
 [  19    4 7838    8]
 [   3    4    3 7776]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.53 mins
epoch :  6|30, iter : 200|1138,  loss : 0.1514
epoch :  6|30, iter : 400|1138,  loss : 0.1487
epoch :  6|30, iter : 600|1138,  loss : 0.1478
epoch :  6|30, iter : 800|1138,  loss : 0.1486
epoch :  6|30, iter : 1000|1138,  loss : 0.1481
acc : 0.8228, precision : 0.4884, recall : 0.4867, f1_score : 0.4876
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9403    0.9431    0.9417     45524
           1     0.9741    0.9727    0.9734    100022

    accuracy                         0.9635    145546
   macro avg     0.9572    0.9579    0.9575    145546
weighted avg     0.9635    0.9635    0.9635    145546

[[42932  2592]
 [ 2726 97296]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9962    0.9965    0.9964     36457
           1     0.9969    0.9966    0.9968     36316
           2     0.9963    0.9964    0.9963     36457
           3     0.9964    0.9964    0.9964     36316

    accuracy                         0.9965    145546
   macro avg     0.9965    0.9965    0.9965    145546
weighted avg     0.9965    0.9965    0.9965    145546

[[36331    28    65    33]
 [   35 36192    31    58]
 [   66    28 36324    39]
 [   37    55    40 36184]]
-------------------------------------------------------------------------------------
train_loss : 0.1484
eval_loss : 0.1442
acc : 0.9895, precision : 0.9867, recall : 0.9513, f1_score : 0.9687
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9167    0.9688    0.9420      9674
           1     0.9856    0.9604    0.9728     21515

    accuracy                         0.9630     31189
   macro avg     0.9511    0.9646    0.9574     31189
weighted avg     0.9642    0.9630    0.9633     31189

[[ 9372   302]
 [  852 20663]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9970    0.9985    0.9977      7745
           1     0.9976    0.9976    0.9976      7789
           2     0.9980    0.9961    0.9970      7869
           3     0.9978    0.9983    0.9981      7786

    accuracy                         0.9976     31189
   macro avg     0.9976    0.9976    0.9976     31189
weighted avg     0.9976    0.9976    0.9976     31189

[[7733    5    2    5]
 [   5 7770   10    4]
 [  15    8 7838    8]
 [   3    6    4 7773]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.20 mins
epoch :  7|30, iter : 200|1138,  loss : 0.1473
epoch :  7|30, iter : 400|1138,  loss : 0.1411
epoch :  7|30, iter : 600|1138,  loss : 0.1412
epoch :  7|30, iter : 800|1138,  loss : 0.1410
epoch :  7|30, iter : 1000|1138,  loss : 0.1407
acc : 0.8235, precision : 0.4904, recall : 0.4879, f1_score : 0.4892
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9428    0.9470    0.9449     45524
           1     0.9758    0.9739    0.9748    100022

    accuracy                         0.9655    145546
   macro avg     0.9593    0.9604    0.9599    145546
weighted avg     0.9655    0.9655    0.9655    145546

[[43110  2414]
 [ 2614 97408]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9964    0.9968    0.9966     36457
           1     0.9972    0.9968    0.9970     36316
           2     0.9965    0.9970    0.9967     36457
           3     0.9970    0.9966    0.9968     36316

    accuracy                         0.9968    145546
   macro avg     0.9968    0.9968    0.9968    145546
weighted avg     0.9968    0.9968    0.9968    145546

[[36340    27    60    30]
 [   37 36199    31    49]
 [   58    24 36346    29]
 [   36    49    37 36194]]
-------------------------------------------------------------------------------------
train_loss : 0.1410
eval_loss : 0.1238
acc : 0.9914, precision : 0.9712, recall : 0.9784, f1_score : 0.9748
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9495    0.9507    0.9501      9674
           1     0.9778    0.9773    0.9775     21515

    accuracy                         0.9690     31189
   macro avg     0.9637    0.9640    0.9638     31189
weighted avg     0.9690    0.9690    0.9690     31189

[[ 9197   477]
 [  489 21026]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9968    0.9979    0.9974      7745
           1     0.9985    0.9955    0.9970      7789
           2     0.9981    0.9973    0.9977      7869
           3     0.9959    0.9985    0.9972      7786

    accuracy                         0.9973     31189
   macro avg     0.9973    0.9973    0.9973     31189
weighted avg     0.9973    0.9973    0.9973     31189

[[7729    6    6    4]
 [   8 7754    6   21]
 [  11    3 7848    7]
 [   6    3    3 7774]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.20 mins
**************** | sota | loss : 0.1238 | f1_score : 0.9748 | ****************
epoch :  8|30, iter : 200|1138,  loss : 0.1342
epoch :  8|30, iter : 400|1138,  loss : 0.1340
epoch :  8|30, iter : 600|1138,  loss : 0.1350
epoch :  8|30, iter : 800|1138,  loss : 0.1365
epoch :  8|30, iter : 1000|1138,  loss : 0.1368
acc : 0.8236, precision : 0.4907, recall : 0.4877, f1_score : 0.4892
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9443    0.9482    0.9462     45524
           1     0.9764    0.9746    0.9755    100022

    accuracy                         0.9663    145546
   macro avg     0.9603    0.9614    0.9609    145546
weighted avg     0.9663    0.9663    0.9663    145546

[[43165  2359]
 [ 2545 97477]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9969    0.9965    0.9967     36457
           1     0.9974    0.9974    0.9974     36316
           2     0.9967    0.9970    0.9968     36457
           3     0.9970    0.9970    0.9970     36316

    accuracy                         0.9970    145546
   macro avg     0.9970    0.9970    0.9970    145546
weighted avg     0.9970    0.9970    0.9970    145546

[[36331    30    62    34]
 [   27 36222    26    41]
 [   51    23 36349    34]
 [   35    41    34 36206]]
-------------------------------------------------------------------------------------
train_loss : 0.1369
eval_loss : 0.1519
acc : 0.9895, precision : 0.9865, recall : 0.9516, f1_score : 0.9688
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9122    0.9674    0.9390      9674
           1     0.9849    0.9581    0.9714     21515

    accuracy                         0.9610     31189
   macro avg     0.9486    0.9628    0.9552     31189
weighted avg     0.9624    0.9610    0.9613     31189

[[ 9359   315]
 [  901 20614]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9963    0.9977    0.9970      7745
           1     0.9978    0.9986    0.9982      7789
           2     0.9986    0.9952    0.9969      7869
           3     0.9974    0.9987    0.9981      7786

    accuracy                         0.9975     31189
   macro avg     0.9975    0.9975    0.9975     31189
weighted avg     0.9975    0.9975    0.9975     31189

[[7727    6    5    7]
 [   2 7778    4    5]
 [  25    5 7831    8]
 [   2    6    2 7776]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.16 mins
epoch :  9|30, iter : 200|1138,  loss : 0.1358
epoch :  9|30, iter : 400|1138,  loss : 0.1322
epoch :  9|30, iter : 600|1138,  loss : 0.1314
epoch :  9|30, iter : 800|1138,  loss : 0.1319
epoch :  9|30, iter : 1000|1138,  loss : 0.1319
acc : 0.8235, precision : 0.4905, recall : 0.4881, f1_score : 0.4893
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9454    0.9499    0.9476     45524
           1     0.9771    0.9750    0.9761    100022

    accuracy                         0.9672    145546
   macro avg     0.9613    0.9625    0.9619    145546
weighted avg     0.9672    0.9672    0.9672    145546

[[43242  2282]
 [ 2496 97526]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9972    0.9973    0.9972     36457
           1     0.9975    0.9974    0.9975     36316
           2     0.9970    0.9974    0.9972     36457
           3     0.9975    0.9970    0.9973     36316

    accuracy                         0.9973    145546
   macro avg     0.9973    0.9973    0.9973    145546
weighted avg     0.9973    0.9973    0.9973    145546

[[36358    23    50    26]
 [   27 36223    28    38]
 [   47    21 36363    26]
 [   29    46    33 36208]]
-------------------------------------------------------------------------------------
train_loss : 0.1319
eval_loss : 0.1329
acc : 0.9910, precision : 0.9706, recall : 0.9767, f1_score : 0.9736
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9402    0.9512    0.9457      9674
           1     0.9779    0.9728    0.9754     21515

    accuracy                         0.9661     31189
   macro avg     0.9591    0.9620    0.9605     31189
weighted avg     0.9662    0.9661    0.9662     31189

[[ 9202   472]
 [  585 20930]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9977    0.9981      7745
           1     0.9981    0.9973    0.9977      7789
           2     0.9989    0.9976    0.9982      7869
           3     0.9962    0.9990    0.9976      7786

    accuracy                         0.9979     31189
   macro avg     0.9979    0.9979    0.9979     31189
weighted avg     0.9979    0.9979    0.9979     31189

[[7727    6    3    9]
 [   2 7768    4   15]
 [   8    5 7850    6]
 [   2    4    2 7778]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.07 mins
epoch : 10|30, iter : 200|1138,  loss : 0.1245
epoch : 10|30, iter : 400|1138,  loss : 0.1277
epoch : 10|30, iter : 600|1138,  loss : 0.1292
epoch : 10|30, iter : 800|1138,  loss : 0.1298
epoch : 10|30, iter : 1000|1138,  loss : 0.1281
acc : 0.8239, precision : 0.4916, recall : 0.4888, f1_score : 0.4902
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9473    0.9525    0.9499     45524
           1     0.9783    0.9759    0.9771    100022

    accuracy                         0.9686    145546
   macro avg     0.9628    0.9642    0.9635    145546
weighted avg     0.9686    0.9686    0.9686    145546

[[43361  2163]
 [ 2410 97612]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9973    0.9974    0.9973     36457
           1     0.9979    0.9974    0.9977     36316
           2     0.9972    0.9974    0.9973     36457
           3     0.9976    0.9978    0.9977     36316

    accuracy                         0.9975    145546
   macro avg     0.9975    0.9975    0.9975    145546
weighted avg     0.9975    0.9975    0.9975    145546

[[36362    23    51    21]
 [   27 36222    25    42]
 [   48    22 36364    23]
 [   25    30    26 36235]]
-------------------------------------------------------------------------------------
train_loss : 0.1282
eval_loss : 0.1374
acc : 0.9905, precision : 0.9781, recall : 0.9661, f1_score : 0.9721
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9303    0.9664    0.9480      9674
           1     0.9846    0.9675    0.9760     21515

    accuracy                         0.9671     31189
   macro avg     0.9575    0.9669    0.9620     31189
weighted avg     0.9678    0.9671    0.9673     31189

[[ 9349   325]
 [  700 20815]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9963    0.9970    0.9966      7745
           1     0.9983    0.9919    0.9951      7789
           2     0.9925    0.9977    0.9951      7869
           3     0.9973    0.9977    0.9975      7786

    accuracy                         0.9961     31189
   macro avg     0.9961    0.9961    0.9961     31189
weighted avg     0.9961    0.9961    0.9961     31189

[[7722    5   13    5]
 [  15 7726   36   12]
 [  10    4 7851    4]
 [   4    4   10 7768]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.11 mins
epoch : 11|30, iter : 200|1138,  loss : 0.1249
epoch : 11|30, iter : 400|1138,  loss : 0.1232
epoch : 11|30, iter : 600|1138,  loss : 0.1233
epoch : 11|30, iter : 800|1138,  loss : 0.1250
epoch : 11|30, iter : 1000|1138,  loss : 0.1246
acc : 0.8240, precision : 0.4919, recall : 0.4892, f1_score : 0.4906
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9483    0.9531    0.9507     45524
           1     0.9786    0.9764    0.9775    100022

    accuracy                         0.9691    145546
   macro avg     0.9635    0.9647    0.9641    145546
weighted avg     0.9691    0.9691    0.9691    145546

[[43389  2135]
 [ 2365 97657]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9974    0.9975    0.9975     36457
           1     0.9978    0.9974    0.9976     36316
           2     0.9971    0.9974    0.9972     36457
           3     0.9974    0.9975    0.9974     36316

    accuracy                         0.9974    145546
   macro avg     0.9974    0.9974    0.9974    145546
weighted avg     0.9974    0.9974    0.9974    145546

[[36366    18    46    27]
 [   23 36221    31    41]
 [   48    20 36361    28]
 [   22    41    28 36225]]
-------------------------------------------------------------------------------------
train_loss : 0.1255
eval_loss : 0.1451
acc : 0.9892, precision : 0.9886, recall : 0.9477, f1_score : 0.9677
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9100    0.9740    0.9409      9674
           1     0.9879    0.9567    0.9720     21515

    accuracy                         0.9620     31189
   macro avg     0.9489    0.9653    0.9565     31189
weighted avg     0.9637    0.9620    0.9624     31189

[[ 9422   252]
 [  932 20583]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9977    0.9981      7745
           1     0.9977    0.9981    0.9979      7789
           2     0.9978    0.9982    0.9980      7869
           3     0.9979    0.9981    0.9980      7786

    accuracy                         0.9980     31189
   macro avg     0.9980    0.9980    0.9980     31189
weighted avg     0.9980    0.9980    0.9980     31189

[[7727    5    6    7]
 [   2 7774    9    4]
 [   5    4 7855    5]
 [   4    9    2 7771]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.09 mins
epoch : 12|30, iter : 200|1138,  loss : 0.1210
epoch : 12|30, iter : 400|1138,  loss : 0.1219
epoch : 12|30, iter : 600|1138,  loss : 0.1221
epoch : 12|30, iter : 800|1138,  loss : 0.1219
epoch : 12|30, iter : 1000|1138,  loss : 0.1220
acc : 0.8241, precision : 0.4922, recall : 0.4894, f1_score : 0.4908
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9488    0.9554    0.9521     45524
           1     0.9796    0.9765    0.9781    100022

    accuracy                         0.9699    145546
   macro avg     0.9642    0.9660    0.9651    145546
weighted avg     0.9700    0.9699    0.9699    145546

[[43493  2031]
 [ 2348 97674]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9975    0.9975    0.9975     36457
           1     0.9982    0.9978    0.9980     36316
           2     0.9972    0.9977    0.9975     36457
           3     0.9979    0.9978    0.9978     36316

    accuracy                         0.9977    145546
   macro avg     0.9977    0.9977    0.9977    145546
weighted avg     0.9977    0.9977    0.9977    145546

[[36366    22    45    24]
 [   22 36236    27    31]
 [   43    19 36373    22]
 [   27    25    29 36235]]
-------------------------------------------------------------------------------------
train_loss : 0.1228
eval_loss : 0.1529
acc : 0.9874, precision : 0.9896, recall : 0.9356, f1_score : 0.9619
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9034    0.9779    0.9391      9674
           1     0.9897    0.9530    0.9710     21515

    accuracy                         0.9607     31189
   macro avg     0.9465    0.9654    0.9551     31189
weighted avg     0.9629    0.9607    0.9611     31189

[[ 9460   214]
 [ 1012 20503]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9974    0.9979    0.9977      7745
           1     0.9978    0.9990    0.9984      7789
           2     0.9989    0.9959    0.9974      7869
           3     0.9973    0.9986    0.9979      7786

    accuracy                         0.9979     31189
   macro avg     0.9978    0.9979    0.9979     31189
weighted avg     0.9979    0.9979    0.9979     31189

[[7729    5    4    7]
 [   1 7781    3    4]
 [  17    5 7837   10]
 [   2    7    2 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.10 mins
epoch : 13|30, iter : 200|1138,  loss : 0.1248
epoch : 13|30, iter : 400|1138,  loss : 0.1215
epoch : 13|30, iter : 600|1138,  loss : 0.1206
epoch : 13|30, iter : 800|1138,  loss : 0.1213
epoch : 13|30, iter : 1000|1138,  loss : 0.1204
acc : 0.8242, precision : 0.4924, recall : 0.4892, f1_score : 0.4908
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9496    0.9559    0.9527     45524
           1     0.9799    0.9769    0.9784    100022

    accuracy                         0.9703    145546
   macro avg     0.9647    0.9664    0.9655    145546
weighted avg     0.9704    0.9703    0.9703    145546

[[43516  2008]
 [ 2312 97710]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9971    0.9973    0.9972     36457
           1     0.9978    0.9972    0.9975     36316
           2     0.9971    0.9974    0.9973     36457
           3     0.9975    0.9975    0.9975     36316

    accuracy                         0.9974    145546
   macro avg     0.9974    0.9974    0.9974    145546
weighted avg     0.9974    0.9974    0.9974    145546

[[36359    19    56    23]
 [   27 36216    29    44]
 [   52    18 36364    23]
 [   27    42    22 36225]]
-------------------------------------------------------------------------------------
train_loss : 0.1225
eval_loss : 0.1671
acc : 0.9894, precision : 0.9813, recall : 0.9558, f1_score : 0.9684
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9074    0.9569    0.9315      9674
           1     0.9801    0.9561    0.9680     21515

    accuracy                         0.9563     31189
   macro avg     0.9438    0.9565    0.9497     31189
weighted avg     0.9576    0.9563    0.9566     31189

[[ 9257   417]
 [  945 20570]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9965    0.9947    0.9956      7745
           1     0.9975    0.9928    0.9952      7789
           2     0.9950    0.9947    0.9949      7869
           3     0.9916    0.9985    0.9950      7786

    accuracy                         0.9952     31189
   macro avg     0.9952    0.9952    0.9952     31189
weighted avg     0.9952    0.9952    0.9952     31189

[[7704   10   21   10]
 [  14 7733   14   28]
 [   7    7 7827   28]
 [   6    2    4 7774]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.20 mins
epoch : 14|30, iter : 200|1138,  loss : 0.1320
epoch : 14|30, iter : 400|1138,  loss : 0.1246
epoch : 14|30, iter : 600|1138,  loss : 0.1236
epoch : 14|30, iter : 800|1138,  loss : 0.1223
epoch : 14|30, iter : 1000|1138,  loss : 0.1215
acc : 0.8241, precision : 0.4921, recall : 0.4890, f1_score : 0.4905
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9503    0.9560    0.9531     45524
           1     0.9799    0.9773    0.9786    100022

    accuracy                         0.9706    145546
   macro avg     0.9651    0.9666    0.9659    145546
weighted avg     0.9706    0.9706    0.9706    145546

[[43519  2005]
 [ 2275 97747]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9976    0.9971    0.9974     36457
           1     0.9976    0.9974    0.9975     36316
           2     0.9970    0.9974    0.9972     36457
           3     0.9971    0.9973    0.9972     36316

    accuracy                         0.9973    145546
   macro avg     0.9973    0.9973    0.9973    145546
weighted avg     0.9973    0.9973    0.9973    145546

[[36352    29    43    33]
 [   24 36220    35    37]
 [   34    23 36363    37]
 [   30    36    32 36218]]
-------------------------------------------------------------------------------------
train_loss : 0.1210
eval_loss : 0.1414
acc : 0.9906, precision : 0.9650, recall : 0.9802, f1_score : 0.9726
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9342    0.9444    0.9393      9674
           1     0.9749    0.9701    0.9725     21515

    accuracy                         0.9621     31189
   macro avg     0.9546    0.9573    0.9559     31189
weighted avg     0.9623    0.9621    0.9622     31189

[[ 9136   538]
 [  643 20872]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9978    0.9983    0.9981      7745
           1     0.9983    0.9974    0.9979      7789
           2     0.9990    0.9968    0.9979      7869
           3     0.9960    0.9986    0.9973      7786

    accuracy                         0.9978     31189
   macro avg     0.9978    0.9978    0.9978     31189
weighted avg     0.9978    0.9978    0.9978     31189

[[7732    5    3    5]
 [   3 7769    3   14]
 [  10    3 7844   12]
 [   4    5    2 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.08 mins
epoch : 15|30, iter : 200|1138,  loss : 0.1246
epoch : 15|30, iter : 400|1138,  loss : 0.1206
epoch : 15|30, iter : 600|1138,  loss : 0.1174
epoch : 15|30, iter : 800|1138,  loss : 0.1168
epoch : 15|30, iter : 1000|1138,  loss : 0.1173
acc : 0.8242, precision : 0.4926, recall : 0.4897, f1_score : 0.4911
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9514    0.9585    0.9549     45524
           1     0.9810    0.9777    0.9794    100022

    accuracy                         0.9717    145546
   macro avg     0.9662    0.9681    0.9672    145546
weighted avg     0.9718    0.9717    0.9717    145546

[[43634  1890]
 [ 2228 97794]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9978    0.9978    0.9978     36457
           1     0.9981    0.9978    0.9979     36316
           2     0.9973    0.9977    0.9975     36457
           3     0.9977    0.9977    0.9977     36316

    accuracy                         0.9977    145546
   macro avg     0.9977    0.9977    0.9977    145546
weighted avg     0.9977    0.9977    0.9977    145546

[[36378    18    41    20]
 [   21 36235    25    35]
 [   38    17 36374    28]
 [   21    33    31 36231]]
-------------------------------------------------------------------------------------
train_loss : 0.1172
eval_loss : 0.1279
acc : 0.9921, precision : 0.9819, recall : 0.9714, f1_score : 0.9766
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9382    0.9575    0.9478      9674
           1     0.9807    0.9716    0.9762     21515

    accuracy                         0.9673     31189
   macro avg     0.9595    0.9646    0.9620     31189
weighted avg     0.9675    0.9673    0.9674     31189

[[ 9263   411]
 [  610 20905]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9975    0.9973    0.9974      7745
           1     0.9971    0.9981    0.9976      7789
           2     0.9977    0.9975    0.9976      7869
           3     0.9982    0.9977    0.9979      7786

    accuracy                         0.9976     31189
   macro avg     0.9976    0.9976    0.9976     31189
weighted avg     0.9976    0.9976    0.9976     31189

[[7724    7    9    5]
 [   6 7774    5    4]
 [   9    6 7849    5]
 [   4   10    4 7768]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.15 mins
epoch : 16|30, iter : 200|1138,  loss : 0.1178
epoch : 16|30, iter : 400|1138,  loss : 0.1183
epoch : 16|30, iter : 600|1138,  loss : 0.1175
epoch : 16|30, iter : 800|1138,  loss : 0.1156
epoch : 16|30, iter : 1000|1138,  loss : 0.1166
acc : 0.8242, precision : 0.4923, recall : 0.4902, f1_score : 0.4913
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9530    0.9571    0.9551     45524
           1     0.9804    0.9785    0.9795    100022

    accuracy                         0.9718    145546
   macro avg     0.9667    0.9678    0.9673    145546
weighted avg     0.9719    0.9718    0.9718    145546

[[43571  1953]
 [ 2147 97875]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9974    0.9975    0.9974     36457
           1     0.9978    0.9977    0.9978     36316
           2     0.9974    0.9977    0.9975     36457
           3     0.9977    0.9974    0.9976     36316

    accuracy                         0.9976    145546
   macro avg     0.9976    0.9976    0.9976    145546
weighted avg     0.9976    0.9976    0.9976    145546

[[36366    23    40    28]
 [   25 36233    27    31]
 [   44    17 36372    24]
 [   26    40    28 36222]]
-------------------------------------------------------------------------------------
train_loss : 0.1175
eval_loss : 0.1404
acc : 0.9884, precision : 0.9876, recall : 0.9437, f1_score : 0.9652
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9274    0.9579    0.9424      9674
           1     0.9808    0.9663    0.9735     21515

    accuracy                         0.9637     31189
   macro avg     0.9541    0.9621    0.9580     31189
weighted avg     0.9642    0.9637    0.9639     31189

[[ 9267   407]
 [  725 20790]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9969    0.9974    0.9972      7745
           1     0.9986    0.9960    0.9973      7789
           2     0.9976    0.9973    0.9975      7869
           3     0.9964    0.9987    0.9976      7786

    accuracy                         0.9974     31189
   macro avg     0.9974    0.9974    0.9974     31189
weighted avg     0.9974    0.9974    0.9974     31189

[[7725    5    9    6]
 [   9 7758    7   15]
 [  11    3 7848    7]
 [   4    3    3 7776]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.02 mins
epoch : 17|30, iter : 200|1138,  loss : 0.1318
epoch : 17|30, iter : 400|1138,  loss : 0.1232
epoch : 17|30, iter : 600|1138,  loss : 0.1202
epoch : 17|30, iter : 800|1138,  loss : 0.1193
epoch : 17|30, iter : 1000|1138,  loss : 0.1168
acc : 0.8241, precision : 0.4922, recall : 0.4895, f1_score : 0.4908
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9515    0.9571    0.9543     45524
           1     0.9804    0.9778    0.9791    100022

    accuracy                         0.9713    145546
   macro avg     0.9660    0.9675    0.9667    145546
weighted avg     0.9714    0.9713    0.9714    145546

[[43572  1952]
 [ 2221 97801]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9976    0.9974    0.9975     36457
           1     0.9981    0.9976    0.9979     36316
           2     0.9970    0.9975    0.9972     36457
           3     0.9975    0.9977    0.9976     36316

    accuracy                         0.9976    145546
   macro avg     0.9976    0.9976    0.9976    145546
weighted avg     0.9976    0.9976    0.9976    145546

[[36364    15    49    29]
 [   19 36229    31    37]
 [   47    21 36365    24]
 [   23    32    29 36232]]
-------------------------------------------------------------------------------------
train_loss : 0.1177
eval_loss : 0.1361
acc : 0.9915, precision : 0.9782, recall : 0.9720, f1_score : 0.9751
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9257    0.9688    0.9468      9674
           1     0.9857    0.9650    0.9752     21515

    accuracy                         0.9662     31189
   macro avg     0.9557    0.9669    0.9610     31189
weighted avg     0.9671    0.9662    0.9664     31189

[[ 9372   302]
 [  752 20763]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9942    0.9983    0.9963      7745
           1     0.9972    0.9985    0.9978      7789
           2     0.9991    0.9934    0.9962      7869
           3     0.9979    0.9983    0.9981      7786

    accuracy                         0.9971     31189
   macro avg     0.9971    0.9971    0.9971     31189
weighted avg     0.9971    0.9971    0.9971     31189

[[7732    7    1    5]
 [   3 7777    4    5]
 [  39    7 7817    6]
 [   3    8    2 7773]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.06 mins
epoch : 18|30, iter : 200|1138,  loss : 0.1111
epoch : 18|30, iter : 400|1138,  loss : 0.1088
epoch : 18|30, iter : 600|1138,  loss : 0.1079
epoch : 18|30, iter : 800|1138,  loss : 0.1105
epoch : 18|30, iter : 1000|1138,  loss : 0.1127
acc : 0.8244, precision : 0.4929, recall : 0.4906, f1_score : 0.4917
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9540    0.9597    0.9568     45524
           1     0.9816    0.9790    0.9803    100022

    accuracy                         0.9729    145546
   macro avg     0.9678    0.9693    0.9686    145546
weighted avg     0.9730    0.9729    0.9729    145546

[[43688  1836]
 [ 2105 97917]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9975    0.9978    0.9976     36457
           1     0.9982    0.9980    0.9981     36316
           2     0.9977    0.9978    0.9978     36457
           3     0.9982    0.9979    0.9980     36316

    accuracy                         0.9979    145546
   macro avg     0.9979    0.9979    0.9979    145546
weighted avg     0.9979    0.9979    0.9979    145546

[[36376    21    41    19]
 [   25 36245    21    25]
 [   40    17 36378    22]
 [   26    28    23 36239]]
-------------------------------------------------------------------------------------
train_loss : 0.1131
eval_loss : 0.1439
acc : 0.9918, precision : 0.9720, recall : 0.9799, f1_score : 0.9759
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9663    0.9130    0.9389      9674
           1     0.9618    0.9857    0.9736     21515

    accuracy                         0.9631     31189
   macro avg     0.9641    0.9493    0.9562     31189
weighted avg     0.9632    0.9631    0.9628     31189

[[ 8832   842]
 [  308 21207]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9988    0.9979    0.9984      7745
           1     0.9985    0.9967    0.9976      7789
           2     0.9977    0.9983    0.9980      7869
           3     0.9967    0.9987    0.9977      7786

    accuracy                         0.9979     31189
   macro avg     0.9979    0.9979    0.9979     31189
weighted avg     0.9979    0.9979    0.9979     31189

[[7729    5    6    5]
 [   2 7763    8   16]
 [   5    3 7856    5]
 [   2    4    4 7776]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.14 mins
epoch : 19|30, iter : 200|1138,  loss : 0.0959
epoch : 19|30, iter : 400|1138,  loss : 0.0948
epoch : 19|30, iter : 600|1138,  loss : 0.0931
epoch : 19|30, iter : 800|1138,  loss : 0.0942
epoch : 19|30, iter : 1000|1138,  loss : 0.0945
acc : 0.8250, precision : 0.4949, recall : 0.4923, f1_score : 0.4936
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9622    0.9675    0.9648     45524
           1     0.9852    0.9827    0.9839    100022

    accuracy                         0.9779    145546
   macro avg     0.9737    0.9751    0.9744    145546
weighted avg     0.9780    0.9779    0.9780    145546

[[44045  1479]
 [ 1731 98291]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9983    0.9982     36457
           1     0.9988    0.9985    0.9987     36316
           2     0.9981    0.9984    0.9982     36457
           3     0.9985    0.9984    0.9984     36316

    accuracy                         0.9984    145546
   macro avg     0.9984    0.9984    0.9984    145546
weighted avg     0.9984    0.9984    0.9984    145546

[[36395    17    26    19]
 [   19 36261    20    16]
 [   27    11 36398    21]
 [   21    15    23 36257]]
-------------------------------------------------------------------------------------
train_loss : 0.0954
eval_loss : 0.1130
acc : 0.9923, precision : 0.9818, recall : 0.9731, f1_score : 0.9774
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9508    0.9594    0.9551      9674
           1     0.9817    0.9777    0.9797     21515

    accuracy                         0.9720     31189
   macro avg     0.9662    0.9685    0.9674     31189
weighted avg     0.9721    0.9720    0.9720     31189

[[ 9281   393]
 [  480 21035]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9981    0.9983    0.9982      7745
           1     0.9981    0.9986    0.9983      7789
           2     0.9991    0.9970    0.9980      7869
           3     0.9976    0.9990    0.9983      7786

    accuracy                         0.9982     31189
   macro avg     0.9982    0.9982    0.9982     31189
weighted avg     0.9982    0.9982    0.9982     31189

[[7732    6    2    5]
 [   2 7778    3    6]
 [  11    5 7845    8]
 [   2    4    2 7778]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.01 mins
**************** | sota | loss : 0.1130 | f1_score : 0.9774 | ****************
epoch : 20|30, iter : 200|1138,  loss : 0.0820
epoch : 20|30, iter : 400|1138,  loss : 0.0852
epoch : 20|30, iter : 600|1138,  loss : 0.0874
epoch : 20|30, iter : 800|1138,  loss : 0.0895
epoch : 20|30, iter : 1000|1138,  loss : 0.0909
acc : 0.8250, precision : 0.4948, recall : 0.4923, f1_score : 0.4935
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9638    0.9687    0.9663     45524
           1     0.9857    0.9835    0.9846    100022

    accuracy                         0.9788    145546
   macro avg     0.9748    0.9761    0.9754    145546
weighted avg     0.9789    0.9788    0.9789    145546

[[44100  1424]
 [ 1655 98367]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9983    0.9983     36457
           1     0.9987    0.9985    0.9986     36316
           2     0.9980    0.9983    0.9981     36457
           3     0.9984    0.9983    0.9983     36316

    accuracy                         0.9983    145546
   macro avg     0.9983    0.9983    0.9983    145546
weighted avg     0.9983    0.9983    0.9983    145546

[[36396    15    26    20]
 [   18 36260    22    16]
 [   25    17 36394    21]
 [   21    17    25 36253]]
-------------------------------------------------------------------------------------
train_loss : 0.0915
eval_loss : 0.1229
acc : 0.9923, precision : 0.9774, recall : 0.9774, f1_score : 0.9774
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9348    0.9650    0.9496      9674
           1     0.9840    0.9697    0.9768     21515

    accuracy                         0.9683     31189
   macro avg     0.9594    0.9673    0.9632     31189
weighted avg     0.9688    0.9683    0.9684     31189

[[ 9335   339]
 [  651 20864]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9977    0.9982      7745
           1     0.9982    0.9986    0.9984      7789
           2     0.9978    0.9982    0.9980      7869
           3     0.9982    0.9985    0.9983      7786

    accuracy                         0.9982     31189
   macro avg     0.9982    0.9982    0.9982     31189
weighted avg     0.9982    0.9982    0.9982     31189

[[7727    5    8    5]
 [   2 7778    6    3]
 [   5    3 7855    6]
 [   3    6    3 7774]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.14 mins
epoch : 21|30, iter : 200|1138,  loss : 0.0835
epoch : 21|30, iter : 400|1138,  loss : 0.0882
epoch : 21|30, iter : 600|1138,  loss : 0.0884
epoch : 21|30, iter : 800|1138,  loss : 0.0886
epoch : 21|30, iter : 1000|1138,  loss : 0.0899
acc : 0.8251, precision : 0.4952, recall : 0.4926, f1_score : 0.4939
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9643    0.9698    0.9670     45524
           1     0.9862    0.9837    0.9849    100022

    accuracy                         0.9793    145546
   macro avg     0.9753    0.9767    0.9760    145546
weighted avg     0.9794    0.9793    0.9793    145546

[[44149  1375]
 [ 1635 98387]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9983    0.9984     36457
           1     0.9988    0.9983    0.9986     36316
           2     0.9981    0.9985    0.9983     36457
           3     0.9983    0.9983    0.9983     36316

    accuracy                         0.9984    145546
   macro avg     0.9984    0.9984    0.9984    145546
weighted avg     0.9984    0.9984    0.9984    145546

[[36396    13    27    21]
 [   18 36256    21    21]
 [   22    10 36404    21]
 [   19    21    23 36253]]
-------------------------------------------------------------------------------------
train_loss : 0.0904
eval_loss : 0.1234
acc : 0.9915, precision : 0.9858, recall : 0.9641, f1_score : 0.9748
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9344    0.9714    0.9525      9674
           1     0.9869    0.9693    0.9780     21515

    accuracy                         0.9700     31189
   macro avg     0.9606    0.9703    0.9653     31189
weighted avg     0.9706    0.9700    0.9701     31189

[[ 9397   277]
 [  660 20855]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9969    0.9977      7745
           1     0.9971    0.9990    0.9980      7789
           2     0.9982    0.9976    0.9979      7869
           3     0.9983    0.9986    0.9985      7786

    accuracy                         0.9980     31189
   macro avg     0.9980    0.9980    0.9980     31189
weighted avg     0.9980    0.9980    0.9980     31189

[[7721   11    8    5]
 [   1 7781    4    3]
 [   9    5 7850    5]
 [   2    7    2 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.09 mins
epoch : 22|30, iter : 200|1138,  loss : 0.0876
epoch : 22|30, iter : 400|1138,  loss : 0.0868
epoch : 22|30, iter : 600|1138,  loss : 0.0857
epoch : 22|30, iter : 800|1138,  loss : 0.0876
epoch : 22|30, iter : 1000|1138,  loss : 0.0879
acc : 0.8254, precision : 0.4959, recall : 0.4931, f1_score : 0.4945
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9651    0.9708    0.9679     45524
           1     0.9867    0.9840    0.9853    100022

    accuracy                         0.9799    145546
   macro avg     0.9759    0.9774    0.9766    145546
weighted avg     0.9799    0.9799    0.9799    145546

[[44195  1329]
 [ 1600 98422]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9984    0.9984     36457
           1     0.9987    0.9983    0.9985     36316
           2     0.9981    0.9984    0.9982     36457
           3     0.9984    0.9983    0.9984     36316

    accuracy                         0.9984    145546
   macro avg     0.9984    0.9984    0.9984    145546
weighted avg     0.9984    0.9984    0.9984    145546

[[36400    14    27    16]
 [   17 36256    20    23]
 [   26    12 36400    19]
 [   17    20    24 36255]]
-------------------------------------------------------------------------------------
train_loss : 0.0890
eval_loss : 0.1167
acc : 0.9926, precision : 0.9775, recall : 0.9793, f1_score : 0.9784
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9550    0.9550    0.9550      9674
           1     0.9798    0.9798    0.9798     21515

    accuracy                         0.9721     31189
   macro avg     0.9674    0.9674    0.9674     31189
weighted avg     0.9721    0.9721    0.9721     31189

[[ 9239   435]
 [  435 21080]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9979    0.9981      7745
           1     0.9983    0.9982    0.9983      7789
           2     0.9983    0.9977    0.9980      7869
           3     0.9977    0.9987    0.9982      7786

    accuracy                         0.9981     31189
   macro avg     0.9981    0.9981    0.9981     31189
weighted avg     0.9981    0.9981    0.9981     31189

[[7729    5    5    6]
 [   2 7775    6    6]
 [   9    3 7851    6]
 [   3    5    2 7776]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.13 mins
epoch : 23|30, iter : 200|1138,  loss : 0.0833
epoch : 23|30, iter : 400|1138,  loss : 0.0842
epoch : 23|30, iter : 600|1138,  loss : 0.0864
epoch : 23|30, iter : 800|1138,  loss : 0.0860
epoch : 23|30, iter : 1000|1138,  loss : 0.0877
acc : 0.8255, precision : 0.4963, recall : 0.4929, f1_score : 0.4946
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9657    0.9711    0.9684     45524
           1     0.9868    0.9843    0.9856    100022

    accuracy                         0.9802    145546
   macro avg     0.9763    0.9777    0.9770    145546
weighted avg     0.9802    0.9802    0.9802    145546

[[44210  1314]
 [ 1568 98454]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9983    0.9983     36457
           1     0.9985    0.9982    0.9983     36316
           2     0.9982    0.9985    0.9983     36457
           3     0.9983    0.9983    0.9983     36316

    accuracy                         0.9983    145546
   macro avg     0.9983    0.9983    0.9983    145546
weighted avg     0.9983    0.9983    0.9983    145546

[[36396    16    23    22]
 [   23 36250    21    22]
 [   21    16 36402    18]
 [   17    24    22 36253]]
-------------------------------------------------------------------------------------
train_loss : 0.0887
eval_loss : 0.1270
acc : 0.9914, precision : 0.9700, recall : 0.9801, f1_score : 0.9750
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9512    0.9431    0.9472      9674
           1     0.9745    0.9782    0.9764     21515

    accuracy                         0.9674     31189
   macro avg     0.9629    0.9607    0.9618     31189
weighted avg     0.9673    0.9674    0.9673     31189

[[ 9124   550]
 [  468 21047]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9983    0.9985      7745
           1     0.9972    0.9988    0.9980      7789
           2     0.9990    0.9961    0.9975      7869
           3     0.9965    0.9981    0.9973      7786

    accuracy                         0.9978     31189
   macro avg     0.9978    0.9978    0.9978     31189
weighted avg     0.9978    0.9978    0.9978     31189

[[7732    6    3    4]
 [   1 7780    3    5]
 [   8    5 7838   18]
 [   2   11    2 7771]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.11 mins
epoch : 24|30, iter : 200|1138,  loss : 0.0972
epoch : 24|30, iter : 400|1138,  loss : 0.0933
epoch : 24|30, iter : 600|1138,  loss : 0.0893
epoch : 24|30, iter : 800|1138,  loss : 0.0885
epoch : 24|30, iter : 1000|1138,  loss : 0.0885
acc : 0.8253, precision : 0.4956, recall : 0.4923, f1_score : 0.4940
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9656    0.9713    0.9684     45524
           1     0.9869    0.9842    0.9856    100022

    accuracy                         0.9802    145546
   macro avg     0.9762    0.9778    0.9770    145546
weighted avg     0.9802    0.9802    0.9802    145546

[[44217  1307]
 [ 1577 98445]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9981    0.9981    0.9981     36457
           1     0.9983    0.9980    0.9981     36316
           2     0.9978    0.9982    0.9980     36457
           3     0.9984    0.9982    0.9983     36316

    accuracy                         0.9981    145546
   macro avg     0.9981    0.9981    0.9981    145546
weighted avg     0.9981    0.9981    0.9981    145546

[[36386    21    32    18]
 [   26 36243    27    20]
 [   27    17 36393    20]
 [   18    24    23 36251]]
-------------------------------------------------------------------------------------
train_loss : 0.0879
eval_loss : 0.1189
acc : 0.9924, precision : 0.9794, recall : 0.9761, f1_score : 0.9778
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9496    0.9577    0.9536      9674
           1     0.9809    0.9771    0.9790     21515

    accuracy                         0.9711     31189
   macro avg     0.9652    0.9674    0.9663     31189
weighted avg     0.9712    0.9711    0.9711     31189

[[ 9265   409]
 [  492 21023]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9973    0.9987    0.9980      7745
           1     0.9982    0.9988    0.9985      7789
           2     0.9991    0.9970    0.9980      7869
           3     0.9986    0.9987    0.9987      7786

    accuracy                         0.9983     31189
   macro avg     0.9983    0.9983    0.9983     31189
weighted avg     0.9983    0.9983    0.9983     31189

[[7735    5    1    4]
 [   3 7780    4    2]
 [  16    3 7845    5]
 [   2    6    2 7776]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.15 mins
epoch : 25|30, iter : 200|1138,  loss : 0.0776
epoch : 25|30, iter : 400|1138,  loss : 0.0806
epoch : 25|30, iter : 600|1138,  loss : 0.0824
epoch : 25|30, iter : 800|1138,  loss : 0.0840
epoch : 25|30, iter : 1000|1138,  loss : 0.0841
acc : 0.8252, precision : 0.4952, recall : 0.4924, f1_score : 0.4938
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9669    0.9721    0.9695     45524
           1     0.9873    0.9848    0.9861    100022

    accuracy                         0.9809    145546
   macro avg     0.9771    0.9785    0.9778    145546
weighted avg     0.9809    0.9809    0.9809    145546

[[44254  1270]
 [ 1517 98505]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9984    0.9983     36457
           1     0.9987    0.9983    0.9985     36316
           2     0.9983    0.9985    0.9984     36457
           3     0.9984    0.9984    0.9984     36316

    accuracy                         0.9984    145546
   macro avg     0.9984    0.9984    0.9984    145546
weighted avg     0.9984    0.9984    0.9984    145546

[[36400    14    24    19]
 [   20 36256    19    21]
 [   24    13 36403    17]
 [   20    19    19 36258]]
-------------------------------------------------------------------------------------
train_loss : 0.0846
eval_loss : 0.1199
acc : 0.9920, precision : 0.9738, recall : 0.9793, f1_score : 0.9765
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9454    0.9562    0.9508      9674
           1     0.9802    0.9752    0.9777     21515

    accuracy                         0.9693     31189
   macro avg     0.9628    0.9657    0.9642     31189
weighted avg     0.9694    0.9693    0.9693     31189

[[ 9250   424]
 [  534 20981]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9979    0.9981      7745
           1     0.9974    0.9988    0.9981      7789
           2     0.9985    0.9976    0.9980      7869
           3     0.9983    0.9981    0.9982      7786

    accuracy                         0.9981     31189
   macro avg     0.9981    0.9981    0.9981     31189
weighted avg     0.9981    0.9981    0.9981     31189

[[7729    5    5    6]
 [   1 7780    5    3]
 [  11    4 7850    4]
 [   2   11    2 7771]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.16 mins
epoch : 26|30, iter : 200|1138,  loss : 0.0738
epoch : 26|30, iter : 400|1138,  loss : 0.0728
epoch : 26|30, iter : 600|1138,  loss : 0.0720
epoch : 26|30, iter : 800|1138,  loss : 0.0711
epoch : 26|30, iter : 1000|1138,  loss : 0.0707
acc : 0.8262, precision : 0.4982, recall : 0.4949, f1_score : 0.4966
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9732    0.9795    0.9763     45524
           1     0.9906    0.9877    0.9892    100022

    accuracy                         0.9852    145546
   macro avg     0.9819    0.9836    0.9828    145546
weighted avg     0.9852    0.9852    0.9852    145546

[[44589   935]
 [ 1226 98796]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9987    0.9986     36457
           1     0.9989    0.9985    0.9987     36316
           2     0.9984    0.9986    0.9985     36457
           3     0.9985    0.9985    0.9985     36316

    accuracy                         0.9986    145546
   macro avg     0.9986    0.9986    0.9986    145546
weighted avg     0.9986    0.9986    0.9986    145546

[[36409    12    18    18]
 [   15 36263    20    18]
 [   22    12 36405    18]
 [   15    16    22 36263]]
-------------------------------------------------------------------------------------
train_loss : 0.0707
eval_loss : 0.1193
acc : 0.9919, precision : 0.9801, recall : 0.9721, f1_score : 0.9761
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9537    0.9559    0.9548      9674
           1     0.9801    0.9791    0.9796     21515

    accuracy                         0.9719     31189
   macro avg     0.9669    0.9675    0.9672     31189
weighted avg     0.9719    0.9719    0.9719     31189

[[ 9247   427]
 [  449 21066]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9988    0.9979    0.9984      7745
           1     0.9974    0.9991    0.9983      7789
           2     0.9986    0.9980    0.9983      7869
           3     0.9986    0.9985    0.9985      7786

    accuracy                         0.9984     31189
   macro avg     0.9984    0.9984    0.9984     31189
weighted avg     0.9984    0.9984    0.9984     31189

[[7729    7    5    4]
 [   1 7782    4    2]
 [   6    5 7853    5]
 [   2    8    2 7774]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.06 mins
epoch : 27|30, iter : 200|1138,  loss : 0.0624
epoch : 27|30, iter : 400|1138,  loss : 0.0625
epoch : 27|30, iter : 600|1138,  loss : 0.0647
epoch : 27|30, iter : 800|1138,  loss : 0.0660
epoch : 27|30, iter : 1000|1138,  loss : 0.0669
acc : 0.8262, precision : 0.4982, recall : 0.4950, f1_score : 0.4966
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9753    0.9812    0.9782     45524
           1     0.9914    0.9887    0.9900    100022

    accuracy                         0.9863    145546
   macro avg     0.9833    0.9849    0.9841    145546
weighted avg     0.9864    0.9863    0.9863    145546

[[44668   856]
 [ 1133 98889]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9986    0.9986     36457
           1     0.9991    0.9986    0.9988     36316
           2     0.9983    0.9987    0.9985     36457
           3     0.9986    0.9987    0.9987     36316

    accuracy                         0.9987    145546
   macro avg     0.9987    0.9987    0.9987    145546
weighted avg     0.9987    0.9987    0.9987    145546

[[36407    12    20    18]
 [   16 36264    20    16]
 [   20    10 36410    17]
 [   15    11    21 36269]]
-------------------------------------------------------------------------------------
train_loss : 0.0664
eval_loss : 0.1228
acc : 0.9918, precision : 0.9854, recall : 0.9663, f1_score : 0.9758
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9468    0.9628    0.9547      9674
           1     0.9831    0.9757    0.9794     21515

    accuracy                         0.9717     31189
   macro avg     0.9650    0.9692    0.9671     31189
weighted avg     0.9719    0.9717    0.9718     31189

[[ 9314   360]
 [  523 20992]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9974    0.9981      7745
           1     0.9977    0.9991    0.9984      7789
           2     0.9980    0.9983    0.9982      7869
           3     0.9987    0.9982    0.9985      7786

    accuracy                         0.9983     31189
   macro avg     0.9983    0.9983    0.9983     31189
weighted avg     0.9983    0.9983    0.9983     31189

[[7725    6   10    4]
 [   1 7782    4    2]
 [   6    3 7856    4]
 [   3    9    2 7772]]
-------------------------------------------------------------------------------------
Single epoch cost time : 5.97 mins
epoch : 28|30, iter : 200|1138,  loss : 0.0665
epoch : 28|30, iter : 400|1138,  loss : 0.0628
epoch : 28|30, iter : 600|1138,  loss : 0.0640
epoch : 28|30, iter : 800|1138,  loss : 0.0638
epoch : 28|30, iter : 1000|1138,  loss : 0.0639
acc : 0.8261, precision : 0.4978, recall : 0.4942, f1_score : 0.4960
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9762    0.9824    0.9793     45524
           1     0.9919    0.9891    0.9905    100022

    accuracy                         0.9870    145546
   macro avg     0.9841    0.9857    0.9849    145546
weighted avg     0.9870    0.9870    0.9870    145546

[[44721   803]
 [ 1091 98931]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9985    0.9986     36457
           1     0.9989    0.9987    0.9988     36316
           2     0.9984    0.9988    0.9986     36457
           3     0.9988    0.9987    0.9987     36316

    accuracy                         0.9987    145546
   macro avg     0.9987    0.9987    0.9987    145546
weighted avg     0.9987    0.9987    0.9987    145546

[[36404    14    21    18]
 [   16 36267    20    13]
 [   18    13 36412    14]
 [   17    14    18 36267]]
-------------------------------------------------------------------------------------
train_loss : 0.0638
eval_loss : 0.1228
acc : 0.9923, precision : 0.9818, recall : 0.9729, f1_score : 0.9773
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9544    0.9548    0.9546      9674
           1     0.9797    0.9795    0.9796     21515

    accuracy                         0.9718     31189
   macro avg     0.9671    0.9672    0.9671     31189
weighted avg     0.9719    0.9718    0.9719     31189

[[ 9237   437]
 [  441 21074]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9983    0.9985      7745
           1     0.9983    0.9986    0.9985      7789
           2     0.9990    0.9981    0.9985      7869
           3     0.9981    0.9990    0.9985      7786

    accuracy                         0.9985     31189
   macro avg     0.9985    0.9985    0.9985     31189
weighted avg     0.9985    0.9985    0.9985     31189

[[7732    6    2    5]
 [   2 7778    4    5]
 [   7    3 7854    5]
 [   2    4    2 7778]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.11 mins
epoch : 29|30, iter : 200|1138,  loss : 0.0518
epoch : 29|30, iter : 400|1138,  loss : 0.0573
epoch : 29|30, iter : 600|1138,  loss : 0.0589
epoch : 29|30, iter : 800|1138,  loss : 0.0591
epoch : 29|30, iter : 1000|1138,  loss : 0.0605
acc : 0.8264, precision : 0.4988, recall : 0.4956, f1_score : 0.4972
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9780    0.9834    0.9807     45524
           1     0.9924    0.9899    0.9912    100022

    accuracy                         0.9879    145546
   macro avg     0.9852    0.9867    0.9859    145546
weighted avg     0.9879    0.9879    0.9879    145546

[[44767   757]
 [ 1007 99015]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9985    0.9985    0.9985     36457
           1     0.9989    0.9987    0.9988     36316
           2     0.9983    0.9988    0.9985     36457
           3     0.9986    0.9984    0.9985     36316

    accuracy                         0.9986    145546
   macro avg     0.9986    0.9986    0.9986    145546
weighted avg     0.9986    0.9986    0.9986    145546

[[36404    14    21    18]
 [   15 36268    18    15]
 [   18    10 36412    17]
 [   20    16    23 36257]]
-------------------------------------------------------------------------------------
train_loss : 0.0607
eval_loss : 0.1278
acc : 0.9921, precision : 0.9836, recall : 0.9701, f1_score : 0.9768
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9520    0.9543    0.9532      9674
           1     0.9794    0.9784    0.9789     21515

    accuracy                         0.9709     31189
   macro avg     0.9657    0.9663    0.9660     31189
weighted avg     0.9709    0.9709    0.9709     31189

[[ 9232   442]
 [  465 21050]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9979    0.9983      7745
           1     0.9981    0.9988    0.9985      7789
           2     0.9983    0.9983    0.9983      7869
           3     0.9986    0.9986    0.9986      7786

    accuracy                         0.9984     31189
   macro avg     0.9984    0.9984    0.9984     31189
weighted avg     0.9984    0.9984    0.9984     31189

[[7729    5    6    5]
 [   2 7780    5    2]
 [   6    3 7856    4]
 [   2    7    2 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.18 mins
epoch : 30|30, iter : 200|1138,  loss : 0.0647
epoch : 30|30, iter : 400|1138,  loss : 0.0603
epoch : 30|30, iter : 600|1138,  loss : 0.0615
epoch : 30|30, iter : 800|1138,  loss : 0.0612
epoch : 30|30, iter : 1000|1138,  loss : 0.0596
acc : 0.8262, precision : 0.4981, recall : 0.4950, f1_score : 0.4966
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9780    0.9835    0.9808     45524
           1     0.9925    0.9899    0.9912    100022

    accuracy                         0.9879    145546
   macro avg     0.9853    0.9867    0.9860    145546
weighted avg     0.9880    0.9879    0.9879    145546

[[44774   750]
 [ 1006 99016]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9985    0.9986    0.9986     36457
           1     0.9989    0.9984    0.9987     36316
           2     0.9983    0.9988    0.9985     36457
           3     0.9984    0.9984    0.9984     36316

    accuracy                         0.9986    145546
   macro avg     0.9986    0.9986    0.9986    145546
weighted avg     0.9986    0.9986    0.9986    145546

[[36405    12    19    21]
 [   18 36258    21    19]
 [   16    11 36413    17]
 [   19    16    22 36259]]
-------------------------------------------------------------------------------------
train_loss : 0.0596
eval_loss : 0.1261
acc : 0.9917, precision : 0.9729, recall : 0.9787, f1_score : 0.9758
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9510    0.9565    0.9537      9674
           1     0.9804    0.9778    0.9791     21515

    accuracy                         0.9712     31189
   macro avg     0.9657    0.9672    0.9664     31189
weighted avg     0.9713    0.9712    0.9712     31189

[[ 9253   421]
 [  477 21038]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9977    0.9985    0.9981      7745
           1     0.9981    0.9987    0.9984      7789
           2     0.9989    0.9977    0.9983      7869
           3     0.9986    0.9983    0.9985      7786

    accuracy                         0.9983     31189
   macro avg     0.9983    0.9983    0.9983     31189
weighted avg     0.9983    0.9983    0.9983     31189

[[7733    5    2    5]
 [   3 7779    5    2]
 [  11    3 7851    4]
 [   4    7    2 7773]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.09 mins
