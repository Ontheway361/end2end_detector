----------------Environment Versions----------------
- Python    : 3.7.3 
- PyTorch   : 1.1.0
- TorchVison: 0.3.0
- GPU_device: True
----------------------------------------------------
Parallel mode was going ...
Model loading was finished ...
After data augmentation, 72773 rows added.
After data augmentation,   0 rows added.
Data loading was finished ...
epoch :  1|30, iter : 200|1138,  loss : 0.9989
epoch :  1|30, iter : 400|1138,  loss : 0.7228
epoch :  1|30, iter : 600|1138,  loss : 0.5884
epoch :  1|30, iter : 800|1138,  loss : 0.5070
epoch :  1|30, iter : 1000|1138,  loss : 0.4515
acc : 0.9575, precision : 0.9120, recall : 0.8343, f1_score : 0.8714
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.7194    0.8534    0.7807     45524
           1     0.9271    0.8485    0.8860    100022

    accuracy                         0.8500    145546
   macro avg     0.8232    0.8509    0.8334    145546
weighted avg     0.8621    0.8500    0.8531    145546

[[38849  6675]
 [15154 84868]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9677    0.9693    0.9685     36457
           1     0.9764    0.9654    0.9709     36316
           2     0.9661    0.9699    0.9680     36457
           3     0.9641    0.9695    0.9668     36316

    accuracy                         0.9685    145546
   macro avg     0.9686    0.9685    0.9685    145546
weighted avg     0.9685    0.9685    0.9685    145546

[[35337   206   565   349]
 [  320 35060   344   592]
 [  524   205 35359   369]
 [  337   438   333 35208]]
-------------------------------------------------------------------------------------
train_loss : 0.4218
eval_loss : 0.2046
acc : 0.9775, precision : 0.9782, recall : 0.8877, f1_score : 0.9307
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8860    0.9321    0.9085      9674
           1     0.9687    0.9461    0.9573     21515

    accuracy                         0.9417     31189
   macro avg     0.9274    0.9391    0.9329     31189
weighted avg     0.9431    0.9417    0.9421     31189

[[ 9017   657]
 [ 1160 20355]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9892    0.9978    0.9935      7745
           1     0.9945    0.9947    0.9946      7789
           2     0.9953    0.9944    0.9949      7869
           3     0.9981    0.9901    0.9941      7786

    accuracy                         0.9943     31189
   macro avg     0.9943    0.9943    0.9943     31189
weighted avg     0.9943    0.9943    0.9943     31189

[[7728   10    3    4]
 [  22 7748   13    6]
 [  30    9 7825    5]
 [  32   24   21 7709]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.43 mins
**************** | sota | loss : 0.2046 | f1_score : 0.9307 | ****************
epoch :  2|30, iter : 200|1138,  loss : 0.2013
epoch :  2|30, iter : 400|1138,  loss : 0.1922
epoch :  2|30, iter : 600|1138,  loss : 0.1865
epoch :  2|30, iter : 800|1138,  loss : 0.1844
epoch :  2|30, iter : 1000|1138,  loss : 0.1803
acc : 0.9852, precision : 0.9727, recall : 0.9404, f1_score : 0.9563
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8898    0.9511    0.9194     45524
           1     0.9770    0.9464    0.9615    100022

    accuracy                         0.9479    145546
   macro avg     0.9334    0.9488    0.9404    145546
weighted avg     0.9497    0.9479    0.9483    145546

[[43300  2224]
 [ 5365 94657]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9939    0.9941    0.9940     36457
           1     0.9942    0.9942    0.9942     36316
           2     0.9937    0.9940    0.9939     36457
           3     0.9944    0.9940    0.9942     36316

    accuracy                         0.9941    145546
   macro avg     0.9941    0.9941    0.9941    145546
weighted avg     0.9941    0.9941    0.9941    145546

[[36242    44   123    48]
 [   49 36104    54   109]
 [  125    47 36237    48]
 [   47   119    51 36099]]
-------------------------------------------------------------------------------------
train_loss : 0.1797
eval_loss : 0.3333
acc : 0.9766, precision : 0.9848, recall : 0.8762, f1_score : 0.9273
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8396    0.9779    0.9035      9674
           1     0.9893    0.9160    0.9512     21515

    accuracy                         0.9352     31189
   macro avg     0.9144    0.9469    0.9274     31189
weighted avg     0.9428    0.9352    0.9364     31189

[[ 9460   214]
 [ 1807 19708]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9569    0.9977    0.9769      7745
           1     0.9985    0.8468    0.9164      7789
           2     0.8605    0.9953    0.9230      7869
           3     0.9926    0.9441    0.9677      7786

    accuracy                         0.9460     31189
   macro avg     0.9521    0.9460    0.9460     31189
weighted avg     0.9519    0.9460    0.9459     31189

[[7727    4   10    4]
 [ 215 6596  931   47]
 [  30    3 7832    4]
 [ 103    3  329 7351]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.14 mins
epoch :  3|30, iter : 200|1138,  loss : 0.1691
epoch :  3|30, iter : 400|1138,  loss : 0.1658
epoch :  3|30, iter : 600|1138,  loss : 0.1621
epoch :  3|30, iter : 800|1138,  loss : 0.1603
epoch :  3|30, iter : 1000|1138,  loss : 0.1576
acc : 0.9879, precision : 0.9768, recall : 0.9523, f1_score : 0.9644
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9054    0.9581    0.9310     45524
           1     0.9804    0.9544    0.9672    100022

    accuracy                         0.9556    145546
   macro avg     0.9429    0.9562    0.9491    145546
weighted avg     0.9569    0.9556    0.9559    145546

[[43615  1909]
 [ 4558 95464]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9945    0.9948    0.9946     36457
           1     0.9947    0.9944    0.9946     36316
           2     0.9941    0.9948    0.9944     36457
           3     0.9949    0.9942    0.9945     36316

    accuracy                         0.9945    145546
   macro avg     0.9945    0.9945    0.9945    145546
weighted avg     0.9945    0.9945    0.9945    145546

[[36267    30   120    40]
 [   40 36114    49   113]
 [  113    46 36266    32]
 [   49   117    46 36104]]
-------------------------------------------------------------------------------------
train_loss : 0.1579
eval_loss : 0.1858
acc : 0.9868, precision : 0.9511, recall : 0.9727, f1_score : 0.9618
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8860    0.9453    0.9147      9674
           1     0.9746    0.9453    0.9597     21515

    accuracy                         0.9453     31189
   macro avg     0.9303    0.9453    0.9372     31189
weighted avg     0.9471    0.9453    0.9458     31189

[[ 9145   529]
 [ 1177 20338]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9906    0.9979    0.9943      7745
           1     0.9950    0.9968    0.9959      7789
           2     0.9981    0.9910    0.9945      7869
           3     0.9972    0.9952    0.9962      7786

    accuracy                         0.9952     31189
   macro avg     0.9952    0.9952    0.9952     31189
weighted avg     0.9952    0.9952    0.9952     31189

[[7729    5    5    6]
 [  10 7764    7    8]
 [  58    5 7798    8]
 [   5   29    3 7749]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.09 mins
**************** | sota | loss : 0.1858 | f1_score : 0.9618 | ****************
epoch :  4|30, iter : 200|1138,  loss : 0.1470
epoch :  4|30, iter : 400|1138,  loss : 0.1439
epoch :  4|30, iter : 600|1138,  loss : 0.1453
epoch :  4|30, iter : 800|1138,  loss : 0.1470
epoch :  4|30, iter : 1000|1138,  loss : 0.1472
acc : 0.9886, precision : 0.9780, recall : 0.9552, f1_score : 0.9665
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9105    0.9599    0.9345     45524
           1     0.9813    0.9571    0.9690    100022

    accuracy                         0.9579    145546
   macro avg     0.9459    0.9585    0.9518    145546
weighted avg     0.9591    0.9579    0.9582    145546

[[43697  1827]
 [ 4294 95728]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9957    0.9957    0.9957     36457
           1     0.9957    0.9956    0.9957     36316
           2     0.9951    0.9959    0.9955     36457
           3     0.9960    0.9954    0.9957     36316

    accuracy                         0.9956    145546
   macro avg     0.9956    0.9956    0.9956    145546
weighted avg     0.9956    0.9956    0.9956    145546

[[36300    31    96    30]
 [   34 36157    42    83]
 [   88    31 36306    32]
 [   35    93    40 36148]]
-------------------------------------------------------------------------------------
train_loss : 0.1464
eval_loss : 0.1964
acc : 0.9848, precision : 0.9897, recall : 0.9204, f1_score : 0.9538
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8313    0.9864    0.9022      9674
           1     0.9933    0.9100    0.9498     21515

    accuracy                         0.9337     31189
   macro avg     0.9123    0.9482    0.9260     31189
weighted avg     0.9430    0.9337    0.9350     31189

[[ 9542   132]
 [ 1937 19578]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9974    0.9921    0.9948      7745
           1     0.9843    0.9987    0.9915      7789
           2     0.9915    0.9895    0.9905      7869
           3     0.9950    0.9877    0.9913      7786

    accuracy                         0.9920     31189
   macro avg     0.9920    0.9920    0.9920     31189
weighted avg     0.9920    0.9920    0.9920     31189

[[7684   22   20   19]
 [   3 7779    5    2]
 [   8   57 7786   18]
 [   9   45   42 7690]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.16 mins
epoch :  5|30, iter : 200|1138,  loss : 0.1413
epoch :  5|30, iter : 400|1138,  loss : 0.1432
epoch :  5|30, iter : 600|1138,  loss : 0.1405
epoch :  5|30, iter : 800|1138,  loss : 0.1417
epoch :  5|30, iter : 1000|1138,  loss : 0.1417
acc : 0.9891, precision : 0.9796, recall : 0.9565, f1_score : 0.9679
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9141    0.9612    0.9370     45524
           1     0.9819    0.9589    0.9702    100022

    accuracy                         0.9596    145546
   macro avg     0.9480    0.9600    0.9536    145546
weighted avg     0.9607    0.9596    0.9599    145546

[[43756  1768]
 [ 4114 95908]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9961    0.9961    0.9961     36457
           1     0.9962    0.9961    0.9962     36316
           2     0.9956    0.9962    0.9959     36457
           3     0.9960    0.9956    0.9958     36316

    accuracy                         0.9960    145546
   macro avg     0.9960    0.9960    0.9960    145546
weighted avg     0.9960    0.9960    0.9960    145546

[[36316    35    76    30]
 [   32 36175    37    72]
 [   72    26 36317    42]
 [   37    77    46 36156]]
-------------------------------------------------------------------------------------
train_loss : 0.1411
eval_loss : 0.2444
acc : 0.9821, precision : 0.9480, recall : 0.9469, f1_score : 0.9475
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.7850    0.9663    0.8663      9674
           1     0.9831    0.8810    0.9293     21515

    accuracy                         0.9075     31189
   macro avg     0.8841    0.9237    0.8978     31189
weighted avg     0.9217    0.9075    0.9097     31189

[[ 9348   326]
 [ 2560 18955]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9815    0.9975    0.9894      7745
           1     0.9965    0.9908    0.9936      7789
           2     0.9943    0.9940    0.9942      7869
           3     0.9986    0.9883    0.9934      7786

    accuracy                         0.9927     31189
   macro avg     0.9927    0.9927    0.9927     31189
weighted avg     0.9927    0.9927    0.9927     31189

[[7726    6    9    4]
 [  55 7717   13    4]
 [  41    3 7822    3]
 [  50   18   23 7695]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.05 mins
epoch :  6|30, iter : 200|1138,  loss : 0.1546
epoch :  6|30, iter : 400|1138,  loss : 0.1418
epoch :  6|30, iter : 600|1138,  loss : 0.1371
epoch :  6|30, iter : 800|1138,  loss : 0.1369
epoch :  6|30, iter : 1000|1138,  loss : 0.1368
acc : 0.9897, precision : 0.9794, recall : 0.9604, f1_score : 0.9698
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9158    0.9623    0.9385     45524
           1     0.9824    0.9597    0.9710    100022

    accuracy                         0.9605    145546
   macro avg     0.9491    0.9610    0.9547    145546
weighted avg     0.9616    0.9605    0.9608    145546

[[43809  1715]
 [ 4028 95994]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9965    0.9966    0.9966     36457
           1     0.9969    0.9968    0.9968     36316
           2     0.9963    0.9965    0.9964     36457
           3     0.9967    0.9964    0.9966     36316

    accuracy                         0.9966    145546
   macro avg     0.9966    0.9966    0.9966    145546
weighted avg     0.9966    0.9966    0.9966    145546

[[36334    28    66    29]
 [   28 36199    30    59]
 [   69    25 36331    32]
 [   31    60    38 36187]]
-------------------------------------------------------------------------------------
train_loss : 0.1359
eval_loss : 0.1436
acc : 0.9872, precision : 0.9752, recall : 0.9490, f1_score : 0.9619
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9131    0.9616    0.9368      9674
           1     0.9823    0.9589    0.9705     21515

    accuracy                         0.9597     31189
   macro avg     0.9477    0.9603    0.9536     31189
weighted avg     0.9609    0.9597    0.9600     31189

[[ 9303   371]
 [  885 20630]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9957    0.9977    0.9967      7745
           1     0.9979    0.9918    0.9948      7789
           2     0.9949    0.9976    0.9963      7869
           3     0.9944    0.9959    0.9951      7786

    accuracy                         0.9957     31189
   macro avg     0.9957    0.9957    0.9957     31189
weighted avg     0.9957    0.9957    0.9957     31189

[[7727    5    9    4]
 [  13 7725   17   34]
 [   9    4 7850    6]
 [  11    7   14 7754]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.25 mins
**************** | sota | loss : 0.1436 | f1_score : 0.9619 | ****************
epoch :  7|30, iter : 200|1138,  loss : 0.1228
epoch :  7|30, iter : 400|1138,  loss : 0.1254
epoch :  7|30, iter : 600|1138,  loss : 0.1285
epoch :  7|30, iter : 800|1138,  loss : 0.1289
epoch :  7|30, iter : 1000|1138,  loss : 0.1285
acc : 0.9898, precision : 0.9813, recall : 0.9593, f1_score : 0.9702
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9185    0.9652    0.9413     45524
           1     0.9838    0.9610    0.9723    100022

    accuracy                         0.9623    145546
   macro avg     0.9511    0.9631    0.9568    145546
weighted avg     0.9634    0.9623    0.9626    145546

[[43938  1586]
 [ 3898 96124]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9971    0.9967    0.9969     36457
           1     0.9971    0.9968    0.9970     36316
           2     0.9966    0.9973    0.9969     36457
           3     0.9971    0.9971    0.9971     36316

    accuracy                         0.9970    145546
   macro avg     0.9970    0.9970    0.9970    145546
weighted avg     0.9970    0.9970    0.9970    145546

[[36336    25    68    28]
 [   31 36201    31    53]
 [   49    25 36357    26]
 [   25    54    26 36211]]
-------------------------------------------------------------------------------------
train_loss : 0.1287
eval_loss : 0.1356
acc : 0.9910, precision : 0.9724, recall : 0.9750, f1_score : 0.9737
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9442    0.9449    0.9446      9674
           1     0.9752    0.9749    0.9751     21515

    accuracy                         0.9656     31189
   macro avg     0.9597    0.9599    0.9598     31189
weighted avg     0.9656    0.9656    0.9656     31189

[[ 9141   533]
 [  540 20975]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9968    0.9975    0.9972      7745
           1     0.9972    0.9961    0.9967      7789
           2     0.9973    0.9970    0.9971      7869
           3     0.9964    0.9970    0.9967      7786

    accuracy                         0.9969     31189
   macro avg     0.9969    0.9969    0.9969     31189
weighted avg     0.9969    0.9969    0.9969     31189

[[7726    8    7    4]
 [   4 7759    9   17]
 [  12    5 7845    7]
 [   9    9    5 7763]]
-------------------------------------------------------------------------------------
Single epoch cost time : 5.98 mins
**************** | sota | loss : 0.1356 | f1_score : 0.9737 | ****************
epoch :  8|30, iter : 200|1138,  loss : 0.1341
epoch :  8|30, iter : 400|1138,  loss : 0.1270
epoch :  8|30, iter : 600|1138,  loss : 0.1241
epoch :  8|30, iter : 800|1138,  loss : 0.1228
epoch :  8|30, iter : 1000|1138,  loss : 0.1237
acc : 0.9902, precision : 0.9819, recall : 0.9607, f1_score : 0.9712
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9202    0.9658    0.9424     45524
           1     0.9841    0.9619    0.9728    100022

    accuracy                         0.9631    145546
   macro avg     0.9521    0.9638    0.9576    145546
weighted avg     0.9641    0.9631    0.9633    145546

[[43967  1557]
 [ 3815 96207]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9970    0.9968    0.9969     36457
           1     0.9972    0.9970    0.9971     36316
           2     0.9966    0.9973    0.9969     36457
           3     0.9971    0.9969    0.9970     36316

    accuracy                         0.9970    145546
   macro avg     0.9970    0.9970    0.9970    145546
weighted avg     0.9970    0.9970    0.9970    145546

[[36341    29    57    30]
 [   27 36207    33    49]
 [   48    26 36357    26]
 [   34    45    33 36204]]
-------------------------------------------------------------------------------------
train_loss : 0.1247
eval_loss : 0.2068
acc : 0.9857, precision : 0.9365, recall : 0.9827, f1_score : 0.9590
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9648    0.8830    0.9221      9674
           1     0.9493    0.9855    0.9671     21515

    accuracy                         0.9537     31189
   macro avg     0.9570    0.9342    0.9446     31189
weighted avg     0.9541    0.9537    0.9531     31189

[[ 8542  1132]
 [  312 21203]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9975    0.9979    0.9977      7745
           1     0.9974    0.9978    0.9976      7789
           2     0.9981    0.9976    0.9978      7869
           3     0.9977    0.9974    0.9976      7786

    accuracy                         0.9977     31189
   macro avg     0.9977    0.9977    0.9977     31189
weighted avg     0.9977    0.9977    0.9977     31189

[[7729    6    5    5]
 [   3 7772    6    8]
 [  11    3 7850    5]
 [   5   11    4 7766]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.11 mins
epoch :  9|30, iter : 200|1138,  loss : 0.1186
epoch :  9|30, iter : 400|1138,  loss : 0.1217
epoch :  9|30, iter : 600|1138,  loss : 0.1203
epoch :  9|30, iter : 800|1138,  loss : 0.1192
epoch :  9|30, iter : 1000|1138,  loss : 0.1189
acc : 0.9908, precision : 0.9833, recall : 0.9628, f1_score : 0.9729
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9251    0.9671    0.9456     45524
           1     0.9847    0.9644    0.9744    100022

    accuracy                         0.9652    145546
   macro avg     0.9549    0.9657    0.9600    145546
weighted avg     0.9660    0.9652    0.9654    145546

[[44024  1500]
 [ 3565 96457]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9973    0.9972    0.9973     36457
           1     0.9976    0.9974    0.9975     36316
           2     0.9971    0.9973    0.9972     36457
           3     0.9974    0.9974    0.9974     36316

    accuracy                         0.9974    145546
   macro avg     0.9974    0.9974    0.9974    145546
weighted avg     0.9974    0.9974    0.9974    145546

[[36355    20    55    27]
 [   23 36223    25    45]
 [   53    22 36360    22]
 [   22    44    27 36223]]
-------------------------------------------------------------------------------------
train_loss : 0.1189
eval_loss : 0.1282
acc : 0.9895, precision : 0.9886, recall : 0.9496, f1_score : 0.9687
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8967    0.9796    0.9363      9674
           1     0.9904    0.9492    0.9694     21515

    accuracy                         0.9587     31189
   macro avg     0.9436    0.9644    0.9529     31189
weighted avg     0.9614    0.9587    0.9591     31189

[[ 9477   197]
 [ 1092 20423]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9972    0.9982    0.9977      7745
           1     0.9932    0.9992    0.9962      7789
           2     0.9990    0.9963    0.9976      7869
           3     0.9982    0.9938    0.9960      7786

    accuracy                         0.9969     31189
   macro avg     0.9969    0.9969    0.9969     31189
weighted avg     0.9969    0.9969    0.9969     31189

[[7731    6    2    6]
 [   1 7783    4    1]
 [  19    3 7840    7]
 [   2   44    2 7738]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.06 mins
epoch : 10|30, iter : 200|1138,  loss : 0.1193
epoch : 10|30, iter : 400|1138,  loss : 0.1155
epoch : 10|30, iter : 600|1138,  loss : 0.1146
epoch : 10|30, iter : 800|1138,  loss : 0.1148
epoch : 10|30, iter : 1000|1138,  loss : 0.1153
acc : 0.9910, precision : 0.9832, recall : 0.9640, f1_score : 0.9735
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9251    0.9689    0.9465     45524
           1     0.9855    0.9643    0.9748    100022

    accuracy                         0.9657    145546
   macro avg     0.9553    0.9666    0.9606    145546
weighted avg     0.9666    0.9657    0.9659    145546

[[44109  1415]
 [ 3573 96449]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9973    0.9973    0.9973     36457
           1     0.9976    0.9976    0.9976     36316
           2     0.9971    0.9975    0.9973     36457
           3     0.9976    0.9972    0.9974     36316

    accuracy                         0.9974    145546
   macro avg     0.9974    0.9974    0.9974    145546
weighted avg     0.9974    0.9974    0.9974    145546

[[36358    21    48    30]
 [   25 36230    26    35]
 [   47    21 36366    23]
 [   28    44    31 36213]]
-------------------------------------------------------------------------------------
train_loss : 0.1170
eval_loss : 0.1659
acc : 0.9836, precision : 0.9192, recall : 0.9910, f1_score : 0.9537
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9619    0.9086    0.9345      9674
           1     0.9599    0.9838    0.9717     21515

    accuracy                         0.9605     31189
   macro avg     0.9609    0.9462    0.9531     31189
weighted avg     0.9605    0.9605    0.9602     31189

[[ 8790   884]
 [  348 21167]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9966    0.9985    0.9975      7745
           1     0.9971    0.9988    0.9979      7789
           2     0.9986    0.9968    0.9977      7869
           3     0.9987    0.9969    0.9978      7786

    accuracy                         0.9978     31189
   macro avg     0.9978    0.9978    0.9978     31189
weighted avg     0.9978    0.9978    0.9978     31189

[[7733    5    3    4]
 [   4 7780    4    1]
 [  14    6 7844    5]
 [   8   12    4 7762]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.01 mins
epoch : 11|30, iter : 200|1138,  loss : 0.1097
epoch : 11|30, iter : 400|1138,  loss : 0.1158
epoch : 11|30, iter : 600|1138,  loss : 0.1137
epoch : 11|30, iter : 800|1138,  loss : 0.1120
epoch : 11|30, iter : 1000|1138,  loss : 0.1130
acc : 0.9913, precision : 0.9842, recall : 0.9648, f1_score : 0.9744
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9290    0.9706    0.9493     45524
           1     0.9863    0.9662    0.9762    100022

    accuracy                         0.9676    145546
   macro avg     0.9577    0.9684    0.9628    145546
weighted avg     0.9684    0.9676    0.9678    145546

[[44184  1340]
 [ 3377 96645]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9974    0.9972    0.9973     36457
           1     0.9976    0.9976    0.9976     36316
           2     0.9970    0.9973    0.9971     36457
           3     0.9974    0.9973    0.9974     36316

    accuracy                         0.9973    145546
   macro avg     0.9973    0.9973    0.9973    145546
weighted avg     0.9973    0.9973    0.9973    145546

[[36355    20    53    29]
 [   19 36229    28    40]
 [   52    23 36357    25]
 [   24    44    29 36219]]
-------------------------------------------------------------------------------------
train_loss : 0.1125
eval_loss : 0.1910
acc : 0.9878, precision : 0.9434, recall : 0.9878, f1_score : 0.9651
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9583    0.8837    0.9195      9674
           1     0.9495    0.9827    0.9658     21515

    accuracy                         0.9520     31189
   macro avg     0.9539    0.9332    0.9427     31189
weighted avg     0.9522    0.9520    0.9514     31189

[[ 8549  1125]
 [  372 21143]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9974    0.9979      7745
           1     0.9974    0.9968    0.9971      7789
           2     0.9981    0.9976    0.9978      7869
           3     0.9962    0.9982    0.9972      7786

    accuracy                         0.9975     31189
   macro avg     0.9975    0.9975    0.9975     31189
weighted avg     0.9975    0.9975    0.9975     31189

[[7725    7    8    5]
 [   2 7764    5   18]
 [   9    3 7850    7]
 [   2   10    2 7772]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.07 mins
epoch : 12|30, iter : 200|1138,  loss : 0.1200
epoch : 12|30, iter : 400|1138,  loss : 0.1132
epoch : 12|30, iter : 600|1138,  loss : 0.1118
epoch : 12|30, iter : 800|1138,  loss : 0.1119
epoch : 12|30, iter : 1000|1138,  loss : 0.1115
acc : 0.9913, precision : 0.9840, recall : 0.9653, f1_score : 0.9746
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9297    0.9699    0.9494     45524
           1     0.9860    0.9666    0.9762    100022

    accuracy                         0.9676    145546
   macro avg     0.9579    0.9683    0.9628    145546
weighted avg     0.9684    0.9676    0.9678    145546

[[44153  1371]
 [ 3338 96684]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9974    0.9975    0.9975     36457
           1     0.9975    0.9976    0.9976     36316
           2     0.9972    0.9974    0.9973     36457
           3     0.9978    0.9974    0.9976     36316

    accuracy                         0.9975    145546
   macro avg     0.9975    0.9975    0.9975    145546
weighted avg     0.9975    0.9975    0.9975    145546

[[36367    20    48    22]
 [   24 36229    27    36]
 [   47    27 36361    22]
 [   23    43    27 36223]]
-------------------------------------------------------------------------------------
train_loss : 0.1116
eval_loss : 0.1199
acc : 0.9902, precision : 0.9791, recall : 0.9627, f1_score : 0.9709
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9226    0.9661    0.9438      9674
           1     0.9844    0.9636    0.9739     21515

    accuracy                         0.9643     31189
   macro avg     0.9535    0.9648    0.9589     31189
weighted avg     0.9653    0.9643    0.9646     31189

[[ 9346   328]
 [  784 20731]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9977    0.9982      7745
           1     0.9962    0.9990    0.9976      7789
           2     0.9989    0.9975    0.9982      7869
           3     0.9979    0.9976    0.9978      7786

    accuracy                         0.9979     31189
   macro avg     0.9979    0.9979    0.9979     31189
weighted avg     0.9979    0.9979    0.9979     31189

[[7727    7    3    8]
 [   1 7781    4    3]
 [   7    8 7849    5]
 [   2   15    2 7767]]
-------------------------------------------------------------------------------------
Single epoch cost time : 5.98 mins
epoch : 13|30, iter : 200|1138,  loss : 0.1095
epoch : 13|30, iter : 400|1138,  loss : 0.1119
epoch : 13|30, iter : 600|1138,  loss : 0.1093
epoch : 13|30, iter : 800|1138,  loss : 0.1089
epoch : 13|30, iter : 1000|1138,  loss : 0.1091
acc : 0.9912, precision : 0.9848, recall : 0.9635, f1_score : 0.9741
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9291    0.9716    0.9499     45524
           1     0.9868    0.9662    0.9764    100022

    accuracy                         0.9679    145546
   macro avg     0.9579    0.9689    0.9631    145546
weighted avg     0.9687    0.9679    0.9681    145546

[[44232  1292]
 [ 3377 96645]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9976    0.9978    0.9977     36457
           1     0.9980    0.9977    0.9979     36316
           2     0.9973    0.9977    0.9975     36457
           3     0.9979    0.9975    0.9977     36316

    accuracy                         0.9977    145546
   macro avg     0.9977    0.9977    0.9977    145546
weighted avg     0.9977    0.9977    0.9977    145546

[[36377    17    42    21]
 [   23 36234    26    33]
 [   45    16 36372    24]
 [   18    41    30 36227]]
-------------------------------------------------------------------------------------
train_loss : 0.1094
eval_loss : 0.1272
acc : 0.9892, precision : 0.9822, recall : 0.9539, f1_score : 0.9678
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9054    0.9690    0.9361      9674
           1     0.9856    0.9545    0.9698     21515

    accuracy                         0.9590     31189
   macro avg     0.9455    0.9617    0.9530     31189
weighted avg     0.9607    0.9590    0.9594     31189

[[ 9374   300]
 [  979 20536]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9957    0.9972      7745
           1     0.9976    0.9982    0.9979      7789
           2     0.9948    0.9983    0.9966      7869
           3     0.9983    0.9969    0.9976      7786

    accuracy                         0.9973     31189
   macro avg     0.9973    0.9973    0.9973     31189
weighted avg     0.9973    0.9973    0.9973     31189

[[7712    5   24    4]
 [   3 7775    6    5]
 [   6    3 7856    4]
 [   2   11   11 7762]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.04 mins
