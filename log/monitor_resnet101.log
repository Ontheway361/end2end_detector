----------------Environment Versions----------------
- Python: 3.7.3 
- PyTorch: 1.1.0
- TorchVison: 0.3.0
- device: True
----------------------------------------------------
Parallel mode was going ...
Model loading was finished ...
Data loading was finished ...
epoch :  1|20, iter :  60|334,  loss : 2.0026
epoch :  1|20, iter : 120|334,  loss : 1.4010
epoch :  1|20, iter : 180|334,  loss : 1.1332
epoch :  1|20, iter : 240|334,  loss : 0.9776
epoch :  1|20, iter : 300|334,  loss : 0.8656
acc : 0.9086, precision : 0.7101, recall : 0.8013, f1_score : 0.7529
train_loss : 0.8163
eval_loss : 0.3494
acc : 0.9661, precision : 0.8625, recall : 0.9583, f1_score : 0.9079
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.7948    0.7818    0.7883      5629
           1     0.9037    0.9103    0.9070     12665

    accuracy                         0.8708     18294
   macro avg     0.8493    0.8461    0.8476     18294
weighted avg     0.8702    0.8708    0.8705     18294

[[ 4401  1228]
 [ 1136 11529]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9769    0.9936    0.9852      4564
           1     0.9878    0.9941    0.9910      4574
           2     0.9903    0.9771    0.9836      4578
           3     0.9954    0.9854    0.9903      4578

    accuracy                         0.9875     18294
   macro avg     0.9876    0.9875    0.9875     18294
weighted avg     0.9876    0.9875    0.9875     18294

[[4535    5   18    6]
 [  13 4547    9    5]
 [  88    7 4473   10]
 [   6   44   17 4511]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.52 mins
----------------new sota was found----------------
epoch :  2|20, iter :  60|334,  loss : 0.3329
epoch :  2|20, iter : 120|334,  loss : 0.3197
epoch :  2|20, iter : 180|334,  loss : 0.3040
epoch :  2|20, iter : 240|334,  loss : 0.2933
epoch :  2|20, iter : 300|334,  loss : 0.2877
acc : 0.9739, precision : 0.9191, recall : 0.9315, f1_score : 0.9253
train_loss : 0.2852
eval_loss : 0.3776
acc : 0.9624, precision : 0.8362, recall : 0.9756, f1_score : 0.9005
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9395    0.7010    0.8029      5629
           1     0.8806    0.9799    0.9276     12665

    accuracy                         0.8941     18294
   macro avg     0.9101    0.8405    0.8653     18294
weighted avg     0.8987    0.8941    0.8892     18294

[[ 3946  1683]
 [  254 12411]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9109    0.9991    0.9530      4564
           1     0.9946    0.9657    0.9799      4574
           2     0.9920    0.9498    0.9704      4578
           3     0.9960    0.9712    0.9834      4578

    accuracy                         0.9714     18294
   macro avg     0.9734    0.9714    0.9717     18294
weighted avg     0.9734    0.9714    0.9717     18294

[[4560    1    1    2]
 [ 122 4417   23   12]
 [ 224    2 4348    4]
 [ 100   21   11 4446]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.41 mins
epoch :  3|20, iter :  60|334,  loss : 0.2214
epoch :  3|20, iter : 120|334,  loss : 0.2184
epoch :  3|20, iter : 180|334,  loss : 0.2209
epoch :  3|20, iter : 240|334,  loss : 0.2168
epoch :  3|20, iter : 300|334,  loss : 0.2117
acc : 0.9819, precision : 0.9464, recall : 0.9494, f1_score : 0.9479
train_loss : 0.2100
eval_loss : 0.2146
acc : 0.9821, precision : 0.9748, recall : 0.9211, f1_score : 0.9472
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9048    0.8863    0.8955      5629
           1     0.9499    0.9585    0.9542     12665

    accuracy                         0.9363     18294
   macro avg     0.9274    0.9224    0.9248     18294
weighted avg     0.9360    0.9363    0.9361     18294

[[ 4989   640]
 [  525 12140]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9958    0.9910    0.9934      4564
           1     0.9969    0.9871    0.9920      4574
           2     0.9887    0.9958    0.9923      4578
           3     0.9894    0.9967    0.9930      4578

    accuracy                         0.9927     18294
   macro avg     0.9927    0.9927    0.9927     18294
weighted avg     0.9927    0.9927    0.9927     18294

[[4523    7   27    7]
 [   1 4515   17   41]
 [  16    2 4559    1]
 [   2    5    8 4563]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.41 mins
----------------new sota was found----------------
epoch :  4|20, iter :  60|334,  loss : 0.1664
epoch :  4|20, iter : 120|334,  loss : 0.1705
epoch :  4|20, iter : 180|334,  loss : 0.1725
epoch :  4|20, iter : 240|334,  loss : 0.1731
epoch :  4|20, iter : 300|334,  loss : 0.1750
acc : 0.9852, precision : 0.9536, recall : 0.9618, f1_score : 0.9577
train_loss : 0.1782
eval_loss : 0.2853
acc : 0.9813, precision : 0.9363, recall : 0.9577, f1_score : 0.9469
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8015    0.9535    0.8709      5629
           1     0.9774    0.8951    0.9344     12665

    accuracy                         0.9130     18294
   macro avg     0.8895    0.9243    0.9027     18294
weighted avg     0.9233    0.9130    0.9149     18294

[[ 5367   262]
 [ 1329 11336]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9622    0.9993    0.9804      4564
           1     0.9975    0.9766    0.9870      4574
           2     0.9969    0.9847    0.9908      4578
           3     0.9912    0.9860    0.9886      4578

    accuracy                         0.9867     18294
   macro avg     0.9870    0.9867    0.9867     18294
weighted avg     0.9870    0.9867    0.9867     18294

[[4561    1    1    1]
 [  76 4467    0   31]
 [  58    4 4508    8]
 [  45    6   13 4514]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.39 mins
epoch :  5|20, iter :  60|334,  loss : 0.1526
epoch :  5|20, iter : 120|334,  loss : 0.1565
epoch :  5|20, iter : 180|334,  loss : 0.1640
epoch :  5|20, iter : 240|334,  loss : 0.1630
epoch :  5|20, iter : 300|334,  loss : 0.1618
acc : 0.9875, precision : 0.9620, recall : 0.9663, f1_score : 0.9641
train_loss : 0.1651
eval_loss : 0.1899
acc : 0.9875, precision : 0.9649, recall : 0.9634, f1_score : 0.9641
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9014    0.9305    0.9157      5629
           1     0.9687    0.9548    0.9617     12665

    accuracy                         0.9473     18294
   macro avg     0.9350    0.9426    0.9387     18294
weighted avg     0.9480    0.9473    0.9475     18294

[[ 5238   391]
 [  573 12092]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9961    0.9950    0.9955      4564
           1     0.9924    0.9980    0.9952      4574
           2     0.9972    0.9948    0.9960      4578
           3     0.9963    0.9941    0.9952      4578

    accuracy                         0.9955     18294
   macro avg     0.9955    0.9955    0.9955     18294
weighted avg     0.9955    0.9955    0.9955     18294

[[4541   13    6    4]
 [   3 4565    2    4]
 [   9    6 4554    9]
 [   6   16    5 4551]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.38 mins
----------------new sota was found----------------
epoch :  6|20, iter :  60|334,  loss : 0.1526
epoch :  6|20, iter : 120|334,  loss : 0.1523
epoch :  6|20, iter : 180|334,  loss : 0.1470
epoch :  6|20, iter : 240|334,  loss : 0.1517
epoch :  6|20, iter : 300|334,  loss : 0.1548
acc : 0.9876, precision : 0.9620, recall : 0.9667, f1_score : 0.9644
train_loss : 0.1555
eval_loss : 0.2030
acc : 0.9809, precision : 0.9095, recall : 0.9887, f1_score : 0.9475
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9460    0.8721    0.9076      5629
           1     0.9451    0.9779    0.9612     12665

    accuracy                         0.9453     18294
   macro avg     0.9455    0.9250    0.9344     18294
weighted avg     0.9454    0.9453    0.9447     18294

[[ 4909   720]
 [  280 12385]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9610    0.9996    0.9799      4564
           1     0.9989    0.9930    0.9959      4574
           2     0.9953    0.9692    0.9821      4578
           3     0.9982    0.9904    0.9943      4578

    accuracy                         0.9880     18294
   macro avg     0.9884    0.9880    0.9881     18294
weighted avg     0.9884    0.9880    0.9881     18294

[[4562    1    1    0]
 [  13 4542   12    7]
 [ 139    1 4437    1]
 [  33    3    8 4534]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.39 mins
epoch :  7|20, iter :  60|334,  loss : 0.1568
epoch :  7|20, iter : 120|334,  loss : 0.1521
epoch :  7|20, iter : 180|334,  loss : 0.1530
epoch :  7|20, iter : 240|334,  loss : 0.1538
epoch :  7|20, iter : 300|334,  loss : 0.1547
acc : 0.9883, precision : 0.9653, recall : 0.9672, f1_score : 0.9663
train_loss : 0.1551
eval_loss : 0.2134
acc : 0.9823, precision : 0.9482, recall : 0.9508, f1_score : 0.9495
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9299    0.8716    0.8998      5629
           1     0.9445    0.9708    0.9574     12665

    accuracy                         0.9403     18294
   macro avg     0.9372    0.9212    0.9286     18294
weighted avg     0.9400    0.9403    0.9397     18294

[[ 4906   723]
 [  370 12295]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9796    0.9982    0.9888      4564
           1     0.9796    0.9996    0.9895      4574
           2     0.9982    0.9753    0.9866      4578
           3     0.9993    0.9830    0.9911      4578

    accuracy                         0.9890     18294
   macro avg     0.9892    0.9890    0.9890     18294
weighted avg     0.9892    0.9890    0.9890     18294

[[4556    2    5    1]
 [   2 4572    0    0]
 [  47   64 4465    2]
 [  46   29    3 4500]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.37 mins
epoch :  8|20, iter :  60|334,  loss : 0.1281
epoch :  8|20, iter : 120|334,  loss : 0.1352
epoch :  8|20, iter : 180|334,  loss : 0.1428
epoch :  8|20, iter : 240|334,  loss : 0.1487
epoch :  8|20, iter : 300|334,  loss : 0.1487
acc : 0.9879, precision : 0.9652, recall : 0.9653, f1_score : 0.9653
train_loss : 0.1498
eval_loss : 0.1827
acc : 0.9861, precision : 0.9441, recall : 0.9781, f1_score : 0.9608
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9045    0.9288    0.9165      5629
           1     0.9680    0.9564    0.9622     12665

    accuracy                         0.9479     18294
   macro avg     0.9362    0.9426    0.9393     18294
weighted avg     0.9484    0.9479    0.9481     18294

[[ 5228   401]
 [  552 12113]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9934    0.9915    0.9924      4564
           1     0.9877    0.9985    0.9930      4574
           2     0.9873    0.9993    0.9933      4578
           3     0.9998    0.9786    0.9891      4578

    accuracy                         0.9920     18294
   macro avg     0.9920    0.9920    0.9920     18294
weighted avg     0.9920    0.9920    0.9920     18294

[[4525   11   28    0]
 [   4 4567    3    0]
 [   1    1 4575    1]
 [  25   45   28 4480]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.34 mins
----------------new sota was found----------------
epoch :  9|20, iter :  60|334,  loss : 0.1266
epoch :  9|20, iter : 120|334,  loss : 0.1314
epoch :  9|20, iter : 180|334,  loss : 0.1388
epoch :  9|20, iter : 240|334,  loss : 0.1393
epoch :  9|20, iter : 300|334,  loss : 0.1382
acc : 0.9887, precision : 0.9671, recall : 0.9680, f1_score : 0.9676
train_loss : 0.1392
eval_loss : 0.2210
acc : 0.9814, precision : 0.9766, recall : 0.9151, f1_score : 0.9449
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8431    0.9677    0.9011      5629
           1     0.9846    0.9199    0.9512     12665

    accuracy                         0.9346     18294
   macro avg     0.9138    0.9438    0.9261     18294
weighted avg     0.9411    0.9346    0.9358     18294

[[ 5447   182]
 [ 1014 11651]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9783    0.9982    0.9882      4564
           1     0.9982    0.9948    0.9965      4574
           2     0.9969    0.9886    0.9928      4578
           3     0.9978    0.9893    0.9935      4578

    accuracy                         0.9927     18294
   macro avg     0.9928    0.9927    0.9927     18294
weighted avg     0.9928    0.9927    0.9927     18294

[[4556    1    7    0]
 [  11 4550    4    9]
 [  50    1 4526    1]
 [  40    6    3 4529]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.37 mins
epoch : 10|20, iter :  60|334,  loss : 0.1514
epoch : 10|20, iter : 120|334,  loss : 0.1380
epoch : 10|20, iter : 180|334,  loss : 0.1377
epoch : 10|20, iter : 240|334,  loss : 0.1387
epoch : 10|20, iter : 300|334,  loss : 0.1389
acc : 0.9892, precision : 0.9684, recall : 0.9694, f1_score : 0.9689
train_loss : 0.1390
eval_loss : 0.2416
acc : 0.9805, precision : 0.9733, recall : 0.9132, f1_score : 0.9423
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9280    0.9019    0.9148      5629
           1     0.9570    0.9689    0.9629     12665

    accuracy                         0.9483     18294
   macro avg     0.9425    0.9354    0.9388     18294
weighted avg     0.9480    0.9483    0.9481     18294

[[ 5077   552]
 [  394 12271]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9627    0.9614    0.9621      4564
           1     0.9587    0.9886    0.9734      4574
           2     0.9998    0.9255    0.9612      4578
           3     0.9563    0.9987    0.9770      4578

    accuracy                         0.9686     18294
   macro avg     0.9694    0.9686    0.9684     18294
weighted avg     0.9694    0.9686    0.9684     18294

[[4388  118    1   57]
 [   1 4522    0   51]
 [ 168   72 4237  101]
 [   1    5    0 4572]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.31 mins
epoch : 11|20, iter :  60|334,  loss : 0.1078
epoch : 11|20, iter : 120|334,  loss : 0.1015
epoch : 11|20, iter : 180|334,  loss : 0.1009
epoch : 11|20, iter : 240|334,  loss : 0.0995
epoch : 11|20, iter : 300|334,  loss : 0.0995
acc : 0.9924, precision : 0.9774, recall : 0.9790, f1_score : 0.9782
train_loss : 0.1003
eval_loss : 0.1325
acc : 0.9887, precision : 0.9844, recall : 0.9505, f1_score : 0.9672
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9234    0.9503    0.9366      5629
           1     0.9776    0.9649    0.9712     12665

    accuracy                         0.9604     18294
   macro avg     0.9505    0.9576    0.9539     18294
weighted avg     0.9609    0.9604    0.9606     18294

[[ 5349   280]
 [  444 12221]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9991    0.9985    0.9988      4564
           1     0.9985    0.9991    0.9988      4574
           2     0.9985    0.9987    0.9986      4578
           3     0.9989    0.9987    0.9988      4578

    accuracy                         0.9987     18294
   macro avg     0.9987    0.9987    0.9987     18294
weighted avg     0.9987    0.9987    0.9987     18294

[[4557    1    6    0]
 [   1 4570    1    2]
 [   1    2 4572    3]
 [   2    4    0 4572]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.31 mins
----------------new sota was found----------------
epoch : 12|20, iter :  60|334,  loss : 0.0747
epoch : 12|20, iter : 120|334,  loss : 0.0815
epoch : 12|20, iter : 180|334,  loss : 0.0878
epoch : 12|20, iter : 240|334,  loss : 0.0895
epoch : 12|20, iter : 300|334,  loss : 0.0912
acc : 0.9934, precision : 0.9807, recall : 0.9811, f1_score : 0.9809
train_loss : 0.0931
eval_loss : 0.1465
acc : 0.9895, precision : 0.9618, recall : 0.9787, f1_score : 0.9702
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9475    0.9078    0.9272      5629
           1     0.9598    0.9777    0.9686     12665

    accuracy                         0.9562     18294
   macro avg     0.9536    0.9427    0.9479     18294
weighted avg     0.9560    0.9562    0.9559     18294

[[ 5110   519]
 [  283 12382]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9972    0.9987    0.9979      4564
           1     0.9989    0.9906    0.9947      4574
           2     0.9996    0.9963    0.9979      4578
           3     0.9888    0.9987    0.9937      4578

    accuracy                         0.9961     18294
   macro avg     0.9961    0.9961    0.9961     18294
weighted avg     0.9961    0.9961    0.9961     18294

[[4558    1    1    4]
 [   2 4531    0   41]
 [   9    1 4561    7]
 [   2    3    1 4572]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.35 mins
epoch : 13|20, iter :  60|334,  loss : 0.0861
epoch : 13|20, iter : 120|334,  loss : 0.0800
epoch : 13|20, iter : 180|334,  loss : 0.0853
epoch : 13|20, iter : 240|334,  loss : 0.0900
epoch : 13|20, iter : 300|334,  loss : 0.0931
acc : 0.9928, precision : 0.9787, recall : 0.9800, f1_score : 0.9794
train_loss : 0.0939
eval_loss : 0.1371
acc : 0.9881, precision : 0.9539, recall : 0.9793, f1_score : 0.9665
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9346    0.9266    0.9306      5629
           1     0.9675    0.9712    0.9693     12665

    accuracy                         0.9575     18294
   macro avg     0.9511    0.9489    0.9500     18294
weighted avg     0.9574    0.9575    0.9574     18294

[[ 5216   413]
 [  365 12300]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9972    0.9985    0.9978      4564
           1     0.9980    0.9963    0.9972      4574
           2     0.9989    0.9972    0.9980      4578
           3     0.9956    0.9978    0.9967      4578

    accuracy                         0.9974     18294
   macro avg     0.9974    0.9974    0.9974     18294
weighted avg     0.9974    0.9974    0.9974     18294

[[4557    1    5    1]
 [   6 4557    0   11]
 [   4    1 4565    8]
 [   3    7    0 4568]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.31 mins
epoch : 14|20, iter :  60|334,  loss : 0.0748
epoch : 14|20, iter : 120|334,  loss : 0.0821
epoch : 14|20, iter : 180|334,  loss : 0.0815
epoch : 14|20, iter : 240|334,  loss : 0.0872
epoch : 14|20, iter : 300|334,  loss : 0.0905
acc : 0.9928, precision : 0.9787, recall : 0.9796, f1_score : 0.9792
train_loss : 0.0913
eval_loss : 0.1425
acc : 0.9892, precision : 0.9612, recall : 0.9775, f1_score : 0.9693
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9411    0.9204    0.9307      5629
           1     0.9650    0.9744    0.9697     12665

    accuracy                         0.9578     18294
   macro avg     0.9531    0.9474    0.9502     18294
weighted avg     0.9576    0.9578    0.9577     18294

[[ 5181   448]
 [  324 12341]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9958    0.9974    0.9966      4564
           1     0.9959    0.9991    0.9975      4574
           2     0.9982    0.9961    0.9972      4578
           3     0.9976    0.9950    0.9963      4578

    accuracy                         0.9969     18294
   macro avg     0.9969    0.9969    0.9969     18294
weighted avg     0.9969    0.9969    0.9969     18294

[[4552    6    3    3]
 [   3 4570    0    1]
 [   6    5 4560    7]
 [  10    8    5 4555]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.33 mins
epoch : 15|20, iter :  60|334,  loss : 0.0764
epoch : 15|20, iter : 120|334,  loss : 0.0732
epoch : 15|20, iter : 180|334,  loss : 0.0775
epoch : 15|20, iter : 240|334,  loss : 0.0815
epoch : 15|20, iter : 300|334,  loss : 0.0841
acc : 0.9935, precision : 0.9797, recall : 0.9829, f1_score : 0.9813
train_loss : 0.0854
eval_loss : 0.1442
acc : 0.9896, precision : 0.9636, recall : 0.9775, f1_score : 0.9705
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9548    0.9037    0.9285      5629
           1     0.9582    0.9810    0.9695     12665

    accuracy                         0.9572     18294
   macro avg     0.9565    0.9423    0.9490     18294
weighted avg     0.9571    0.9572    0.9569     18294

[[ 5087   542]
 [  241 12424]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9976    0.9982    0.9979      4564
           1     0.9948    0.9983    0.9965      4574
           2     0.9965    0.9983    0.9974      4578
           3     0.9993    0.9934    0.9964      4578

    accuracy                         0.9970     18294
   macro avg     0.9971    0.9970    0.9970     18294
weighted avg     0.9971    0.9970    0.9970     18294

[[4556    3    5    0]
 [   5 4566    2    1]
 [   3    3 4570    2]
 [   3   18    9 4548]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.31 mins
epoch : 16|20, iter :  60|334,  loss : 0.0852
epoch : 16|20, iter : 120|334,  loss : 0.0885
epoch : 16|20, iter : 180|334,  loss : 0.0842
epoch : 16|20, iter : 240|334,  loss : 0.0840
epoch : 16|20, iter : 300|334,  loss : 0.0842
acc : 0.9930, precision : 0.9794, recall : 0.9805, f1_score : 0.9799
train_loss : 0.0855
eval_loss : 0.1360
acc : 0.9896, precision : 0.9789, recall : 0.9609, f1_score : 0.9698
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9219    0.9451    0.9333      5629
           1     0.9753    0.9644    0.9698     12665

    accuracy                         0.9585     18294
   macro avg     0.9486    0.9547    0.9516     18294
weighted avg     0.9589    0.9585    0.9586     18294

[[ 5320   309]
 [  451 12214]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9982    0.9982      4564
           1     0.9965    0.9991    0.9978      4574
           2     0.9991    0.9985    0.9988      4578
           3     0.9996    0.9976    0.9986      4578

    accuracy                         0.9984     18294
   macro avg     0.9984    0.9984    0.9984     18294
weighted avg     0.9984    0.9984    0.9984     18294

[[4556    5    3    0]
 [   2 4570    1    1]
 [   4    2 4571    1]
 [   2    9    0 4567]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.30 mins
epoch : 17|20, iter :  60|334,  loss : 0.0807
epoch : 17|20, iter : 120|334,  loss : 0.0838
epoch : 17|20, iter : 180|334,  loss : 0.0858
epoch : 17|20, iter : 240|334,  loss : 0.0859
epoch : 17|20, iter : 300|334,  loss : 0.0854
acc : 0.9938, precision : 0.9817, recall : 0.9825, f1_score : 0.9821
train_loss : 0.0867
eval_loss : 0.1635
acc : 0.9885, precision : 0.9668, recall : 0.9674, f1_score : 0.9671
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9531    0.8840    0.9172      5629
           1     0.9500    0.9807    0.9651     12665

    accuracy                         0.9509     18294
   macro avg     0.9516    0.9323    0.9412     18294
weighted avg     0.9510    0.9509    0.9504     18294

[[ 4976   653]
 [  245 12420]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9958    0.9987    0.9973      4564
           1     0.9982    0.9954    0.9968      4574
           2     0.9965    0.9989    0.9977      4578
           3     0.9978    0.9954    0.9966      4578

    accuracy                         0.9971     18294
   macro avg     0.9971    0.9971    0.9971     18294
weighted avg     0.9971    0.9971    0.9971     18294

[[4558    1    5    0]
 [  11 4553    1    9]
 [   3    1 4573    1]
 [   5    6   10 4557]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.33 mins
epoch : 18|20, iter :  60|334,  loss : 0.0801
epoch : 18|20, iter : 120|334,  loss : 0.0731
epoch : 18|20, iter : 180|334,  loss : 0.0769
epoch : 18|20, iter : 240|334,  loss : 0.0784
epoch : 18|20, iter : 300|334,  loss : 0.0820
acc : 0.9934, precision : 0.9798, recall : 0.9822, f1_score : 0.9810
train_loss : 0.0828
eval_loss : 0.1601
acc : 0.9850, precision : 0.9284, recall : 0.9903, f1_score : 0.9583
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9617    0.8776    0.9177      5629
           1     0.9476    0.9844    0.9657     12665

    accuracy                         0.9516     18294
   macro avg     0.9546    0.9310    0.9417     18294
weighted avg     0.9519    0.9516    0.9509     18294

[[ 4940   689]
 [  197 12468]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9991    0.9978    0.9985      4564
           1     0.9965    0.9993    0.9979      4574
           2     0.9987    0.9983    0.9985      4578
           3     0.9985    0.9974    0.9979      4578

    accuracy                         0.9982     18294
   macro avg     0.9982    0.9982    0.9982     18294
weighted avg     0.9982    0.9982    0.9982     18294

[[4554    3    5    2]
 [   1 4571    0    2]
 [   1    4 4570    3]
 [   2    9    1 4566]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.31 mins
epoch : 19|20, iter :  60|334,  loss : 0.0547
epoch : 19|20, iter : 120|334,  loss : 0.0558
epoch : 19|20, iter : 180|334,  loss : 0.0533
epoch : 19|20, iter : 240|334,  loss : 0.0521
epoch : 19|20, iter : 300|334,  loss : 0.0514
acc : 0.9962, precision : 0.9899, recall : 0.9884, f1_score : 0.9891
train_loss : 0.0507
eval_loss : 0.1441
acc : 0.9892, precision : 0.9734, recall : 0.9643, f1_score : 0.9688
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9330    0.9272    0.9301      5629
           1     0.9677    0.9704    0.9691     12665

    accuracy                         0.9571     18294
   macro avg     0.9503    0.9488    0.9496     18294
weighted avg     0.9570    0.9571    0.9571     18294

[[ 5219   410]
 [  375 12290]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9989    0.9989    0.9989      4564
           1     0.9978    0.9996    0.9987      4574
           2     0.9980    0.9993    0.9987      4578
           3     0.9996    0.9965    0.9980      4578

    accuracy                         0.9986     18294
   macro avg     0.9986    0.9986    0.9986     18294
weighted avg     0.9986    0.9986    0.9986     18294

[[4559    1    4    0]
 [   1 4572    0    1]
 [   0    2 4575    1]
 [   4    7    5 4562]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.31 mins
epoch : 20|20, iter :  60|334,  loss : 0.0387
epoch : 20|20, iter : 120|334,  loss : 0.0340
epoch : 20|20, iter : 180|334,  loss : 0.0320
epoch : 20|20, iter : 240|334,  loss : 0.0347
epoch : 20|20, iter : 300|334,  loss : 0.0362
acc : 0.9974, precision : 0.9927, recall : 0.9922, f1_score : 0.9924
train_loss : 0.0367
eval_loss : 0.1538
acc : 0.9880, precision : 0.9682, recall : 0.9630, f1_score : 0.9656
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9342    0.9284    0.9313      5629
           1     0.9683    0.9709    0.9696     12665

    accuracy                         0.9579     18294
   macro avg     0.9512    0.9497    0.9505     18294
weighted avg     0.9578    0.9579    0.9578     18294

[[ 5226   403]
 [  368 12297]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9978    0.9985    0.9981      4564
           1     0.9978    0.9987    0.9983      4574
           2     0.9980    0.9985    0.9983      4578
           3     0.9989    0.9969    0.9979      4578

    accuracy                         0.9981     18294
   macro avg     0.9981    0.9981    0.9981     18294
weighted avg     0.9981    0.9981    0.9981     18294

[[4557    1    6    0]
 [   2 4568    0    4]
 [   5    1 4571    1]
 [   3    8    3 4564]]
-------------------------------------------------------------------------------------
Single epoch cost time : 2.32 mins
