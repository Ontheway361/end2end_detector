----------------Environment Versions----------------
- Python: 3.7.3 
- PyTorch: 1.1.0
- TorchVison: 0.3.0
- device: True
----------------------------------------------------
Parallel mode was going ...
Model loading was finished ...
Data loading was finished ...
epoch :  1|20, iter :  60|334,  loss : 0.4212
epoch :  1|20, iter : 120|334,  loss : 0.3248
epoch :  1|20, iter : 180|334,  loss : 0.2800
epoch :  1|20, iter : 240|334,  loss : 0.2516
epoch :  1|20, iter : 300|334,  loss : 0.2305
acc : 0.9540, recall : 0.8944, f1_score : 0.8711, precision : 0.8490
train_loss : 0.2215
acc : 0.9806, recall : 0.9590, f1_score : 0.9452, precision : 0.9318
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9090    0.7715    0.8346      5629
           1     0.9049    0.9657    0.9343     12665

    accuracy                         0.9059     18294
   macro avg     0.9069    0.8686    0.8844     18294
weighted avg     0.9061    0.9059    0.9036     18294

[[ 4343  1286]
 [  435 12230]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9991    0.9875    0.9933      4564
           1     0.9893    0.9934    0.9914      4574
           2     0.9849    0.9978    0.9913      4578
           3     0.9925    0.9869    0.9897      4578

    accuracy                         0.9914     18294
   macro avg     0.9915    0.9914    0.9914     18294
weighted avg     0.9915    0.9914    0.9914     18294

[[4507    3   50    4]
 [   1 4544    6   23]
 [   1    2 4568    7]
 [   2   44   14 4518]]
-------------------------------------------------------------------------------------
eval_loss : 0.1386
Single epoch cost time : 1.89 mins
----------------new sota was found----------------
epoch :  2|20, iter :  60|334,  loss : 0.1214
epoch :  2|20, iter : 120|334,  loss : 0.1196
epoch :  2|20, iter : 180|334,  loss : 0.1152
epoch :  2|20, iter : 240|334,  loss : 0.1120
epoch :  2|20, iter : 300|334,  loss : 0.1109
acc : 0.9814, recall : 0.9493, f1_score : 0.9465, precision : 0.9437
train_loss : 0.1100
acc : 0.9494, recall : 0.7219, f1_score : 0.8327, precision : 0.9838
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.7203    0.9810    0.8307      5629
           1     0.9899    0.8307    0.9034     12665

    accuracy                         0.8770     18294
   macro avg     0.8551    0.9059    0.8670     18294
weighted avg     0.9070    0.8770    0.8810     18294

[[ 5522   107]
 [ 2144 10521]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9894    0.9989    0.9941      4564
           1     0.9987    0.9821    0.9903      4574
           2     0.9991    0.9869    0.9930      4578
           3     0.9788    0.9976    0.9881      4578

    accuracy                         0.9914     18294
   macro avg     0.9915    0.9914    0.9914     18294
weighted avg     0.9915    0.9914    0.9914     18294

[[4559    1    3    1]
 [   1 4492    0   81]
 [  39    4 4518   17]
 [   9    1    1 4567]]
-------------------------------------------------------------------------------------
eval_loss : 0.1701
Single epoch cost time : 1.36 mins
epoch :  3|20, iter :  60|334,  loss : 0.1007
epoch :  3|20, iter : 120|334,  loss : 0.0980
epoch :  3|20, iter : 180|334,  loss : 0.0970
epoch :  3|20, iter : 240|334,  loss : 0.0956
epoch :  3|20, iter : 300|334,  loss : 0.0959
acc : 0.9842, recall : 0.9558, f1_score : 0.9546, precision : 0.9533
train_loss : 0.0961
acc : 0.9861, recall : 0.9480, f1_score : 0.9596, precision : 0.9714
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8589    0.9531    0.9036      5629
           1     0.9781    0.9304    0.9537     12665

    accuracy                         0.9374     18294
   macro avg     0.9185    0.9418    0.9286     18294
weighted avg     0.9414    0.9374    0.9383     18294

[[ 5365   264]
 [  881 11784]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9950    0.9980    0.9965      4564
           1     0.9978    0.9790    0.9883      4574
           2     0.9985    0.9860    0.9922      4578
           3     0.9709    0.9983    0.9844      4578

    accuracy                         0.9903     18294
   macro avg     0.9905    0.9903    0.9903     18294
weighted avg     0.9905    0.9903    0.9903     18294

[[4555    1    6    2]
 [   5 4478    1   90]
 [  17    2 4514   45]
 [   1    7    0 4570]]
-------------------------------------------------------------------------------------
eval_loss : 0.1096
Single epoch cost time : 1.37 mins
----------------new sota was found----------------
epoch :  4|20, iter :  60|334,  loss : 0.0806
epoch :  4|20, iter : 120|334,  loss : 0.0878
epoch :  4|20, iter : 180|334,  loss : 0.0873
epoch :  4|20, iter : 240|334,  loss : 0.0870
epoch :  4|20, iter : 300|334,  loss : 0.0880
acc : 0.9855, recall : 0.9590, f1_score : 0.9584, precision : 0.9577
train_loss : 0.0885
acc : 0.9687, recall : 0.8324, f1_score : 0.9029, precision : 0.9863
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.7882    0.9614    0.8663      5629
           1     0.9810    0.8852    0.9306     12665

    accuracy                         0.9087     18294
   macro avg     0.8846    0.9233    0.8985     18294
weighted avg     0.9217    0.9087    0.9108     18294

[[ 5412   217]
 [ 1454 11211]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9866    0.9989    0.9927      4564
           1     0.9971    0.9718    0.9843      4574
           2     0.9985    0.9882    0.9933      4578
           3     0.9737    0.9963    0.9849      4578

    accuracy                         0.9888     18294
   macro avg     0.9890    0.9888    0.9888     18294
weighted avg     0.9890    0.9888    0.9888     18294

[[4559    1    3    1]
 [   8 4445    3  118]
 [  49    1 4524    4]
 [   5   11    1 4561]]
-------------------------------------------------------------------------------------
eval_loss : 0.1519
Single epoch cost time : 1.40 mins
epoch :  5|20, iter :  60|334,  loss : 0.0820
epoch :  5|20, iter : 120|334,  loss : 0.0820
epoch :  5|20, iter : 180|334,  loss : 0.0845
epoch :  5|20, iter : 240|334,  loss : 0.0853
epoch :  5|20, iter : 300|334,  loss : 0.0853
acc : 0.9857, recall : 0.9574, f1_score : 0.9587, precision : 0.9600
train_loss : 0.0860
acc : 0.9878, recall : 0.9577, f1_score : 0.9647, precision : 0.9717
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8905    0.9222    0.9061      5629
           1     0.9649    0.9496    0.9572     12665

    accuracy                         0.9412     18294
   macro avg     0.9277    0.9359    0.9316     18294
weighted avg     0.9420    0.9412    0.9415     18294

[[ 5191   438]
 [  638 12027]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9975    0.9601    0.9785      4564
           1     0.9761    0.9980    0.9869      4574
           2     0.9529    0.9991    0.9755      4578
           3     0.9998    0.9661    0.9827      4578

    accuracy                         0.9809     18294
   macro avg     0.9816    0.9809    0.9809     18294
weighted avg     0.9815    0.9809    0.9809     18294

[[4382    1  181    0]
 [   2 4565    7    0]
 [   1    2 4574    1]
 [   8  109   38 4423]]
-------------------------------------------------------------------------------------
eval_loss : 0.1122
Single epoch cost time : 1.38 mins
epoch :  6|20, iter :  60|334,  loss : 0.0866
epoch :  6|20, iter : 120|334,  loss : 0.0795
epoch :  6|20, iter : 180|334,  loss : 0.0779
epoch :  6|20, iter : 240|334,  loss : 0.0782
epoch :  6|20, iter : 300|334,  loss : 0.0797
acc : 0.9873, recall : 0.9604, f1_score : 0.9635, precision : 0.9666
train_loss : 0.0811
acc : 0.9830, recall : 0.9881, f1_score : 0.9530, precision : 0.9204
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9139    0.9066    0.9102      5629
           1     0.9586    0.9620    0.9603     12665

    accuracy                         0.9450     18294
   macro avg     0.9362    0.9343    0.9353     18294
weighted avg     0.9448    0.9450    0.9449     18294

[[ 5103   526]
 [  481 12184]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9915    0.9974    0.9944      4564
           1     0.9617    0.9998    0.9804      4574
           2     0.9996    0.9786    0.9890      4578
           3     0.9996    0.9751    0.9872      4578

    accuracy                         0.9877     18294
   macro avg     0.9881    0.9877    0.9877     18294
weighted avg     0.9881    0.9877    0.9877     18294

[[4552   11    1    0]
 [   1 4573    0    0]
 [  32   64 4480    2]
 [   6  107    1 4464]]
-------------------------------------------------------------------------------------
eval_loss : 0.1027
Single epoch cost time : 1.36 mins
----------------new sota was found----------------
epoch :  7|20, iter :  60|334,  loss : 0.0820
epoch :  7|20, iter : 120|334,  loss : 0.0822
epoch :  7|20, iter : 180|334,  loss : 0.0802
epoch :  7|20, iter : 240|334,  loss : 0.0796
epoch :  7|20, iter : 300|334,  loss : 0.0804
acc : 0.9875, recall : 0.9613, f1_score : 0.9640, precision : 0.9666
train_loss : 0.0795
acc : 0.9910, recall : 0.9753, f1_score : 0.9742, precision : 0.9731
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9073    0.9387    0.9227      5629
           1     0.9723    0.9574    0.9648     12665

    accuracy                         0.9516     18294
   macro avg     0.9398    0.9480    0.9438     18294
weighted avg     0.9523    0.9516    0.9518     18294

[[ 5284   345]
 [  540 12125]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9969    0.9980    0.9975      4564
           1     0.9952    0.9967    0.9960      4574
           2     0.9969    0.9967    0.9968      4578
           3     0.9972    0.9948    0.9960      4578

    accuracy                         0.9966     18294
   macro avg     0.9966    0.9966    0.9966     18294
weighted avg     0.9966    0.9966    0.9966     18294

[[4555    1    7    1]
 [   1 4559    4   10]
 [  12    1 4563    2]
 [   1   20    3 4554]]
-------------------------------------------------------------------------------------
eval_loss : 0.0799
Single epoch cost time : 1.37 mins
----------------new sota was found----------------
epoch :  8|20, iter :  60|334,  loss : 0.0738
epoch :  8|20, iter : 120|334,  loss : 0.0729
epoch :  8|20, iter : 180|334,  loss : 0.0774
epoch :  8|20, iter : 240|334,  loss : 0.0772
epoch :  8|20, iter : 300|334,  loss : 0.0770
acc : 0.9876, recall : 0.9644, f1_score : 0.9642, precision : 0.9640
train_loss : 0.0763
acc : 0.9867, recall : 0.9386, f1_score : 0.9609, precision : 0.9842
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8746    0.9366    0.9045      5629
           1     0.9709    0.9403    0.9554     12665

    accuracy                         0.9392     18294
   macro avg     0.9227    0.9384    0.9299     18294
weighted avg     0.9413    0.9392    0.9397     18294

[[ 5272   357]
 [  756 11909]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9969    0.9978    0.9974      4564
           1     0.9987    0.9834    0.9910      4574
           2     0.9948    0.9969    0.9959      4578
           3     0.9855    0.9976    0.9915      4578

    accuracy                         0.9939     18294
   macro avg     0.9940    0.9939    0.9939     18294
weighted avg     0.9940    0.9939    0.9939     18294

[[4554    1    9    0]
 [   4 4498    6   66]
 [   9    4 4564    1]
 [   1    1    9 4567]]
-------------------------------------------------------------------------------------
eval_loss : 0.1024
Single epoch cost time : 1.40 mins
epoch :  9|20, iter :  60|334,  loss : 0.0627
epoch :  9|20, iter : 120|334,  loss : 0.0675
epoch :  9|20, iter : 180|334,  loss : 0.0688
epoch :  9|20, iter : 240|334,  loss : 0.0701
epoch :  9|20, iter : 300|334,  loss : 0.0694
acc : 0.9892, recall : 0.9697, f1_score : 0.9688, precision : 0.9680
train_loss : 0.0702
acc : 0.9884, recall : 0.9599, f1_score : 0.9666, precision : 0.9733
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9494    0.8708    0.9085      5629
           1     0.9446    0.9794    0.9617     12665

    accuracy                         0.9460     18294
   macro avg     0.9470    0.9251    0.9351     18294
weighted avg     0.9461    0.9460    0.9453     18294

[[ 4902   727]
 [  261 12404]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9989    0.9958    0.9974      4564
           1     0.9969    0.9948    0.9958      4574
           2     0.9954    0.9987    0.9971      4578
           3     0.9950    0.9969    0.9960      4578

    accuracy                         0.9966     18294
   macro avg     0.9966    0.9966    0.9966     18294
weighted avg     0.9966    0.9966    0.9966     18294

[[4545    1   14    4]
 [   3 4550    4   17]
 [   1    3 4572    2]
 [   1   10    3 4564]]
-------------------------------------------------------------------------------------
eval_loss : 0.0827
Single epoch cost time : 1.38 mins
epoch : 10|20, iter :  60|334,  loss : 0.0685
epoch : 10|20, iter : 120|334,  loss : 0.0658
epoch : 10|20, iter : 180|334,  loss : 0.0671
epoch : 10|20, iter : 240|334,  loss : 0.0668
epoch : 10|20, iter : 300|334,  loss : 0.0674
acc : 0.9894, recall : 0.9694, f1_score : 0.9694, precision : 0.9694
train_loss : 0.0685
acc : 0.9898, recall : 0.9728, f1_score : 0.9708, precision : 0.9688
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9302    0.9428    0.9365      5629
           1     0.9744    0.9686    0.9715     12665

    accuracy                         0.9606     18294
   macro avg     0.9523    0.9557    0.9540     18294
weighted avg     0.9608    0.9606    0.9607     18294

[[ 5307   322]
 [  398 12267]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9989    0.9985    0.9987      4564
           1     0.9989    0.9958    0.9974      4574
           2     0.9993    0.9989    0.9991      4578
           3     0.9952    0.9991    0.9972      4578

    accuracy                         0.9981     18294
   macro avg     0.9981    0.9981    0.9981     18294
weighted avg     0.9981    0.9981    0.9981     18294

[[4557    2    2    3]
 [   1 4555    0   18]
 [   3    1 4573    1]
 [   1    2    1 4574]]
-------------------------------------------------------------------------------------
eval_loss : 0.0658
Single epoch cost time : 1.35 mins
----------------new sota was found----------------
epoch : 11|20, iter :  60|334,  loss : 0.0522
epoch : 11|20, iter : 120|334,  loss : 0.0523
epoch : 11|20, iter : 180|334,  loss : 0.0529
epoch : 11|20, iter : 240|334,  loss : 0.0521
epoch : 11|20, iter : 300|334,  loss : 0.0511
acc : 0.9924, recall : 0.9775, f1_score : 0.9781, precision : 0.9787
train_loss : 0.0506
acc : 0.9913, recall : 0.9728, f1_score : 0.9749, precision : 0.9770
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9432    0.9376    0.9404      5629
           1     0.9724    0.9749    0.9736     12665

    accuracy                         0.9634     18294
   macro avg     0.9578    0.9563    0.9570     18294
weighted avg     0.9634    0.9634    0.9634     18294

[[ 5278   351]
 [  318 12347]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9901    0.9944      4564
           1     0.9985    0.9993    0.9989      4574
           2     0.9905    0.9987    0.9946      4578
           3     0.9993    0.9987    0.9990      4578

    accuracy                         0.9967     18294
   macro avg     0.9967    0.9967    0.9967     18294
weighted avg     0.9967    0.9967    0.9967     18294

[[4519    1   43    1]
 [   1 4571    1    1]
 [   3    2 4572    1]
 [   2    4    0 4572]]
-------------------------------------------------------------------------------------
eval_loss : 0.0627
Single epoch cost time : 1.40 mins
----------------new sota was found----------------
epoch : 12|20, iter :  60|334,  loss : 0.0429
epoch : 12|20, iter : 120|334,  loss : 0.0452
epoch : 12|20, iter : 180|334,  loss : 0.0460
epoch : 12|20, iter : 240|334,  loss : 0.0459
epoch : 12|20, iter : 300|334,  loss : 0.0469
acc : 0.9925, recall : 0.9791, f1_score : 0.9785, precision : 0.9779
train_loss : 0.0483
acc : 0.9910, recall : 0.9734, f1_score : 0.9743, precision : 0.9752
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9476    0.9321    0.9398      5629
           1     0.9701    0.9771    0.9736     12665

    accuracy                         0.9633     18294
   macro avg     0.9588    0.9546    0.9567     18294
weighted avg     0.9632    0.9633    0.9632     18294

[[ 5247   382]
 [  290 12375]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9948    0.9989    0.9968      4564
           1     0.9941    0.9998    0.9969      4574
           2     0.9996    0.9934    0.9965      4578
           3     0.9996    0.9958    0.9977      4578

    accuracy                         0.9970     18294
   macro avg     0.9970    0.9970    0.9970     18294
weighted avg     0.9970    0.9970    0.9970     18294

[[4559    3    1    1]
 [   1 4573    0    0]
 [  21    8 4548    1]
 [   2   16    1 4559]]
-------------------------------------------------------------------------------------
eval_loss : 0.0638
Single epoch cost time : 1.37 mins
epoch : 13|20, iter :  60|334,  loss : 0.0399
epoch : 13|20, iter : 120|334,  loss : 0.0422
epoch : 13|20, iter : 180|334,  loss : 0.0446
epoch : 13|20, iter : 240|334,  loss : 0.0476
epoch : 13|20, iter : 300|334,  loss : 0.0474
acc : 0.9933, recall : 0.9806, f1_score : 0.9807, precision : 0.9807
train_loss : 0.0479
acc : 0.9907, recall : 0.9737, f1_score : 0.9734, precision : 0.9731
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9291    0.9378    0.9334      5629
           1     0.9722    0.9682    0.9702     12665

    accuracy                         0.9588     18294
   macro avg     0.9507    0.9530    0.9518     18294
weighted avg     0.9590    0.9588    0.9589     18294

[[ 5279   350]
 [  403 12262]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9996    0.9987    0.9991      4564
           1     0.9967    0.9991    0.9979      4574
           2     0.9985    0.9989    0.9987      4578
           3     0.9989    0.9969    0.9979      4578

    accuracy                         0.9984     18294
   macro avg     0.9984    0.9984    0.9984     18294
weighted avg     0.9984    0.9984    0.9984     18294

[[4558    1    5    0]
 [   1 4570    1    2]
 [   0    2 4573    3]
 [   1   12    1 4564]]
-------------------------------------------------------------------------------------
eval_loss : 0.0672
Single epoch cost time : 1.37 mins
epoch : 14|20, iter :  60|334,  loss : 0.0437
epoch : 14|20, iter : 120|334,  loss : 0.0429
epoch : 14|20, iter : 180|334,  loss : 0.0440
epoch : 14|20, iter : 240|334,  loss : 0.0451
epoch : 14|20, iter : 300|334,  loss : 0.0450
acc : 0.9934, recall : 0.9811, f1_score : 0.9811, precision : 0.9811
train_loss : 0.0449
acc : 0.9905, recall : 0.9718, f1_score : 0.9729, precision : 0.9739
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9402    0.9243    0.9322      5629
           1     0.9666    0.9739    0.9702     12665

    accuracy                         0.9586     18294
   macro avg     0.9534    0.9491    0.9512     18294
weighted avg     0.9585    0.9586    0.9585     18294

[[ 5203   426]
 [  331 12334]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9996    0.9945    0.9970      4564
           1     0.9974    0.9993    0.9984      4574
           2     0.9928    0.9996    0.9962      4578
           3     0.9998    0.9961    0.9979      4578

    accuracy                         0.9974     18294
   macro avg     0.9974    0.9974    0.9974     18294
weighted avg     0.9974    0.9974    0.9974     18294

[[4539    1   24    0]
 [   1 4571    2    0]
 [   0    1 4576    1]
 [   1   10    7 4560]]
-------------------------------------------------------------------------------------
eval_loss : 0.0672
Single epoch cost time : 1.39 mins
epoch : 15|20, iter :  60|334,  loss : 0.0384
epoch : 15|20, iter : 120|334,  loss : 0.0376
epoch : 15|20, iter : 180|334,  loss : 0.0395
epoch : 15|20, iter : 240|334,  loss : 0.0417
epoch : 15|20, iter : 300|334,  loss : 0.0429
acc : 0.9936, recall : 0.9814, f1_score : 0.9817, precision : 0.9819
train_loss : 0.0440
acc : 0.9859, recall : 0.9909, f1_score : 0.9608, precision : 0.9325
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9565    0.8915    0.9229      5629
           1     0.9532    0.9820    0.9674     12665

    accuracy                         0.9541     18294
   macro avg     0.9549    0.9367    0.9451     18294
weighted avg     0.9542    0.9541    0.9537     18294

[[ 5018   611]
 [  228 12437]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9935    0.9991    0.9963      4564
           1     0.9987    0.9954    0.9970      4574
           2     0.9961    0.9969    0.9965      4578
           3     0.9991    0.9958    0.9975      4578

    accuracy                         0.9968     18294
   macro avg     0.9968    0.9968    0.9968     18294
weighted avg     0.9968    0.9968    0.9968     18294

[[4560    1    3    0]
 [  13 4553    5    3]
 [  12    1 4564    1]
 [   5    4   10 4559]]
-------------------------------------------------------------------------------------
eval_loss : 0.0746
Single epoch cost time : 1.38 mins
epoch : 16|20, iter :  60|334,  loss : 0.0408
epoch : 16|20, iter : 120|334,  loss : 0.0409
epoch : 16|20, iter : 180|334,  loss : 0.0410
epoch : 16|20, iter : 240|334,  loss : 0.0420
epoch : 16|20, iter : 300|334,  loss : 0.0413
acc : 0.9937, recall : 0.9826, f1_score : 0.9817, precision : 0.9809
train_loss : 0.0420
acc : 0.9899, recall : 0.9630, f1_score : 0.9708, precision : 0.9787
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9203    0.9558    0.9377      5629
           1     0.9800    0.9632    0.9715     12665

    accuracy                         0.9609     18294
   macro avg     0.9501    0.9595    0.9546     18294
weighted avg     0.9616    0.9609    0.9611     18294

[[ 5380   249]
 [  466 12199]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9991    0.9976    0.9984      4564
           1     0.9983    0.9993    0.9988      4574
           2     0.9983    0.9989    0.9986      4578
           3     0.9987    0.9985    0.9986      4578

    accuracy                         0.9986     18294
   macro avg     0.9986    0.9986    0.9986     18294
weighted avg     0.9986    0.9986    0.9986     18294

[[4553    1    8    2]
 [   1 4571    0    2]
 [   2    1 4573    2]
 [   1    6    0 4571]]
-------------------------------------------------------------------------------------
eval_loss : 0.0661
Single epoch cost time : 1.38 mins
epoch : 17|20, iter :  60|334,  loss : 0.0330
epoch : 17|20, iter : 120|334,  loss : 0.0339
epoch : 17|20, iter : 180|334,  loss : 0.0357
epoch : 17|20, iter : 240|334,  loss : 0.0380
epoch : 17|20, iter : 300|334,  loss : 0.0383
acc : 0.9941, recall : 0.9822, f1_score : 0.9831, precision : 0.9839
train_loss : 0.0386
acc : 0.9900, recall : 0.9796, f1_score : 0.9716, precision : 0.9636
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9381    0.9289    0.9335      5629
           1     0.9686    0.9728    0.9707     12665

    accuracy                         0.9593     18294
   macro avg     0.9533    0.9508    0.9521     18294
weighted avg     0.9592    0.9593    0.9592     18294

[[ 5229   400]
 [  345 12320]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9991    0.9980    0.9986      4564
           1     0.9972    0.9985    0.9978      4574
           2     0.9974    0.9989    0.9981      4578
           3     0.9987    0.9969    0.9978      4578

    accuracy                         0.9981     18294
   macro avg     0.9981    0.9981    0.9981     18294
weighted avg     0.9981    0.9981    0.9981     18294

[[4555    1    7    1]
 [   1 4567    2    4]
 [   2    2 4573    1]
 [   1   10    3 4564]]
-------------------------------------------------------------------------------------
eval_loss : 0.0716
Single epoch cost time : 1.38 mins
epoch : 18|20, iter :  60|334,  loss : 0.0301
epoch : 18|20, iter : 120|334,  loss : 0.0317
epoch : 18|20, iter : 180|334,  loss : 0.0337
epoch : 18|20, iter : 240|334,  loss : 0.0347
epoch : 18|20, iter : 300|334,  loss : 0.0362
acc : 0.9948, recall : 0.9857, f1_score : 0.9850, precision : 0.9842
train_loss : 0.0370
acc : 0.9878, recall : 0.9527, f1_score : 0.9645, precision : 0.9766
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8974    0.9558    0.9257      5629
           1     0.9798    0.9514    0.9654     12665

    accuracy                         0.9528     18294
   macro avg     0.9386    0.9536    0.9455     18294
weighted avg     0.9544    0.9528    0.9532     18294

[[ 5380   249]
 [  615 12050]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9978    0.9985    0.9981      4564
           1     0.9967    0.9993    0.9980      4574
           2     0.9993    0.9967    0.9980      4578
           3     0.9985    0.9978    0.9981      4578

    accuracy                         0.9981     18294
   macro avg     0.9981    0.9981    0.9981     18294
weighted avg     0.9981    0.9981    0.9981     18294

[[4557    3    2    2]
 [   1 4571    0    2]
 [   8    4 4563    3]
 [   1    8    1 4568]]
-------------------------------------------------------------------------------------
eval_loss : 0.0731
Single epoch cost time : 1.39 mins
epoch : 19|20, iter :  60|334,  loss : 0.0300
epoch : 19|20, iter : 120|334,  loss : 0.0264
epoch : 19|20, iter : 180|334,  loss : 0.0251
epoch : 19|20, iter : 240|334,  loss : 0.0243
epoch : 19|20, iter : 300|334,  loss : 0.0237
acc : 0.9966, recall : 0.9900, f1_score : 0.9904, precision : 0.9907
train_loss : 0.0238
acc : 0.9907, recall : 0.9655, f1_score : 0.9730, precision : 0.9806
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9294    0.9467    0.9380      5629
           1     0.9761    0.9680    0.9721     12665

    accuracy                         0.9615     18294
   macro avg     0.9527    0.9574    0.9550     18294
weighted avg     0.9617    0.9615    0.9616     18294

[[ 5329   300]
 [  405 12260]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9980    0.9989    0.9985      4564
           1     0.9985    0.9993    0.9989      4574
           2     0.9991    0.9974    0.9983      4578
           3     0.9985    0.9985    0.9985      4578

    accuracy                         0.9985     18294
   macro avg     0.9985    0.9985    0.9985     18294
weighted avg     0.9985    0.9985    0.9985     18294

[[4559    1    3    1]
 [   1 4571    0    2]
 [   7    1 4566    4]
 [   1    5    1 4571]]
-------------------------------------------------------------------------------------
eval_loss : 0.0724
Single epoch cost time : 1.37 mins
epoch : 20|20, iter :  60|334,  loss : 0.0169
epoch : 20|20, iter : 120|334,  loss : 0.0182
epoch : 20|20, iter : 180|334,  loss : 0.0176
epoch : 20|20, iter : 240|334,  loss : 0.0176
epoch : 20|20, iter : 300|334,  loss : 0.0185
acc : 0.9977, recall : 0.9929, f1_score : 0.9933, precision : 0.9937
train_loss : 0.0187
acc : 0.9909, recall : 0.9712, f1_score : 0.9739, precision : 0.9767
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9341    0.9449    0.9395      5629
           1     0.9754    0.9704    0.9729     12665

    accuracy                         0.9626     18294
   macro avg     0.9548    0.9577    0.9562     18294
weighted avg     0.9627    0.9626    0.9626     18294

[[ 5319   310]
 [  375 12290]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9993    0.9989    0.9991      4564
           1     0.9976    0.9998    0.9987      4574
           2     0.9983    0.9989    0.9986      4578
           3     0.9996    0.9972    0.9984      4578

    accuracy                         0.9987     18294
   macro avg     0.9987    0.9987    0.9987     18294
weighted avg     0.9987    0.9987    0.9987     18294

[[4559    1    4    0]
 [   1 4573    0    0]
 [   1    2 4573    2]
 [   1    8    4 4565]]
-------------------------------------------------------------------------------------
eval_loss : 0.0739
Single epoch cost time : 1.40 mins
