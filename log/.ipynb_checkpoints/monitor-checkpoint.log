----------------Environment Versions----------------
- Python: 3.7.3 
- PyTorch: 1.1.0
- TorchVison: 0.3.0
- device: True
----------------------------------------------------
Single-gpu mode was going ...
Model loading was finished ...
After data augmentation, 10625 rows added.
After data augmentation,   0 rows added.
Data loading was finished ...
epoch :  1|21, iter : 100|417,  loss : 1.4180
epoch :  1|21, iter : 200|417,  loss : 0.9938
epoch :  1|21, iter : 300|417,  loss : 0.8034
epoch :  1|21, iter : 400|417,  loss : 0.6859
acc : 0.8732, precision : 0.7147, recall : 0.9013, f1_score : 0.7972
train_loss : 0.6720
eval_loss : 0.3665
acc : 0.9743, precision : 0.9127, recall : 0.9398, f1_score : 0.9260
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.7589    0.8515    0.8025      5637
           1     0.9301    0.8795    0.9041     12657

    accuracy                         0.8709     18294
   macro avg     0.8445    0.8655    0.8533     18294
weighted avg     0.8773    0.8709    0.8728     18294

[[ 4800   837]
 [ 1525 11132]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9697    0.9853    0.9774      4544
           1     0.9956    0.9798    0.9876      4593
           2     0.9703    0.9921    0.9811      4578
           3     0.9906    0.9683    0.9793      4579

    accuracy                         0.9814     18294
   macro avg     0.9815    0.9814    0.9814     18294
weighted avg     0.9816    0.9814    0.9814     18294

[[4477    3   62    2]
 [  30 4500   28   35]
 [  29    2 4542    5]
 [  81   15   49 4434]]
-------------------------------------------------------------------------------------
Single epoch cost time : 10.34 mins
****************new SOTA was found****************
epoch :  2|21, iter : 100|417,  loss : 0.2774
epoch :  2|21, iter : 200|417,  loss : 0.2678
epoch :  2|21, iter : 300|417,  loss : 0.2559
epoch :  2|21, iter : 400|417,  loss : 0.2446
acc : 0.9734, precision : 0.9490, recall : 0.9551, f1_score : 0.9520
train_loss : 0.2432
eval_loss : 0.2628
acc : 0.9842, precision : 0.9763, recall : 0.9305, f1_score : 0.9528
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.7967    0.9610    0.8712      5637
           1     0.9809    0.8908    0.9337     12657

    accuracy                         0.9124     18294
   macro avg     0.8888    0.9259    0.9024     18294
weighted avg     0.9241    0.9124    0.9144     18294

[[ 5417   220]
 [ 1382 11275]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9956    0.9971    0.9964      4544
           1     0.9969    0.9950    0.9960      4593
           2     0.9965    0.9952    0.9958      4578
           3     0.9954    0.9972    0.9963      4579

    accuracy                         0.9961     18294
   macro avg     0.9961    0.9961    0.9961     18294
weighted avg     0.9961    0.9961    0.9961     18294

[[4531    0   13    0]
 [   4 4570    3   16]
 [  12    5 4556    5]
 [   4    9    0 4566]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.16 mins
****************new SOTA was found****************
epoch :  3|21, iter : 100|417,  loss : 0.1815
epoch :  3|21, iter : 200|417,  loss : 0.1861
epoch :  3|21, iter : 300|417,  loss : 0.1857
epoch :  3|21, iter : 400|417,  loss : 0.1850
acc : 0.9803, precision : 0.9637, recall : 0.9651, f1_score : 0.9644
train_loss : 0.1862
eval_loss : 0.2491
acc : 0.9757, precision : 0.8846, recall : 0.9873, f1_score : 0.9331
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9468    0.7995    0.8670      5637
           1     0.9165    0.9800    0.9472     12657

    accuracy                         0.9244     18294
   macro avg     0.9317    0.8898    0.9071     18294
weighted avg     0.9259    0.9244    0.9225     18294

[[ 4507  1130]
 [  253 12404]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9678    0.9974    0.9823      4544
           1     0.9971    0.9793    0.9881      4593
           2     0.9895    0.9867    0.9881      4578
           3     0.9958    0.9862    0.9910      4579

    accuracy                         0.9874     18294
   macro avg     0.9875    0.9874    0.9874     18294
weighted avg     0.9876    0.9874    0.9874     18294

[[4532    0   12    0]
 [  58 4498   20   17]
 [  59    0 4517    2]
 [  34   13   16 4516]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.16 mins
****************new SOTA was found****************
epoch :  4|21, iter : 100|417,  loss : 0.1690
epoch :  4|21, iter : 200|417,  loss : 0.1758
epoch :  4|21, iter : 300|417,  loss : 0.1692
epoch :  4|21, iter : 400|417,  loss : 0.1689
acc : 0.9820, precision : 0.9666, recall : 0.9683, f1_score : 0.9674
train_loss : 0.1692
eval_loss : 0.4423
acc : 0.9814, precision : 0.9648, recall : 0.9251, f1_score : 0.9445
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.6904    0.9759    0.8087      5637
           1     0.9868    0.8051    0.8867     12657

    accuracy                         0.8577     18294
   macro avg     0.8386    0.8905    0.8477     18294
weighted avg     0.8955    0.8577    0.8627     18294

[[ 5501   136]
 [ 2467 10190]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9663    0.9978    0.9818      4544
           1     0.9335    0.9996    0.9654      4593
           2     0.9993    0.9605    0.9795      4578
           3     0.9993    0.9349    0.9660      4579

    accuracy                         0.9732     18294
   macro avg     0.9746    0.9732    0.9732     18294
weighted avg     0.9746    0.9732    0.9732     18294

[[4534    8    2    0]
 [   0 4591    1    1]
 [ 136   43 4397    2]
 [  22  276    0 4281]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.21 mins
epoch :  5|21, iter : 100|417,  loss : 0.1492
epoch :  5|21, iter : 200|417,  loss : 0.1517
epoch :  5|21, iter : 300|417,  loss : 0.1569
epoch :  5|21, iter : 400|417,  loss : 0.1564
acc : 0.9837, precision : 0.9706, recall : 0.9706, f1_score : 0.9706
train_loss : 0.1574
eval_loss : 0.2637
acc : 0.9798, precision : 0.9736, recall : 0.9066, f1_score : 0.9389
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8381    0.9542    0.8924      5637
           1     0.9783    0.9179    0.9471     12657

    accuracy                         0.9291     18294
   macro avg     0.9082    0.9361    0.9198     18294
weighted avg     0.9351    0.9291    0.9303     18294

[[ 5379   258]
 [ 1039 11618]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9916    0.9824    0.9870      4544
           1     0.9864    0.9959    0.9911      4593
           2     0.9995    0.9653    0.9821      4578
           3     0.9632    0.9959    0.9793      4579

    accuracy                         0.9849     18294
   macro avg     0.9852    0.9848    0.9849     18294
weighted avg     0.9852    0.9849    0.9849     18294

[[4464    9    1   70]
 [   2 4574    1   16]
 [  34   37 4419   88]
 [   2   17    0 4560]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.08 mins
epoch :  6|21, iter : 100|417,  loss : 0.1408
epoch :  6|21, iter : 200|417,  loss : 0.1481
epoch :  6|21, iter : 300|417,  loss : 0.1484
epoch :  6|21, iter : 400|417,  loss : 0.1501
acc : 0.9846, precision : 0.9726, recall : 0.9717, f1_score : 0.9721
train_loss : 0.1499
eval_loss : 0.2108
acc : 0.9844, precision : 0.9314, recall : 0.9815, f1_score : 0.9558
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9271    0.8662    0.8956      5637
           1     0.9421    0.9697    0.9557     12657

    accuracy                         0.9378     18294
   macro avg     0.9346    0.9180    0.9257     18294
weighted avg     0.9375    0.9378    0.9372     18294

[[ 4883   754]
 [  384 12273]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9759    0.9993    0.9875      4544
           1     0.9967    0.9946    0.9956      4593
           2     0.9996    0.9799    0.9896      4578
           3     0.9958    0.9939    0.9949      4579

    accuracy                         0.9919     18294
   macro avg     0.9920    0.9919    0.9919     18294
weighted avg     0.9920    0.9919    0.9919     18294

[[4541    0    1    2]
 [  16 4568    1    8]
 [  82    1 4486    9]
 [  14   14    0 4551]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.09 mins
****************new SOTA was found****************
epoch :  7|21, iter : 100|417,  loss : 0.1512
epoch :  7|21, iter : 200|417,  loss : 0.1506
epoch :  7|21, iter : 300|417,  loss : 0.1495
epoch :  7|21, iter : 400|417,  loss : 0.1491
acc : 0.9846, precision : 0.9713, recall : 0.9732, f1_score : 0.9723
train_loss : 0.1492
eval_loss : 0.1970
acc : 0.9870, precision : 0.9563, recall : 0.9685, f1_score : 0.9623
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8758    0.9383    0.9060      5637
           1     0.9716    0.9407    0.9559     12657

    accuracy                         0.9400     18294
   macro avg     0.9237    0.9395    0.9309     18294
weighted avg     0.9421    0.9400    0.9405     18294

[[ 5289   348]
 [  750 11907]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9954    0.9952    0.9953      4544
           1     0.9858    0.9980    0.9919      4593
           2     0.9941    0.9952    0.9947      4578
           3     0.9987    0.9854    0.9920      4579

    accuracy                         0.9934     18294
   macro avg     0.9935    0.9934    0.9934     18294
weighted avg     0.9935    0.9934    0.9934     18294

[[4522    2   20    0]
 [   4 4584    3    2]
 [  15    3 4556    4]
 [   2   61    4 4512]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.10 mins
****************new SOTA was found****************
epoch :  8|21, iter : 100|417,  loss : 0.1367
epoch :  8|21, iter : 200|417,  loss : 0.1359
epoch :  8|21, iter : 300|417,  loss : 0.1404
epoch :  8|21, iter : 400|417,  loss : 0.1427
acc : 0.9846, precision : 0.9715, recall : 0.9730, f1_score : 0.9723
train_loss : 0.1426
eval_loss : 0.1695
acc : 0.9855, precision : 0.9868, recall : 0.9280, f1_score : 0.9565
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9055    0.9283    0.9168      5637
           1     0.9677    0.9569    0.9623     12657

    accuracy                         0.9481     18294
   macro avg     0.9366    0.9426    0.9395     18294
weighted avg     0.9486    0.9481    0.9482     18294

[[ 5233   404]
 [  546 12111]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9969    0.9974    0.9971      4544
           1     0.9858    0.9965    0.9911      4593
           2     0.9963    0.9969    0.9966      4578
           3     0.9973    0.9854    0.9913      4579

    accuracy                         0.9940     18294
   macro avg     0.9941    0.9940    0.9940     18294
weighted avg     0.9941    0.9940    0.9940     18294

[[4532    1    9    2]
 [   3 4577    6    7]
 [   9    2 4564    3]
 [   2   63    2 4512]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.17 mins
****************new SOTA was found****************
epoch :  9|21, iter : 100|417,  loss : 0.1333
epoch :  9|21, iter : 200|417,  loss : 0.1326
epoch :  9|21, iter : 300|417,  loss : 0.1343
epoch :  9|21, iter : 400|417,  loss : 0.1371
acc : 0.9853, precision : 0.9737, recall : 0.9729, f1_score : 0.9733
train_loss : 0.1368
eval_loss : 0.1655
acc : 0.9867, precision : 0.9472, recall : 0.9767, f1_score : 0.9617
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9241    0.9292    0.9267      5637
           1     0.9684    0.9660    0.9672     12657

    accuracy                         0.9547     18294
   macro avg     0.9463    0.9476    0.9469     18294
weighted avg     0.9548    0.9547    0.9547     18294

[[ 5238   399]
 [  430 12227]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9785    0.9998    0.9890      4544
           1     0.9996    0.9898    0.9946      4593
           2     0.9958    0.9943    0.9951      4578
           3     0.9974    0.9871    0.9922      4579

    accuracy                         0.9927     18294
   macro avg     0.9928    0.9927    0.9927     18294
weighted avg     0.9928    0.9927    0.9927     18294

[[4543    0    1    0]
 [  31 4546    5   11]
 [  25    0 4552    1]
 [  44    2   13 4520]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.03 mins
****************new SOTA was found****************
epoch : 10|21, iter : 100|417,  loss : 0.1396
epoch : 10|21, iter : 200|417,  loss : 0.1318
epoch : 10|21, iter : 300|417,  loss : 0.1330
epoch : 10|21, iter : 400|417,  loss : 0.1336
acc : 0.9859, precision : 0.9752, recall : 0.9740, f1_score : 0.9746
train_loss : 0.1332
eval_loss : 0.1696
acc : 0.9882, precision : 0.9790, recall : 0.9516, f1_score : 0.9651
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8734    0.9659    0.9174      5637
           1     0.9841    0.9377    0.9603     12657

    accuracy                         0.9464     18294
   macro avg     0.9288    0.9518    0.9388     18294
weighted avg     0.9500    0.9464    0.9471     18294

[[ 5445   192]
 [  789 11868]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9930    0.9980    0.9955      4544
           1     0.9965    0.9980    0.9973      4593
           2     0.9982    0.9932    0.9957      4578
           3     0.9983    0.9967    0.9975      4579

    accuracy                         0.9965     18294
   macro avg     0.9965    0.9965    0.9965     18294
weighted avg     0.9965    0.9965    0.9965     18294

[[4535    2    7    0]
 [   2 4584    1    6]
 [  29    0 4547    2]
 [   1   14    0 4564]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.09 mins
epoch : 11|21, iter : 100|417,  loss : 0.1017
epoch : 11|21, iter : 200|417,  loss : 0.0959
epoch : 11|21, iter : 300|417,  loss : 0.0961
epoch : 11|21, iter : 400|417,  loss : 0.0953
acc : 0.9902, precision : 0.9834, recall : 0.9811, f1_score : 0.9822
train_loss : 0.0953
eval_loss : 0.1218
acc : 0.9909, precision : 0.9763, recall : 0.9704, f1_score : 0.9733
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9376    0.9360    0.9368      5637
           1     0.9715    0.9723    0.9719     12657

    accuracy                         0.9611     18294
   macro avg     0.9546    0.9541    0.9543     18294
weighted avg     0.9611    0.9611    0.9611     18294

[[ 5276   361]
 [  351 12306]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9963    0.9996    0.9979      4544
           1     1.0000    0.9963    0.9981      4593
           2     0.9993    0.9963    0.9978      4578
           3     0.9963    0.9998    0.9980      4579

    accuracy                         0.9980     18294
   macro avg     0.9980    0.9980    0.9980     18294
weighted avg     0.9980    0.9980    0.9980     18294

[[4542    0    1    1]
 [   0 4576    2   15]
 [  16    0 4561    1]
 [   1    0    0 4578]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.05 mins
****************new SOTA was found****************
epoch : 12|21, iter : 100|417,  loss : 0.0830
epoch : 12|21, iter : 200|417,  loss : 0.0882
epoch : 12|21, iter : 300|417,  loss : 0.0937
epoch : 12|21, iter : 400|417,  loss : 0.0926
acc : 0.9901, precision : 0.9820, recall : 0.9823, f1_score : 0.9822
train_loss : 0.0935
eval_loss : 0.1434
acc : 0.9903, precision : 0.9628, recall : 0.9815, f1_score : 0.9721
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9170    0.9484    0.9324      5637
           1     0.9767    0.9618    0.9691     12657

    accuracy                         0.9576     18294
   macro avg     0.9468    0.9551    0.9508     18294
weighted avg     0.9583    0.9576    0.9578     18294

[[ 5346   291]
 [  484 12173]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9963    0.9978    0.9970      4544
           1     0.9989    0.9963    0.9976      4593
           2     0.9961    0.9987    0.9974      4578
           3     0.9987    0.9972    0.9979      4579

    accuracy                         0.9975     18294
   macro avg     0.9975    0.9975    0.9975     18294
weighted avg     0.9975    0.9975    0.9975     18294

[[4534    1    8    1]
 [   6 4576    7    4]
 [   4    1 4572    1]
 [   7    3    3 4566]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.04 mins
epoch : 13|21, iter : 100|417,  loss : 0.0807
epoch : 13|21, iter : 200|417,  loss : 0.0828
epoch : 13|21, iter : 300|417,  loss : 0.0864
epoch : 13|21, iter : 400|417,  loss : 0.0908
acc : 0.9907, precision : 0.9830, recall : 0.9832, f1_score : 0.9831
train_loss : 0.0919
eval_loss : 0.1289
acc : 0.9908, precision : 0.9726, recall : 0.9736, f1_score : 0.9731
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9198    0.9521    0.9357      5637
           1     0.9783    0.9630    0.9706     12657

    accuracy                         0.9597     18294
   macro avg     0.9491    0.9576    0.9531     18294
weighted avg     0.9603    0.9597    0.9598     18294

[[ 5367   270]
 [  468 12189]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9993    0.9963    0.9978      4544
           1     0.9985    0.9989    0.9987      4593
           2     0.9965    0.9983    0.9974      4578
           3     0.9983    0.9991    0.9987      4579

    accuracy                         0.9981     18294
   macro avg     0.9981    0.9981    0.9981     18294
weighted avg     0.9981    0.9981    0.9981     18294

[[4527    3   14    0]
 [   0 4588    2    3]
 [   2    1 4570    5]
 [   1    3    0 4575]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.02 mins
epoch : 14|21, iter : 100|417,  loss : 0.0769
epoch : 14|21, iter : 200|417,  loss : 0.0823
epoch : 14|21, iter : 300|417,  loss : 0.0859
epoch : 14|21, iter : 400|417,  loss : 0.0872
acc : 0.9914, precision : 0.9843, recall : 0.9848, f1_score : 0.9845
train_loss : 0.0875
eval_loss : 0.1357
acc : 0.9900, precision : 0.9786, recall : 0.9627, f1_score : 0.9706
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9428    0.9189    0.9307      5637
           1     0.9643    0.9752    0.9697     12657

    accuracy                         0.9579     18294
   macro avg     0.9536    0.9471    0.9502     18294
weighted avg     0.9577    0.9579    0.9577     18294

[[ 5180   457]
 [  314 12343]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9945    0.9998    0.9971      4544
           1     0.9998    0.9980    0.9989      4593
           2     0.9991    0.9956    0.9974      4578
           3     0.9991    0.9991    0.9991      4579

    accuracy                         0.9981     18294
   macro avg     0.9981    0.9981    0.9981     18294
weighted avg     0.9981    0.9981    0.9981     18294

[[4543    0    1    0]
 [   4 4584    2    3]
 [  19    0 4558    1]
 [   2    1    1 4575]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.02 mins
epoch : 15|21, iter : 100|417,  loss : 0.0822
epoch : 15|21, iter : 200|417,  loss : 0.0885
epoch : 15|21, iter : 300|417,  loss : 0.0871
epoch : 15|21, iter : 400|417,  loss : 0.0884
acc : 0.9910, precision : 0.9843, recall : 0.9830, f1_score : 0.9836
train_loss : 0.0885
eval_loss : 0.1287
acc : 0.9900, precision : 0.9624, recall : 0.9799, f1_score : 0.9711
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9306    0.9395    0.9350      5637
           1     0.9729    0.9688    0.9709     12657

    accuracy                         0.9598     18294
   macro avg     0.9518    0.9541    0.9529     18294
weighted avg     0.9599    0.9598    0.9598     18294

[[ 5296   341]
 [  395 12262]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9978    0.9991    0.9985      4544
           1     0.9989    0.9987    0.9988      4593
           2     0.9987    0.9991    0.9989      4578
           3     0.9991    0.9976    0.9984      4579

    accuracy                         0.9986     18294
   macro avg     0.9986    0.9986    0.9986     18294
weighted avg     0.9986    0.9986    0.9986     18294

[[4540    0    3    1]
 [   3 4587    1    2]
 [   3    0 4574    1]
 [   4    5    2 4568]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.02 mins
epoch : 16|21, iter : 100|417,  loss : 0.0566
epoch : 16|21, iter : 200|417,  loss : 0.0576
epoch : 16|21, iter : 300|417,  loss : 0.0589
epoch : 16|21, iter : 400|417,  loss : 0.0579
acc : 0.9945, precision : 0.9912, recall : 0.9889, f1_score : 0.9901
train_loss : 0.0584
eval_loss : 0.1317
acc : 0.9908, precision : 0.9670, recall : 0.9796, f1_score : 0.9732
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9258    0.9493    0.9374      5637
           1     0.9771    0.9661    0.9716     12657

    accuracy                         0.9609     18294
   macro avg     0.9515    0.9577    0.9545     18294
weighted avg     0.9613    0.9609    0.9610     18294

[[ 5351   286]
 [  429 12228]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9980    0.9998    0.9989      4544
           1     1.0000    0.9991    0.9996      4593
           2     0.9991    0.9980    0.9986      4578
           3     0.9993    0.9996    0.9995      4579

    accuracy                         0.9991     18294
   macro avg     0.9991    0.9991    0.9991     18294
weighted avg     0.9991    0.9991    0.9991     18294

[[4543    0    1    0]
 [   0 4589    3    1]
 [   7    0 4569    2]
 [   2    0    0 4577]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.01 mins
epoch : 17|21, iter : 100|417,  loss : 0.0405
epoch : 17|21, iter : 200|417,  loss : 0.0458
epoch : 17|21, iter : 300|417,  loss : 0.0461
epoch : 17|21, iter : 400|417,  loss : 0.0479
acc : 0.9957, precision : 0.9931, recall : 0.9914, f1_score : 0.9922
train_loss : 0.0480
eval_loss : 0.1372
acc : 0.9908, precision : 0.9690, recall : 0.9777, f1_score : 0.9734
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9238    0.9482    0.9358      5637
           1     0.9767    0.9652    0.9709     12657

    accuracy                         0.9599     18294
   macro avg     0.9502    0.9567    0.9534     18294
weighted avg     0.9604    0.9599    0.9601     18294

[[ 5345   292]
 [  441 12216]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9980    0.9993    0.9987      4544
           1     1.0000    0.9998    0.9999      4593
           2     0.9991    0.9980    0.9986      4578
           3     0.9998    0.9998    0.9998      4579

    accuracy                         0.9992     18294
   macro avg     0.9992    0.9992    0.9992     18294
weighted avg     0.9992    0.9992    0.9992     18294

[[4541    0    3    0]
 [   0 4592    1    0]
 [   8    0 4569    1]
 [   1    0    0 4578]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.00 mins
epoch : 18|21, iter : 100|417,  loss : 0.0409
epoch : 18|21, iter : 200|417,  loss : 0.0440
epoch : 18|21, iter : 300|417,  loss : 0.0472
epoch : 18|21, iter : 400|417,  loss : 0.0469
acc : 0.9952, precision : 0.9919, recall : 0.9908, f1_score : 0.9913
train_loss : 0.0473
eval_loss : 0.1417
acc : 0.9913, precision : 0.9782, recall : 0.9707, f1_score : 0.9744
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9186    0.9535    0.9358      5637
           1     0.9789    0.9624    0.9706     12657

    accuracy                         0.9597     18294
   macro avg     0.9488    0.9580    0.9532     18294
weighted avg     0.9604    0.9597    0.9599     18294

[[ 5375   262]
 [  476 12181]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9996    0.9989      4544
           1     0.9996    0.9987    0.9991      4593
           2     0.9993    0.9978    0.9986      4578
           3     0.9985    0.9996    0.9990      4579

    accuracy                         0.9989     18294
   macro avg     0.9989    0.9989    0.9989     18294
weighted avg     0.9989    0.9989    0.9989     18294

[[4542    0    2    0]
 [   0 4587    1    5]
 [   7    1 4568    2]
 [   1    1    0 4577]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.03 mins
epoch : 19|21, iter : 100|417,  loss : 0.0351
epoch : 19|21, iter : 200|417,  loss : 0.0379
epoch : 19|21, iter : 300|417,  loss : 0.0396
epoch : 19|21, iter : 400|417,  loss : 0.0415
acc : 0.9962, precision : 0.9938, recall : 0.9926, f1_score : 0.9932
train_loss : 0.0413
eval_loss : 0.1606
acc : 0.9904, precision : 0.9720, recall : 0.9723, f1_score : 0.9721
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9206    0.9443    0.9323      5637
           1     0.9749    0.9637    0.9693     12657

    accuracy                         0.9577     18294
   macro avg     0.9478    0.9540    0.9508     18294
weighted avg     0.9582    0.9577    0.9579     18294

[[ 5323   314]
 [  459 12198]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9989    0.9986      4544
           1     0.9970    0.9993    0.9982      4593
           2     0.9987    0.9987    0.9987      4578
           3     0.9996    0.9965    0.9980      4579

    accuracy                         0.9984     18294
   macro avg     0.9984    0.9984    0.9984     18294
weighted avg     0.9984    0.9984    0.9984     18294

[[4539    1    4    0]
 [   1 4590    1    1]
 [   5    0 4572    1]
 [   2   13    1 4563]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.00 mins
epoch : 20|21, iter : 100|417,  loss : 0.0356
epoch : 20|21, iter : 200|417,  loss : 0.0361
epoch : 20|21, iter : 300|417,  loss : 0.0374
epoch : 20|21, iter : 400|417,  loss : 0.0394
acc : 0.9961, precision : 0.9939, recall : 0.9919, f1_score : 0.9929
train_loss : 0.0397
eval_loss : 0.1609
acc : 0.9895, precision : 0.9560, recall : 0.9837, f1_score : 0.9697
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9507    0.9074    0.9286      5637
           1     0.9596    0.9791    0.9692     12657

    accuracy                         0.9570     18294
   macro avg     0.9552    0.9432    0.9489     18294
weighted avg     0.9569    0.9570    0.9567     18294

[[ 5115   522]
 [  265 12392]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9985    0.9986      4544
           1     0.9987    0.9993    0.9990      4593
           2     0.9993    0.9987    0.9990      4578
           3     0.9989    0.9991    0.9990      4579

    accuracy                         0.9989     18294
   macro avg     0.9989    0.9989    0.9989     18294
weighted avg     0.9989    0.9989    0.9989     18294

[[4537    3    2    2]
 [   1 4590    1    1]
 [   4    0 4572    2]
 [   1    3    0 4575]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.05 mins
epoch : 21|21, iter : 100|417,  loss : 0.0326
epoch : 21|21, iter : 200|417,  loss : 0.0343
epoch : 21|21, iter : 300|417,  loss : 0.0362
epoch : 21|21, iter : 400|417,  loss : 0.0371
acc : 0.9966, precision : 0.9946, recall : 0.9930, f1_score : 0.9938
train_loss : 0.0373
eval_loss : 0.1940
acc : 0.9895, precision : 0.9650, recall : 0.9742, f1_score : 0.9696
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8943    0.9500    0.9213      5637
           1     0.9771    0.9500    0.9633     12657

    accuracy                         0.9500     18294
   macro avg     0.9357    0.9500    0.9423     18294
weighted avg     0.9516    0.9500    0.9504     18294

[[ 5355   282]
 [  633 12024]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9991    0.9956    0.9974      4544
           1     0.9991    0.9987    0.9989      4593
           2     0.9954    0.9993    0.9974      4578
           3     0.9989    0.9989    0.9989      4579

    accuracy                         0.9981     18294
   macro avg     0.9981    0.9981    0.9981     18294
weighted avg     0.9981    0.9981    0.9981     18294

[[4524    1   19    0]
 [   1 4587    1    4]
 [   2    0 4575    1]
 [   1    3    1 4574]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.00 mins
