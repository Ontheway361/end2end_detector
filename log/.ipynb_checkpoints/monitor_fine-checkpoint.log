----------------Environment Versions----------------
- Python: 3.7.3 
- PyTorch: 1.1.0
- TorchVison: 0.3.0
- device: True
----------------------------------------------------
Parallel mode was going ...
Resuming the train process at  13 epoches ...
Model loading was finished ...
After data augmentation, 18226 rows added.
After data augmentation,   0 rows added.
Data loading was finished ...
epoch : 13|21, iter : 200|711,  loss : 0.1116
epoch : 13|21, iter : 400|711,  loss : 0.1186
epoch : 13|21, iter : 600|711,  loss : 0.1203
acc : 0.9897, precision : 0.9817, recall : 0.9810, f1_score : 0.9813
train_loss : 0.1205
eval_loss : 0.1454
acc : 0.9907, precision : 0.9758, recall : 0.9695, f1_score : 0.9726
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9362    0.9476    0.9418      9674
           1     0.9763    0.9710    0.9736     21515

    accuracy                         0.9637     31189
   macro avg     0.9562    0.9593    0.9577     31189
weighted avg     0.9639    0.9637    0.9638     31189

[[ 9167   507]
 [  625 20890]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9977    0.9974    0.9975      7745
           1     0.9973    0.9974    0.9974      7789
           2     0.9977    0.9972    0.9975      7869
           3     0.9974    0.9981    0.9978      7786

    accuracy                         0.9975     31189
   macro avg     0.9975    0.9975    0.9975     31189
weighted avg     0.9975    0.9975    0.9975     31189

[[7725    5   10    5]
 [   4 7769    5   11]
 [  12    6 7847    4]
 [   2   10    3 7771]]
-------------------------------------------------------------------------------------
Single epoch cost time : 13.56 mins
****************sota | loss : 0.1454 | f1_score : 0.9726****************
epoch : 14|21, iter : 200|711,  loss : 0.1160
epoch : 14|21, iter : 400|711,  loss : 0.1166
epoch : 14|21, iter : 600|711,  loss : 0.1186
acc : 0.9900, precision : 0.9821, recall : 0.9819, f1_score : 0.9820
train_loss : 0.1183
eval_loss : 0.1459
acc : 0.9909, precision : 0.9833, recall : 0.9629, f1_score : 0.9730
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9215    0.9630    0.9418      9674
           1     0.9830    0.9631    0.9730     21515

    accuracy                         0.9631     31189
   macro avg     0.9522    0.9630    0.9574     31189
weighted avg     0.9639    0.9631    0.9633     31189

[[ 9316   358]
 [  794 20721]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9977    0.9972    0.9974      7745
           1     0.9979    0.9958    0.9969      7789
           2     0.9981    0.9973    0.9977      7869
           3     0.9954    0.9988    0.9971      7786

    accuracy                         0.9973     31189
   macro avg     0.9973    0.9973    0.9973     31189
weighted avg     0.9973    0.9973    0.9973     31189

[[7723    7    5   10]
 [   5 7756    7   21]
 [  11    5 7848    5]
 [   2    4    3 7777]]
-------------------------------------------------------------------------------------
Single epoch cost time : 38.86 mins
epoch : 15|21, iter : 200|711,  loss : 0.1063
epoch : 15|21, iter : 400|711,  loss : 0.1084
epoch : 15|21, iter : 600|711,  loss : 0.1102
acc : 0.9906, precision : 0.9833, recall : 0.9827, f1_score : 0.9830
train_loss : 0.1122
eval_loss : 0.1595
acc : 0.9903, precision : 0.9665, recall : 0.9769, f1_score : 0.9716
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9500    0.9171    0.9333      9674
           1     0.9633    0.9783    0.9707     21515

    accuracy                         0.9593     31189
   macro avg     0.9566    0.9477    0.9520     31189
weighted avg     0.9592    0.9593    0.9591     31189

[[ 8872   802]
 [  467 21048]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9981    0.9948    0.9964      7745
           1     0.9962    0.9969    0.9965      7789
           2     0.9990    0.9949    0.9969      7869
           3     0.9923    0.9988    0.9956      7786

    accuracy                         0.9964     31189
   macro avg     0.9964    0.9964    0.9964     31189
weighted avg     0.9964    0.9964    0.9964     31189

[[7705   16    3   21]
 [   1 7765    3   20]
 [  12    9 7829   19]
 [   2    5    2 7777]]
-------------------------------------------------------------------------------------
Single epoch cost time : 27.62 mins
epoch : 16|21, iter : 200|711,  loss : 0.1021
epoch : 16|21, iter : 400|711,  loss : 0.1056
epoch : 16|21, iter : 600|711,  loss : 0.1090
acc : 0.9904, precision : 0.9830, recall : 0.9823, f1_score : 0.9826
train_loss : 0.1110
eval_loss : 0.1378
acc : 0.9914, precision : 0.9653, recall : 0.9849, f1_score : 0.9750
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9604    0.9246    0.9422      9674
           1     0.9667    0.9828    0.9747     21515

    accuracy                         0.9648     31189
   macro avg     0.9635    0.9537    0.9584     31189
weighted avg     0.9647    0.9648    0.9646     31189

[[ 8945   729]
 [  369 21146]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9977    0.9975    0.9976      7745
           1     0.9976    0.9981    0.9978      7789
           2     0.9985    0.9967    0.9976      7869
           3     0.9969    0.9983    0.9976      7786

    accuracy                         0.9977     31189
   macro avg     0.9977    0.9977    0.9977     31189
weighted avg     0.9977    0.9977    0.9977     31189

[[7726    6    6    7]
 [   2 7774    4    9]
 [  14    4 7843    8]
 [   2    9    2 7773]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.81 mins
****************sota | loss : 0.1378 | f1_score : 0.9750****************
epoch : 17|21, iter : 200|711,  loss : 0.1055
epoch : 17|21, iter : 400|711,  loss : 0.1063
epoch : 17|21, iter : 600|711,  loss : 0.1071
acc : 0.9912, precision : 0.9846, recall : 0.9836, f1_score : 0.9841
train_loss : 0.1081
eval_loss : 0.1461
acc : 0.9916, precision : 0.9892, recall : 0.9610, f1_score : 0.9749
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9144    0.9764    0.9444      9674
           1     0.9891    0.9589    0.9738     21515

    accuracy                         0.9643     31189
   macro avg     0.9517    0.9677    0.9591     31189
weighted avg     0.9659    0.9643    0.9647     31189

[[ 9446   228]
 [  884 20631]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9979    0.9979    0.9979      7745
           1     0.9981    0.9981    0.9981      7789
           2     0.9985    0.9978    0.9982      7869
           3     0.9977    0.9983    0.9980      7786

    accuracy                         0.9980     31189
   macro avg     0.9980    0.9980    0.9980     31189
weighted avg     0.9980    0.9980    0.9980     31189

[[7729    5    6    5]
 [   4 7774    3    8]
 [   9    3 7852    5]
 [   3    7    3 7773]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.38 mins
epoch : 18|21, iter : 200|711,  loss : 0.1027
epoch : 18|21, iter : 400|711,  loss : 0.1056
epoch : 18|21, iter : 600|711,  loss : 0.1080
acc : 0.9910, precision : 0.9840, recall : 0.9836, f1_score : 0.9838
train_loss : 0.1073
eval_loss : 0.1451
acc : 0.9903, precision : 0.9714, recall : 0.9714, f1_score : 0.9714
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9298    0.9598    0.9446      9674
           1     0.9817    0.9674    0.9745     21515

    accuracy                         0.9651     31189
   macro avg     0.9557    0.9636    0.9595     31189
weighted avg     0.9656    0.9651    0.9652     31189

[[ 9285   389]
 [  701 20814]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9915    0.9988    0.9952      7745
           1     0.9963    0.9954    0.9958      7789
           2     0.9973    0.9947    0.9960      7869
           3     0.9987    0.9950    0.9968      7786

    accuracy                         0.9960     31189
   macro avg     0.9960    0.9960    0.9960     31189
weighted avg     0.9960    0.9960    0.9960     31189

[[7736    5    0    4]
 [  20 7753   14    2]
 [  35    3 7827    4]
 [  11   21    7 7747]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.75 mins
epoch : 19|21, iter : 200|711,  loss : 0.1027
epoch : 19|21, iter : 400|711,  loss : 0.1041
epoch : 19|21, iter : 600|711,  loss : 0.1035
acc : 0.9916, precision : 0.9850, recall : 0.9849, f1_score : 0.9849
train_loss : 0.1040
eval_loss : 0.1348
acc : 0.9905, precision : 0.9887, recall : 0.9550, f1_score : 0.9716
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9372    0.9496    0.9433      9674
           1     0.9772    0.9714    0.9743     21515

    accuracy                         0.9646     31189
   macro avg     0.9572    0.9605    0.9588     31189
weighted avg     0.9648    0.9646    0.9647     31189

[[ 9186   488]
 [  616 20899]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9977    0.9979      7745
           1     0.9977    0.9979    0.9978      7789
           2     0.9985    0.9976    0.9980      7869
           3     0.9970    0.9982    0.9976      7786

    accuracy                         0.9979     31189
   macro avg     0.9979    0.9979    0.9979     31189
weighted avg     0.9979    0.9979    0.9979     31189

[[7727    5    7    6]
 [   3 7773    3   10]
 [   9    3 7850    7]
 [   2   10    2 7772]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.45 mins
epoch : 20|21, iter : 200|711,  loss : 0.0962
epoch : 20|21, iter : 400|711,  loss : 0.0987
epoch : 20|21, iter : 600|711,  loss : 0.1016
acc : 0.9913, precision : 0.9850, recall : 0.9835, f1_score : 0.9843
train_loss : 0.1024
eval_loss : 0.1420
acc : 0.9909, precision : 0.9872, recall : 0.9590, f1_score : 0.9729
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9196    0.9674    0.9429      9674
           1     0.9850    0.9620    0.9734     21515

    accuracy                         0.9637     31189
   macro avg     0.9523    0.9647    0.9581     31189
weighted avg     0.9647    0.9637    0.9639     31189

[[ 9359   315]
 [  818 20697]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9973    0.9980      7745
           1     0.9965    0.9988    0.9977      7789
           2     0.9978    0.9983    0.9981      7869
           3     0.9985    0.9970    0.9978      7786

    accuracy                         0.9979     31189
   macro avg     0.9979    0.9979    0.9979     31189
weighted avg     0.9979    0.9979    0.9979     31189

[[7724    7    8    6]
 [   1 7780    6    2]
 [   6    3 7856    4]
 [   3   17    3 7763]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.01 mins
epoch : 21|21, iter : 200|711,  loss : 0.1008
epoch : 21|21, iter : 400|711,  loss : 0.1040
epoch : 21|21, iter : 600|711,  loss : 0.1020
acc : 0.9914, precision : 0.9846, recall : 0.9844, f1_score : 0.9845
train_loss : 0.1034
eval_loss : 0.1304
acc : 0.9918, precision : 0.9748, recall : 0.9770, f1_score : 0.9759
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9451    0.9522    0.9487      9674
           1     0.9785    0.9751    0.9768     21515

    accuracy                         0.9680     31189
   macro avg     0.9618    0.9637    0.9627     31189
weighted avg     0.9681    0.9680    0.9681     31189

[[ 9212   462]
 [  535 20980]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9988    0.9952    0.9970      7745
           1     0.9973    0.9985    0.9979      7789
           2     0.9954    0.9982    0.9968      7869
           3     0.9983    0.9979    0.9981      7786

    accuracy                         0.9975     31189
   macro avg     0.9975    0.9975    0.9975     31189
weighted avg     0.9975    0.9975    0.9975     31189

[[7708    6   27    4]
 [   2 7777    6    4]
 [   5    4 7855    5]
 [   2   11    3 7770]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.01 mins
****************sota | loss : 0.1304 | f1_score : 0.9759****************
