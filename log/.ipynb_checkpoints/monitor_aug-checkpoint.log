----------------Environment Versions----------------
- Python: 3.7.3 
- PyTorch: 1.1.0
- TorchVison: 0.3.0
- device: True
----------------------------------------------------
Parallel mode was going ...
Model loading was finished ...
After data augmentation, 18226 rows added.
After data augmentation,   0 rows added.
Data loading was finished ...
epoch :  1|21, iter : 200|711,  loss : 0.9899
epoch :  1|21, iter : 400|711,  loss : 0.6863
epoch :  1|21, iter : 600|711,  loss : 0.5452
acc : 0.9176, precision : 0.8088, recall : 0.9201, f1_score : 0.8609
train_loss : 0.4941
eval_loss : 0.2598
acc : 0.9835, precision : 0.9337, recall : 0.9720, f1_score : 0.9524
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8789    0.8940    0.8864      9674
           1     0.9520    0.9446    0.9483     21515

    accuracy                         0.9289     31189
   macro avg     0.9154    0.9193    0.9173     31189
weighted avg     0.9293    0.9289    0.9291     31189

[[ 8649  1025]
 [ 1192 20323]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9921    0.9921    0.9921      7745
           1     0.9983    0.9571    0.9773      7789
           2     0.9755    0.9980    0.9866      7869
           3     0.9780    0.9956    0.9868      7786

    accuracy                         0.9857     31189
   macro avg     0.9860    0.9857    0.9857     31189
weighted avg     0.9860    0.9857    0.9857     31189

[[7684    5   43   13]
 [  48 7455  129  157]
 [   9    3 7853    4]
 [   4    5   25 7752]]
-------------------------------------------------------------------------------------
Single epoch cost time : 13.92 mins
****************ota | loss : 0.2598 | f1_score : 0.9524****************
epoch :  2|21, iter : 200|711,  loss : 0.1909
epoch :  2|21, iter : 400|711,  loss : 0.1856
epoch :  2|21, iter : 600|711,  loss : 0.1803
acc : 0.9818, precision : 0.9672, recall : 0.9673, f1_score : 0.9672
train_loss : 0.1791
eval_loss : 0.2457
acc : 0.9853, precision : 0.9751, recall : 0.9373, f1_score : 0.9559
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8230    0.9807    0.8950      9674
           1     0.9905    0.9052    0.9459     21515

    accuracy                         0.9286     31189
   macro avg     0.9068    0.9429    0.9204     31189
weighted avg     0.9385    0.9286    0.9301     31189

[[ 9487   187]
 [ 2040 19475]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9772    0.9965    0.9868      7745
           1     0.9978    0.9828    0.9902      7789
           2     0.9888    0.9910    0.9899      7869
           3     0.9960    0.9892    0.9926      7786

    accuracy                         0.9899     31189
   macro avg     0.9900    0.9899    0.9899     31189
weighted avg     0.9900    0.9899    0.9899     31189

[[7718    5   18    4]
 [  75 7655   35   24]
 [  64    4 7798    3]
 [  41    8   35 7702]]
-------------------------------------------------------------------------------------
Single epoch cost time : 12.73 mins
****************ota | loss : 0.2457 | f1_score : 0.9559****************
epoch :  3|21, iter : 200|711,  loss : 0.1621
epoch :  3|21, iter : 400|711,  loss : 0.1571
epoch :  3|21, iter : 600|711,  loss : 0.1548
acc : 0.9845, precision : 0.9719, recall : 0.9720, f1_score : 0.9720
train_loss : 0.1544
eval_loss : 0.2609
acc : 0.9819, precision : 0.9139, recall : 0.9868, f1_score : 0.9490
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9734    0.7936    0.8743      9674
           1     0.9143    0.9902    0.9508     21515

    accuracy                         0.9292     31189
   macro avg     0.9438    0.8919    0.9125     31189
weighted avg     0.9326    0.9292    0.9270     31189

[[ 7677  1997]
 [  210 21305]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9825    0.9982    0.9903      7745
           1     0.9983    0.9755    0.9868      7789
           2     0.9986    0.9834    0.9909      7869
           3     0.9769    0.9987    0.9877      7786

    accuracy                         0.9889     31189
   macro avg     0.9891    0.9889    0.9889     31189
weighted avg     0.9891    0.9889    0.9889     31189

[[7731    5    1    8]
 [  44 7598    8  139]
 [  89    5 7738   37]
 [   5    3    2 7776]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.23 mins
epoch :  4|21, iter : 200|711,  loss : 0.1373
epoch :  4|21, iter : 400|711,  loss : 0.1412
epoch :  4|21, iter : 600|711,  loss : 0.1443
acc : 0.9862, precision : 0.9749, recall : 0.9753, f1_score : 0.9751
train_loss : 0.1442
eval_loss : 0.1511
acc : 0.9876, precision : 0.9893, recall : 0.9371, f1_score : 0.9625
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9056    0.9636    0.9337      9674
           1     0.9832    0.9548    0.9688     21515

    accuracy                         0.9575     31189
   macro avg     0.9444    0.9592    0.9512     31189
weighted avg     0.9591    0.9575    0.9579     31189

[[ 9322   352]
 [  972 20543]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9933    0.9957      7745
           1     0.9911    0.9982    0.9946      7789
           2     0.9913    0.9977    0.9945      7869
           3     0.9978    0.9890    0.9934      7786

    accuracy                         0.9945     31189
   macro avg     0.9946    0.9945    0.9946     31189
weighted avg     0.9946    0.9945    0.9945     31189

[[7693    7   37    8]
 [   4 7775    7    3]
 [   8    4 7851    6]
 [   2   59   25 7700]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.08 mins
****************ota | loss : 0.1511 | f1_score : 0.9625****************
epoch :  5|21, iter : 200|711,  loss : 0.1380
epoch :  5|21, iter : 400|711,  loss : 0.1362
epoch :  5|21, iter : 600|711,  loss : 0.1363
acc : 0.9863, precision : 0.9758, recall : 0.9749, f1_score : 0.9753
train_loss : 0.1356
eval_loss : 0.1635
acc : 0.9862, precision : 0.9422, recall : 0.9789, f1_score : 0.9602
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8982    0.9517    0.9242      9674
           1     0.9777    0.9515    0.9644     21515

    accuracy                         0.9516     31189
   macro avg     0.9379    0.9516    0.9443     31189
weighted avg     0.9530    0.9516    0.9519     31189

[[ 9207   467]
 [ 1044 20471]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9866    0.9981    0.9923      7745
           1     0.9978    0.9938    0.9958      7789
           2     0.9978    0.9966    0.9972      7869
           3     0.9966    0.9904    0.9935      7786

    accuracy                         0.9947     31189
   macro avg     0.9947    0.9947    0.9947     31189
weighted avg     0.9947    0.9947    0.9947     31189

[[7730    5    6    4]
 [  23 7741    7   18]
 [  19    4 7842    4]
 [  63    8    4 7711]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.06 mins
epoch :  6|21, iter : 200|711,  loss : 0.1247
epoch :  6|21, iter : 400|711,  loss : 0.1273
epoch :  6|21, iter : 600|711,  loss : 0.1289
acc : 0.9867, precision : 0.9758, recall : 0.9761, f1_score : 0.9759
train_loss : 0.1301
eval_loss : 0.1609
acc : 0.9891, precision : 0.9869, recall : 0.9488, f1_score : 0.9675
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9108    0.9455    0.9278      9674
           1     0.9751    0.9584    0.9666     21515

    accuracy                         0.9544     31189
   macro avg     0.9429    0.9519    0.9472     31189
weighted avg     0.9551    0.9544    0.9546     31189

[[ 9147   527]
 [  896 20619]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9955    0.9978    0.9966      7745
           1     0.9974    0.9827    0.9900      7789
           2     0.9841    0.9962    0.9901      7869
           3     0.9951    0.9951    0.9951      7786

    accuracy                         0.9929     31189
   macro avg     0.9930    0.9929    0.9930     31189
weighted avg     0.9930    0.9929    0.9929     31189

[[7728    5    7    5]
 [   8 7654   98   29]
 [  23    3 7839    4]
 [   4   12   22 7748]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.06 mins
epoch :  7|21, iter : 200|711,  loss : 0.1229
epoch :  7|21, iter : 400|711,  loss : 0.1269
epoch :  7|21, iter : 600|711,  loss : 0.1241
acc : 0.9881, precision : 0.9788, recall : 0.9783, f1_score : 0.9786
train_loss : 0.1220
eval_loss : 0.1704
acc : 0.9851, precision : 0.9850, recall : 0.9264, f1_score : 0.9548
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8995    0.9523    0.9252      9674
           1     0.9780    0.9522    0.9649     21515

    accuracy                         0.9522     31189
   macro avg     0.9388    0.9523    0.9450     31189
weighted avg     0.9537    0.9522    0.9526     31189

[[ 9213   461]
 [ 1029 20486]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9847    0.9979    0.9913      7745
           1     0.9974    0.9904    0.9939      7789
           2     0.9943    0.9919    0.9931      7869
           3     0.9965    0.9927    0.9946      7786

    accuracy                         0.9932     31189
   macro avg     0.9932    0.9932    0.9932     31189
weighted avg     0.9932    0.9932    0.9932     31189

[[7729    5    7    4]
 [  36 7714   21   18]
 [  55    4 7805    5]
 [  29   11   17 7729]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.06 mins
epoch :  8|21, iter : 200|711,  loss : 0.1190
epoch :  8|21, iter : 400|711,  loss : 0.1180
epoch :  8|21, iter : 600|711,  loss : 0.1201
acc : 0.9878, precision : 0.9782, recall : 0.9778, f1_score : 0.9780
train_loss : 0.1192
eval_loss : 0.1383
acc : 0.9902, precision : 0.9668, recall : 0.9759, f1_score : 0.9713
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9157    0.9541    0.9345      9674
           1     0.9790    0.9605    0.9696     21515

    accuracy                         0.9585     31189
   macro avg     0.9473    0.9573    0.9521     31189
weighted avg     0.9593    0.9585    0.9587     31189

[[ 9230   444]
 [  850 20665]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9928    0.9985    0.9956      7745
           1     0.9970    0.9968    0.9969      7789
           2     0.9934    0.9940    0.9937      7869
           3     0.9987    0.9927    0.9957      7786

    accuracy                         0.9955     31189
   macro avg     0.9955    0.9955    0.9955     31189
weighted avg     0.9955    0.9955    0.9955     31189

[[7733    5    3    4]
 [   7 7764   15    3]
 [  39    5 7822    3]
 [  10   13   34 7729]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.03 mins
****************ota | loss : 0.1383 | f1_score : 0.9713****************
epoch :  9|21, iter : 200|711,  loss : 0.1099
epoch :  9|21, iter : 400|711,  loss : 0.1146
epoch :  9|21, iter : 600|711,  loss : 0.1158
acc : 0.9880, precision : 0.9783, recall : 0.9784, f1_score : 0.9784
train_loss : 0.1167
eval_loss : 0.1382
acc : 0.9845, precision : 0.9232, recall : 0.9913, f1_score : 0.9561
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9509    0.9147    0.9325      9674
           1     0.9623    0.9788    0.9705     21515

    accuracy                         0.9589     31189
   macro avg     0.9566    0.9467    0.9515     31189
weighted avg     0.9588    0.9589    0.9587     31189

[[ 8849   825]
 [  457 21058]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9923    0.9986    0.9954      7745
           1     0.9951    0.9955    0.9953      7789
           2     0.9991    0.9940    0.9966      7869
           3     0.9974    0.9959    0.9967      7786

    accuracy                         0.9960     31189
   macro avg     0.9960    0.9960    0.9960     31189
weighted avg     0.9960    0.9960    0.9960     31189

[[7734    5    1    5]
 [  21 7754    4   10]
 [  33    9 7822    5]
 [   6   24    2 7754]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.07 mins
epoch : 10|21, iter : 200|711,  loss : 0.1085
epoch : 10|21, iter : 400|711,  loss : 0.1099
epoch : 10|21, iter : 600|711,  loss : 0.1113
acc : 0.9885, precision : 0.9793, recall : 0.9794, f1_score : 0.9793
train_loss : 0.1129
eval_loss : 0.1262
acc : 0.9908, precision : 0.9785, recall : 0.9673, f1_score : 0.9728
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9277    0.9548    0.9411      9674
           1     0.9794    0.9665    0.9729     21515

    accuracy                         0.9629     31189
   macro avg     0.9536    0.9607    0.9570     31189
weighted avg     0.9634    0.9629    0.9630     31189

[[ 9237   437]
 [  720 20795]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9966    0.9977      7745
           1     0.9963    0.9983    0.9973      7789
           2     0.9964    0.9980    0.9972      7869
           3     0.9982    0.9967    0.9974      7786

    accuracy                         0.9974     31189
   macro avg     0.9974    0.9974    0.9974     31189
weighted avg     0.9974    0.9974    0.9974     31189

[[7719    5   15    6]
 [   2 7776    9    2]
 [   6    4 7853    6]
 [   2   20    4 7760]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.00 mins
****************ota | loss : 0.1262 | f1_score : 0.9728****************
epoch : 11|21, iter : 200|711,  loss : 0.0872
epoch : 11|21, iter : 400|711,  loss : 0.0863
epoch : 11|21, iter : 600|711,  loss : 0.0861
acc : 0.9914, precision : 0.9849, recall : 0.9840, f1_score : 0.9845
train_loss : 0.0868
eval_loss : 0.1214
acc : 0.9913, precision : 0.9844, recall : 0.9644, f1_score : 0.9743
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9191    0.9743    0.9459      9674
           1     0.9881    0.9614    0.9746     21515

    accuracy                         0.9654     31189
   macro avg     0.9536    0.9678    0.9602     31189
weighted avg     0.9667    0.9654    0.9657     31189

[[ 9425   249]
 [  830 20685]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9914    0.9987    0.9950      7745
           1     0.9982    0.9982    0.9982      7789
           2     0.9986    0.9919    0.9952      7869
           3     0.9987    0.9982    0.9985      7786

    accuracy                         0.9967     31189
   macro avg     0.9967    0.9967    0.9967     31189
weighted avg     0.9967    0.9967    0.9967     31189

[[7735    5    1    4]
 [   5 7775    7    2]
 [  56    4 7805    4]
 [   6    5    3 7772]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.00 mins
****************ota | loss : 0.1214 | f1_score : 0.9743****************
epoch : 12|21, iter : 200|711,  loss : 0.0745
epoch : 12|21, iter : 400|711,  loss : 0.0826
epoch : 12|21, iter : 600|711,  loss : 0.0852
acc : 0.9922, precision : 0.9866, recall : 0.9854, f1_score : 0.9860
train_loss : 0.0850
eval_loss : 0.1138
acc : 0.9911, precision : 0.9880, recall : 0.9594, f1_score : 0.9735
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9466    0.9419    0.9442      9674
           1     0.9739    0.9761    0.9750     21515

    accuracy                         0.9655     31189
   macro avg     0.9603    0.9590    0.9596     31189
weighted avg     0.9655    0.9655    0.9655     31189

[[ 9112   562]
 [  514 21001]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9981    0.9981      7745
           1     0.9971    0.9982    0.9976      7789
           2     0.9981    0.9978    0.9980      7869
           3     0.9985    0.9977    0.9981      7786

    accuracy                         0.9979     31189
   macro avg     0.9979    0.9979    0.9979     31189
weighted avg     0.9979    0.9979    0.9979     31189

[[7730    6    4    5]
 [   1 7775    9    4]
 [  10    4 7852    3]
 [   3   13    2 7768]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.08 mins
epoch : 13|21, iter : 200|711,  loss : 0.0821
epoch : 13|21, iter : 400|711,  loss : 0.0808
epoch : 13|21, iter : 600|711,  loss : 0.0820
acc : 0.9923, precision : 0.9867, recall : 0.9855, f1_score : 0.9861
train_loss : 0.0830
eval_loss : 0.1064
acc : 0.9927, precision : 0.9824, recall : 0.9746, f1_score : 0.9785
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9401    0.9582    0.9491      9674
           1     0.9811    0.9725    0.9768     21515

    accuracy                         0.9681     31189
   macro avg     0.9606    0.9654    0.9629     31189
weighted avg     0.9683    0.9681    0.9682     31189

[[ 9270   404]
 [  591 20924]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9983    0.9983      7745
           1     0.9982    0.9978    0.9980      7789
           2     0.9978    0.9978    0.9978      7869
           3     0.9982    0.9986    0.9984      7786

    accuracy                         0.9981     31189
   macro avg     0.9981    0.9981    0.9981     31189
weighted avg     0.9981    0.9981    0.9981     31189

[[7732    6    3    4]
 [   2 7772   10    5]
 [   8    4 7852    5]
 [   3    4    4 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.96 mins
****************ota | loss : 0.1064 | f1_score : 0.9785****************
epoch : 14|21, iter : 200|711,  loss : 0.0776
epoch : 14|21, iter : 400|711,  loss : 0.0806
epoch : 14|21, iter : 600|711,  loss : 0.0804
acc : 0.9922, precision : 0.9864, recall : 0.9853, f1_score : 0.9859
train_loss : 0.0820
eval_loss : 0.1322
acc : 0.9895, precision : 0.9908, recall : 0.9475, f1_score : 0.9686
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9390    0.9316    0.9353      9674
           1     0.9693    0.9728    0.9711     21515

    accuracy                         0.9600     31189
   macro avg     0.9542    0.9522    0.9532     31189
weighted avg     0.9599    0.9600    0.9600     31189

[[ 9012   662]
 [  585 20930]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9979    0.9974    0.9977      7745
           1     0.9986    0.9960    0.9973      7789
           2     0.9972    0.9983    0.9978      7869
           3     0.9963    0.9982    0.9972      7786

    accuracy                         0.9975     31189
   macro avg     0.9975    0.9975    0.9975     31189
weighted avg     0.9975    0.9975    0.9975     31189

[[7725    5   11    4]
 [   5 7758    6   20]
 [   5    3 7856    5]
 [   6    3    5 7772]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.96 mins
epoch : 15|21, iter : 200|711,  loss : 0.0699
epoch : 15|21, iter : 400|711,  loss : 0.0719
epoch : 15|21, iter : 600|711,  loss : 0.0757
acc : 0.9928, precision : 0.9874, recall : 0.9866, f1_score : 0.9870
train_loss : 0.0773
eval_loss : 0.1078
acc : 0.9915, precision : 0.9669, recall : 0.9836, f1_score : 0.9752
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9451    0.9535    0.9493      9674
           1     0.9790    0.9751    0.9770     21515

    accuracy                         0.9684     31189
   macro avg     0.9620    0.9643    0.9632     31189
weighted avg     0.9685    0.9684    0.9684     31189

[[ 9224   450]
 [  536 20979]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9990    0.9965    0.9977      7745
           1     0.9981    0.9982    0.9981      7789
           2     0.9968    0.9986    0.9977      7869
           3     0.9981    0.9986    0.9983      7786

    accuracy                         0.9980     31189
   macro avg     0.9980    0.9980    0.9980     31189
weighted avg     0.9980    0.9980    0.9980     31189

[[7718    5   17    5]
 [   1 7775    6    7]
 [   5    3 7858    3]
 [   2    7    2 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.04 mins
epoch : 16|21, iter : 200|711,  loss : 0.0579
epoch : 16|21, iter : 400|711,  loss : 0.0573
epoch : 16|21, iter : 600|711,  loss : 0.0589
acc : 0.9952, precision : 0.9919, recall : 0.9906, f1_score : 0.9912
train_loss : 0.0589
eval_loss : 0.1085
acc : 0.9923, precision : 0.9818, recall : 0.9729, f1_score : 0.9773
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9468    0.9536    0.9502      9674
           1     0.9791    0.9759    0.9775     21515

    accuracy                         0.9690     31189
   macro avg     0.9629    0.9648    0.9638     31189
weighted avg     0.9691    0.9690    0.9690     31189

[[ 9225   449]
 [  518 20997]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9979    0.9986    0.9983      7745
           1     0.9982    0.9983    0.9983      7789
           2     0.9987    0.9977    0.9982      7869
           3     0.9982    0.9985    0.9983      7786

    accuracy                         0.9983     31189
   macro avg     0.9983    0.9983    0.9983     31189
weighted avg     0.9983    0.9983    0.9983     31189

[[7734    5    2    4]
 [   2 7776    5    6]
 [  11    3 7851    4]
 [   3    6    3 7774]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.98 mins
epoch : 17|21, iter : 200|711,  loss : 0.0475
epoch : 17|21, iter : 400|711,  loss : 0.0529
epoch : 17|21, iter : 600|711,  loss : 0.0536
acc : 0.9956, precision : 0.9928, recall : 0.9912, f1_score : 0.9920
train_loss : 0.0544
eval_loss : 0.1088
acc : 0.9922, precision : 0.9774, recall : 0.9770, f1_score : 0.9772
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9559    0.9460    0.9510      9674
           1     0.9759    0.9804    0.9781     21515

    accuracy                         0.9697     31189
   macro avg     0.9659    0.9632    0.9645     31189
weighted avg     0.9697    0.9697    0.9697     31189

[[ 9152   522]
 [  422 21093]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9988    0.9985    0.9986      7745
           1     0.9976    0.9983    0.9979      7789
           2     0.9992    0.9961    0.9976      7869
           3     0.9958    0.9986    0.9972      7786

    accuracy                         0.9979     31189
   macro avg     0.9979    0.9979    0.9979     31189
weighted avg     0.9979    0.9979    0.9979     31189

[[7733    6    1    5]
 [   1 7776    3    9]
 [   6    6 7838   19]
 [   2    7    2 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.95 mins
epoch : 18|21, iter : 200|711,  loss : 0.0462
epoch : 18|21, iter : 400|711,  loss : 0.0493
epoch : 18|21, iter : 600|711,  loss : 0.0516
acc : 0.9958, precision : 0.9932, recall : 0.9917, f1_score : 0.9924
train_loss : 0.0510
eval_loss : 0.1169
acc : 0.9917, precision : 0.9754, recall : 0.9761, f1_score : 0.9757
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9416    0.9561    0.9488      9674
           1     0.9801    0.9733    0.9767     21515

    accuracy                         0.9680     31189
   macro avg     0.9608    0.9647    0.9627     31189
weighted avg     0.9682    0.9680    0.9680     31189

[[ 9249   425]
 [  574 20941]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9986    0.9984      7745
           1     0.9983    0.9981    0.9982      7789
           2     0.9991    0.9975    0.9983      7869
           3     0.9974    0.9990    0.9982      7786

    accuracy                         0.9983     31189
   macro avg     0.9983    0.9983    0.9983     31189
weighted avg     0.9983    0.9983    0.9983     31189

[[7734    5    1    5]
 [   2 7774    4    9]
 [  10    4 7849    6]
 [   2    4    2 7778]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.04 mins
epoch : 19|21, iter : 200|711,  loss : 0.0469
epoch : 19|21, iter : 400|711,  loss : 0.0480
epoch : 19|21, iter : 600|711,  loss : 0.0490
acc : 0.9960, precision : 0.9935, recall : 0.9920, f1_score : 0.9928
train_loss : 0.0494
eval_loss : 0.1146
acc : 0.9917, precision : 0.9839, recall : 0.9671, f1_score : 0.9754
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9378    0.9594    0.9484      9674
           1     0.9815    0.9714    0.9764     21515

    accuracy                         0.9676     31189
   macro avg     0.9597    0.9654    0.9624     31189
weighted avg     0.9680    0.9676    0.9677     31189

[[ 9281   393]
 [  616 20899]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9979    0.9985    0.9982      7745
           1     0.9982    0.9985    0.9983      7789
           2     0.9989    0.9973    0.9981      7869
           3     0.9978    0.9986    0.9982      7786

    accuracy                         0.9982     31189
   macro avg     0.9982    0.9982    0.9982     31189
weighted avg     0.9982    0.9982    0.9982     31189

[[7733    5    2    5]
 [   2 7777    4    6]
 [  11    4 7848    6]
 [   3    5    3 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.00 mins
epoch : 20|21, iter : 200|711,  loss : 0.0427
epoch : 20|21, iter : 400|711,  loss : 0.0433
epoch : 20|21, iter : 600|711,  loss : 0.0439
acc : 0.9964, precision : 0.9940, recall : 0.9928, f1_score : 0.9934
train_loss : 0.0450
eval_loss : 0.1135
acc : 0.9924, precision : 0.9800, recall : 0.9755, f1_score : 0.9777
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9441    0.9562    0.9501      9674
           1     0.9802    0.9745    0.9773     21515

    accuracy                         0.9688     31189
   macro avg     0.9621    0.9654    0.9637     31189
weighted avg     0.9690    0.9688    0.9689     31189

[[ 9250   424]
 [  548 20967]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9983    0.9985      7745
           1     0.9982    0.9981    0.9981      7789
           2     0.9982    0.9981    0.9982      7869
           3     0.9981    0.9986    0.9983      7786

    accuracy                         0.9983     31189
   macro avg     0.9983    0.9983    0.9983     31189
weighted avg     0.9983    0.9983    0.9983     31189

[[7732    5    3    5]
 [   1 7774    8    6]
 [   8    3 7854    4]
 [   2    6    3 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.03 mins
epoch : 21|21, iter : 200|711,  loss : 0.0383
epoch : 21|21, iter : 400|711,  loss : 0.0411
epoch : 21|21, iter : 600|711,  loss : 0.0424
acc : 0.9965, precision : 0.9943, recall : 0.9930, f1_score : 0.9937
train_loss : 0.0430
eval_loss : 0.1187
acc : 0.9915, precision : 0.9833, recall : 0.9665, f1_score : 0.9749
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9483    0.9470    0.9477      9674
           1     0.9762    0.9768    0.9765     21515

    accuracy                         0.9676     31189
   macro avg     0.9623    0.9619    0.9621     31189
weighted avg     0.9675    0.9676    0.9675     31189

[[ 9161   513]
 [  499 21016]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9981    0.9982      7745
           1     0.9976    0.9986    0.9981      7789
           2     0.9985    0.9980    0.9982      7869
           3     0.9983    0.9981    0.9982      7786

    accuracy                         0.9982     31189
   macro avg     0.9982    0.9982    0.9982     31189
weighted avg     0.9982    0.9982    0.9982     31189

[[7730    5    5    5]
 [   1 7778    5    5]
 [  10    3 7853    3]
 [   2   11    2 7771]]
-------------------------------------------------------------------------------------
Single epoch cost time : 3.92 mins
