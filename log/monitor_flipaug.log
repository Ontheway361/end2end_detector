----------------Environment Versions----------------
- Python    : 3.7.3 
- PyTorch   : 1.1.0
- TorchVison: 0.3.0
- GPU_device: True
----------------------------------------------------
Parallel mode was going ...
Model loading was finished ...
After data augmentation, 72773 rows added.
After data augmentation,   0 rows added.
Data loading was finished ...
epoch :  1|30, iter : 200|1138,  loss : 1.1207
epoch :  1|30, iter : 400|1138,  loss : 0.7691
epoch :  1|30, iter : 600|1138,  loss : 0.6026
epoch :  1|30, iter : 800|1138,  loss : 0.5108
epoch :  1|30, iter : 1000|1138,  loss : 0.4482
acc : 0.9584, precision : 0.8677, recall : 0.8963, f1_score : 0.8818
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8349    0.7502    0.7903     45524
           1     0.8913    0.9325    0.9114    100022

    accuracy                         0.8755    145546
   macro avg     0.8631    0.8413    0.8509    145546
weighted avg     0.8737    0.8755    0.8735    145546

[[34153 11371]
 [ 6756 93266]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9631    0.9548    0.9589     36452
           1     0.9481    0.9600    0.9540     36422
           2     0.9455    0.9610    0.9532     36462
           3     0.9690    0.9493    0.9590     36210

    accuracy                         0.9563    145546
   macro avg     0.9564    0.9563    0.9563    145546
weighted avg     0.9564    0.9563    0.9563    145546

[[34804   527   831   290]
 [  342 34965   574   541]
 [  548   606 35039   269]
 [  442   780   614 34374]]
-------------------------------------------------------------------------------------
train_loss : 0.4168
eval_loss : 0.2337
acc : 0.9845, precision : 0.9836, recall : 0.9244, f1_score : 0.9530
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8553    0.9382    0.8948      9674
           1     0.9709    0.9286    0.9493     21515

    accuracy                         0.9316     31189
   macro avg     0.9131    0.9334    0.9221     31189
weighted avg     0.9351    0.9316    0.9324     31189

[[ 9076   598]
 [ 1536 19979]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9976    0.9817    0.9896      7745
           1     0.9945    0.9909    0.9927      7789
           2     0.9699    0.9978    0.9837      7869
           3     0.9973    0.9877    0.9925      7786

    accuracy                         0.9895     31189
   macro avg     0.9898    0.9895    0.9896     31189
weighted avg     0.9897    0.9895    0.9896     31189

[[7603    5  133    4]
 [   2 7718   57   12]
 [   8    4 7852    5]
 [   8   34   54 7690]]
-------------------------------------------------------------------------------------
Single epoch cost time : 11.53 mins
**************** | sota | loss : 0.2337 | f1_score : 0.9530 | ****************
epoch :  2|30, iter : 200|1138,  loss : 0.1744
epoch :  2|30, iter : 400|1138,  loss : 0.1679
epoch :  2|30, iter : 600|1138,  loss : 0.1658
epoch :  2|30, iter : 800|1138,  loss : 0.1650
epoch :  2|30, iter : 1000|1138,  loss : 0.1636
acc : 0.9881, precision : 0.9665, recall : 0.9646, f1_score : 0.9655
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9245    0.9309    0.9277     45524
           1     0.9685    0.9654    0.9669    100022

    accuracy                         0.9546    145546
   macro avg     0.9465    0.9482    0.9473    145546
weighted avg     0.9547    0.9546    0.9547    145546

[[42380  3144]
 [ 3460 96562]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9935    0.9934    0.9935     36452
           1     0.9944    0.9940    0.9942     36422
           2     0.9935    0.9940    0.9938     36462
           3     0.9934    0.9934    0.9934     36210

    accuracy                         0.9937    145546
   macro avg     0.9937    0.9937    0.9937    145546
weighted avg     0.9937    0.9937    0.9937    145546

[[36211    45   140    56]
 [   51 36204    42   125]
 [  120    40 36244    58]
 [   65   120    54 35971]]
-------------------------------------------------------------------------------------
train_loss : 0.1642
eval_loss : 0.3313
acc : 0.9527, precision : 0.8505, recall : 0.8767, f1_score : 0.8634
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8322    0.9613    0.8921      9674
           1     0.9813    0.9129    0.9458     21515

    accuracy                         0.9279     31189
   macro avg     0.9068    0.9371    0.9190     31189
weighted avg     0.9351    0.9279    0.9292     31189

[[ 9300   374]
 [ 1875 19640]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.8558    0.9977    0.9213      7745
           1     0.9817    0.9834    0.9826      7789
           2     0.9978    0.8760    0.9329      7869
           3     0.9966    0.9535    0.9746      7786

    accuracy                         0.9524     31189
   macro avg     0.9580    0.9526    0.9528     31189
weighted avg     0.9582    0.9524    0.9528     31189

[[7727    6    2   10]
 [ 117 7660    7    5]
 [ 946   20 6893   10]
 [ 239  117    6 7424]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.68 mins
epoch :  3|30, iter : 200|1138,  loss : 0.1706
epoch :  3|30, iter : 400|1138,  loss : 0.1592
epoch :  3|30, iter : 600|1138,  loss : 0.1545
epoch :  3|30, iter : 800|1138,  loss : 0.1533
epoch :  3|30, iter : 1000|1138,  loss : 0.1515
acc : 0.9891, precision : 0.9706, recall : 0.9661, f1_score : 0.9683
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9289    0.9397    0.9343     45524
           1     0.9724    0.9673    0.9698    100022

    accuracy                         0.9586    145546
   macro avg     0.9506    0.9535    0.9520    145546
weighted avg     0.9588    0.9586    0.9587    145546

[[42779  2745]
 [ 3275 96747]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9943    0.9941    0.9942     36452
           1     0.9948    0.9949    0.9949     36422
           2     0.9941    0.9946    0.9944     36462
           3     0.9945    0.9941    0.9943     36210

    accuracy                         0.9944    145546
   macro avg     0.9944    0.9944    0.9944    145546
weighted avg     0.9944    0.9944    0.9944    145546

[[36237    43   118    54]
 [   41 36237    42   102]
 [  113    40 36266    43]
 [   52   105    55 35998]]
-------------------------------------------------------------------------------------
train_loss : 0.1504
eval_loss : 0.3147
acc : 0.9835, precision : 0.9367, recall : 0.9688, f1_score : 0.9525
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8162    0.8490    0.8323      9674
           1     0.9308    0.9141    0.9224     21515

    accuracy                         0.8939     31189
   macro avg     0.8735    0.8815    0.8773     31189
weighted avg     0.8953    0.8939    0.8944     31189

[[ 8213  1461]
 [ 1849 19666]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9752    0.9867      7745
           1     0.9956    0.9964    0.9960      7789
           2     0.9760    0.9982    0.9870      7869
           3     0.9956    0.9950    0.9953      7786

    accuracy                         0.9912     31189
   macro avg     0.9914    0.9912    0.9913     31189
weighted avg     0.9914    0.9912    0.9912     31189

[[7553   14  158   20]
 [   2 7761   17    9]
 [   5    4 7855    5]
 [   5   16   18 7747]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.69 mins
epoch :  4|30, iter : 200|1138,  loss : 0.1808
epoch :  4|30, iter : 400|1138,  loss : 0.1602
epoch :  4|30, iter : 600|1138,  loss : 0.1511
epoch :  4|30, iter : 800|1138,  loss : 0.1481
epoch :  4|30, iter : 1000|1138,  loss : 0.1449
acc : 0.9898, precision : 0.9720, recall : 0.9691, f1_score : 0.9706
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9308    0.9386    0.9347     45524
           1     0.9720    0.9683    0.9701    100022

    accuracy                         0.9590    145546
   macro avg     0.9514    0.9534    0.9524    145546
weighted avg     0.9591    0.9590    0.9590    145546

[[42730  2794]
 [ 3175 96847]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9950    0.9956    0.9953     36452
           1     0.9955    0.9954    0.9954     36422
           2     0.9954    0.9957    0.9956     36462
           3     0.9956    0.9948    0.9952     36210

    accuracy                         0.9954    145546
   macro avg     0.9954    0.9954    0.9954    145546
weighted avg     0.9954    0.9954    0.9954    145546

[[36291    37    86    38]
 [   47 36254    35    86]
 [   87    32 36307    36]
 [   48    95    47 36020]]
-------------------------------------------------------------------------------------
train_loss : 0.1456
eval_loss : 0.1673
acc : 0.9865, precision : 0.9844, recall : 0.9355, f1_score : 0.9593
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9169    0.9629    0.9393      9674
           1     0.9829    0.9608    0.9717     21515

    accuracy                         0.9614     31189
   macro avg     0.9499    0.9618    0.9555     31189
weighted avg     0.9625    0.9614    0.9617     31189

[[ 9315   359]
 [  844 20671]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9795    0.9889      7745
           1     0.9986    0.9734    0.9858      7789
           2     0.9533    0.9983    0.9753      7869
           3     0.9966    0.9929    0.9948      7786

    accuracy                         0.9861     31189
   macro avg     0.9867    0.9860    0.9862     31189
weighted avg     0.9866    0.9861    0.9862     31189

[[7586    5  150    4]
 [   2 7582  187   18]
 [   6    3 7856    4]
 [   4    3   48 7731]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.75 mins
**************** | sota | loss : 0.1673 | f1_score : 0.9593 | ****************
epoch :  5|30, iter : 200|1138,  loss : 0.1329
epoch :  5|30, iter : 400|1138,  loss : 0.1331
epoch :  5|30, iter : 600|1138,  loss : 0.1312
epoch :  5|30, iter : 800|1138,  loss : 0.1303
epoch :  5|30, iter : 1000|1138,  loss : 0.1303
acc : 0.9908, precision : 0.9750, recall : 0.9720, f1_score : 0.9735
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9366    0.9468    0.9417     45524
           1     0.9757    0.9708    0.9732    100022

    accuracy                         0.9633    145546
   macro avg     0.9561    0.9588    0.9575    145546
weighted avg     0.9635    0.9633    0.9634    145546

[[43104  2420]
 [ 2918 97104]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9964    0.9959    0.9962     36452
           1     0.9964    0.9968    0.9966     36422
           2     0.9958    0.9964    0.9961     36462
           3     0.9964    0.9959    0.9962     36210

    accuracy                         0.9963    145546
   macro avg     0.9963    0.9963    0.9963    145546
weighted avg     0.9963    0.9963    0.9963    145546

[[36304    29    84    35]
 [   25 36305    35    57]
 [   68    27 36330    37]
 [   37    75    35 36063]]
-------------------------------------------------------------------------------------
train_loss : 0.1299
eval_loss : 0.1593
acc : 0.9901, precision : 0.9658, recall : 0.9767, f1_score : 0.9712
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9355    0.9437    0.9396      9674
           1     0.9746    0.9708    0.9727     21515

    accuracy                         0.9624     31189
   macro avg     0.9551    0.9572    0.9561     31189
weighted avg     0.9625    0.9624    0.9624     31189

[[ 9129   545]
 [  629 20886]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9950    0.9966    0.9958      7745
           1     0.9632    0.9978    0.9802      7789
           2     0.9942    0.9977    0.9959      7869
           3     0.9989    0.9577    0.9779      7786

    accuracy                         0.9875     31189
   macro avg     0.9878    0.9875    0.9875     31189
weighted avg     0.9878    0.9875    0.9875     31189

[[7719    5   17    4]
 [   6 7772   10    1]
 [   8    7 7851    3]
 [  25  285   19 7457]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.64 mins
**************** | sota | loss : 0.1593 | f1_score : 0.9712 | ****************
epoch :  6|30, iter : 200|1138,  loss : 0.1291
epoch :  6|30, iter : 400|1138,  loss : 0.1271
epoch :  6|30, iter : 600|1138,  loss : 0.1242
epoch :  6|30, iter : 800|1138,  loss : 0.1257
epoch :  6|30, iter : 1000|1138,  loss : 0.1256
acc : 0.9914, precision : 0.9761, recall : 0.9739, f1_score : 0.9750
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9396    0.9481    0.9438     45524
           1     0.9763    0.9723    0.9743    100022

    accuracy                         0.9647    145546
   macro avg     0.9579    0.9602    0.9590    145546
weighted avg     0.9648    0.9647    0.9647    145546

[[43160  2364]
 [ 2775 97247]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9962    0.9966    0.9964     36452
           1     0.9968    0.9965    0.9966     36422
           2     0.9961    0.9965    0.9963     36462
           3     0.9969    0.9964    0.9967     36210

    accuracy                         0.9965    145546
   macro avg     0.9965    0.9965    0.9965    145546
weighted avg     0.9965    0.9965    0.9965    145546

[[36328    23    74    27]
 [   42 36294    31    55]
 [   63    36 36333    30]
 [   34    59    37 36080]]
-------------------------------------------------------------------------------------
train_loss : 0.1256
eval_loss : 0.1780
acc : 0.9802, precision : 0.9324, recall : 0.9530, f1_score : 0.9426
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9465    0.9174    0.9317      9674
           1     0.9634    0.9767    0.9700     21515

    accuracy                         0.9583     31189
   macro avg     0.9549    0.9470    0.9508     31189
weighted avg     0.9581    0.9583    0.9581     31189

[[ 8875   799]
 [  502 21013]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9615    0.9797      7745
           1     0.9652    0.9982    0.9814      7789
           2     0.9970    0.9821    0.9895      7869
           3     0.9801    0.9977    0.9888      7786

    accuracy                         0.9849     31189
   macro avg     0.9852    0.9849    0.9849     31189
weighted avg     0.9853    0.9849    0.9849     31189

[[7447  192   18   88]
 [   1 7775    3   10]
 [   8   73 7728   60]
 [   1   15    2 7768]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.73 mins
epoch :  7|30, iter : 200|1138,  loss : 0.1249
epoch :  7|30, iter : 400|1138,  loss : 0.1203
epoch :  7|30, iter : 600|1138,  loss : 0.1191
epoch :  7|30, iter : 800|1138,  loss : 0.1189
epoch :  7|30, iter : 1000|1138,  loss : 0.1180
acc : 0.9919, precision : 0.9774, recall : 0.9756, f1_score : 0.9765
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9422    0.9506    0.9464     45524
           1     0.9774    0.9735    0.9755    100022

    accuracy                         0.9663    145546
   macro avg     0.9598    0.9621    0.9609    145546
weighted avg     0.9664    0.9663    0.9664    145546

[[43277  2247]
 [ 2653 97369]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9971    0.9970    0.9970     36452
           1     0.9975    0.9973    0.9974     36422
           2     0.9965    0.9975    0.9970     36462
           3     0.9974    0.9966    0.9970     36210

    accuracy                         0.9971    145546
   macro avg     0.9971    0.9971    0.9971    145546
weighted avg     0.9971    0.9971    0.9971    145546

[[36341    23    64    24]
 [   27 36324    24    47]
 [   46    21 36372    23]
 [   34    48    40 36088]]
-------------------------------------------------------------------------------------
train_loss : 0.1181
eval_loss : 0.1408
acc : 0.9846, precision : 0.9931, recall : 0.9159, f1_score : 0.9529
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8934    0.9744    0.9321      9674
           1     0.9880    0.9477    0.9674     21515

    accuracy                         0.9560     31189
   macro avg     0.9407    0.9610    0.9498     31189
weighted avg     0.9586    0.9560    0.9565     31189

[[ 9426   248]
 [ 1125 20390]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9978    0.9981      7745
           1     0.9982    0.9982    0.9982      7789
           2     0.9985    0.9981    0.9983      7869
           3     0.9978    0.9988    0.9983      7786

    accuracy                         0.9982     31189
   macro avg     0.9982    0.9982    0.9982     31189
weighted avg     0.9982    0.9982    0.9982     31189

[[7728    6    4    7]
 [   3 7775    6    5]
 [   6    4 7854    5]
 [   3    4    2 7777]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.63 mins
epoch :  8|30, iter : 200|1138,  loss : 0.1102
epoch :  8|30, iter : 400|1138,  loss : 0.1112
epoch :  8|30, iter : 600|1138,  loss : 0.1127
epoch :  8|30, iter : 800|1138,  loss : 0.1129
epoch :  8|30, iter : 1000|1138,  loss : 0.1142
acc : 0.9918, precision : 0.9772, recall : 0.9755, f1_score : 0.9764
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9448    0.9516    0.9482     45524
           1     0.9779    0.9747    0.9763    100022

    accuracy                         0.9675    145546
   macro avg     0.9613    0.9631    0.9622    145546
weighted avg     0.9675    0.9675    0.9675    145546

[[43319  2205]
 [ 2532 97490]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9967    0.9971    0.9969     36452
           1     0.9977    0.9975    0.9976     36422
           2     0.9970    0.9972    0.9971     36462
           3     0.9975    0.9970    0.9973     36210

    accuracy                         0.9972    145546
   macro avg     0.9972    0.9972    0.9972    145546
weighted avg     0.9972    0.9972    0.9972    145546

[[36347    21    61    23]
 [   28 36332    20    42]
 [   56    21 36359    26]
 [   37    42    28 36103]]
-------------------------------------------------------------------------------------
train_loss : 0.1147
eval_loss : 0.1277
acc : 0.9889, precision : 0.9882, recall : 0.9462, f1_score : 0.9667
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9107    0.9684    0.9386      9674
           1     0.9854    0.9573    0.9711     21515

    accuracy                         0.9607     31189
   macro avg     0.9480    0.9628    0.9549     31189
weighted avg     0.9622    0.9607    0.9610     31189

[[ 9368   306]
 [  919 20596]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9956    0.9970      7745
           1     0.9956    0.9990    0.9973      7789
           2     0.9978    0.9971    0.9975      7869
           3     0.9979    0.9981    0.9980      7786

    accuracy                         0.9974     31189
   macro avg     0.9974    0.9974    0.9974     31189
weighted avg     0.9974    0.9974    0.9974     31189

[[7711   13   12    9]
 [   2 7781    3    3]
 [   9   10 7846    4]
 [   2   11    2 7771]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.62 mins
epoch :  9|30, iter : 200|1138,  loss : 0.1181
epoch :  9|30, iter : 400|1138,  loss : 0.1148
epoch :  9|30, iter : 600|1138,  loss : 0.1132
epoch :  9|30, iter : 800|1138,  loss : 0.1119
epoch :  9|30, iter : 1000|1138,  loss : 0.1115
acc : 0.9921, precision : 0.9786, recall : 0.9760, f1_score : 0.9773
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9443    0.9542    0.9492     45524
           1     0.9790    0.9744    0.9767    100022

    accuracy                         0.9681    145546
   macro avg     0.9617    0.9643    0.9629    145546
weighted avg     0.9682    0.9681    0.9681    145546

[[43437  2087]
 [ 2563 97459]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9969    0.9972    0.9971     36452
           1     0.9973    0.9971    0.9972     36422
           2     0.9970    0.9970    0.9970     36462
           3     0.9972    0.9972    0.9972     36210

    accuracy                         0.9971    145546
   macro avg     0.9971    0.9971    0.9971    145546
weighted avg     0.9971    0.9971    0.9971    145546

[[36349    22    55    26]
 [   30 36317    25    50]
 [   55    29 36354    24]
 [   27    46    30 36107]]
-------------------------------------------------------------------------------------
train_loss : 0.1122
eval_loss : 0.1286
acc : 0.9902, precision : 0.9755, recall : 0.9667, f1_score : 0.9711
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9330    0.9477    0.9403      9674
           1     0.9763    0.9694    0.9729     21515

    accuracy                         0.9627     31189
   macro avg     0.9547    0.9586    0.9566     31189
weighted avg     0.9629    0.9627    0.9628     31189

[[ 9168   506]
 [  658 20857]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9933    0.9959      7745
           1     0.9936    0.9990    0.9963      7789
           2     0.9934    0.9985    0.9959      7869
           3     0.9988    0.9934    0.9961      7786

    accuracy                         0.9961     31189
   macro avg     0.9961    0.9960    0.9961     31189
weighted avg     0.9961    0.9961    0.9961     31189

[[7693    6   42    4]
 [   2 7781    4    2]
 [   5    4 7857    3]
 [   5   40    6 7735]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.71 mins
epoch : 10|30, iter : 200|1138,  loss : 0.1078
epoch : 10|30, iter : 400|1138,  loss : 0.1089
epoch : 10|30, iter : 600|1138,  loss : 0.1075
epoch : 10|30, iter : 800|1138,  loss : 0.1080
epoch : 10|30, iter : 1000|1138,  loss : 0.1081
acc : 0.9926, precision : 0.9788, recall : 0.9782, f1_score : 0.9785
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9472    0.9551    0.9511     45524
           1     0.9795    0.9758    0.9776    100022

    accuracy                         0.9693    145546
   macro avg     0.9634    0.9654    0.9644    145546
weighted avg     0.9694    0.9693    0.9693    145546

[[43480  2044]
 [ 2423 97599]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9974    0.9975    0.9974     36452
           1     0.9974    0.9978    0.9976     36422
           2     0.9971    0.9973    0.9972     36462
           3     0.9978    0.9972    0.9975     36210

    accuracy                         0.9974    145546
   macro avg     0.9974    0.9974    0.9974    145546
weighted avg     0.9974    0.9974    0.9974    145546

[[36360    23    52    17]
 [   22 36341    22    37]
 [   45    27 36363    27]
 [   29    43    30 36108]]
-------------------------------------------------------------------------------------
train_loss : 0.1087
eval_loss : 0.1148
acc : 0.9897, precision : 0.9900, recall : 0.9494, f1_score : 0.9693
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9341    0.9600    0.9469      9674
           1     0.9818    0.9696    0.9756     21515

    accuracy                         0.9666     31189
   macro avg     0.9580    0.9648    0.9613     31189
weighted avg     0.9670    0.9666    0.9667     31189

[[ 9287   387]
 [  655 20860]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9973    0.9985    0.9979      7745
           1     0.9982    0.9981    0.9981      7789
           2     0.9987    0.9975    0.9981      7869
           3     0.9979    0.9982    0.9981      7786

    accuracy                         0.9980     31189
   macro avg     0.9980    0.9980    0.9980     31189
weighted avg     0.9980    0.9980    0.9980     31189

[[7733    5    3    4]
 [   4 7774    4    7]
 [  10    5 7849    5]
 [   7    4    3 7772]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.59 mins
epoch : 11|30, iter : 200|1138,  loss : 0.1118
epoch : 11|30, iter : 400|1138,  loss : 0.1077
epoch : 11|30, iter : 600|1138,  loss : 0.1060
epoch : 11|30, iter : 800|1138,  loss : 0.1060
epoch : 11|30, iter : 1000|1138,  loss : 0.1063
acc : 0.9930, precision : 0.9803, recall : 0.9794, f1_score : 0.9798
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9478    0.9574    0.9525     45524
           1     0.9805    0.9760    0.9782    100022

    accuracy                         0.9702    145546
   macro avg     0.9641    0.9667    0.9654    145546
weighted avg     0.9703    0.9702    0.9702    145546

[[43583  1941]
 [ 2402 97620]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9973    0.9975    0.9974     36452
           1     0.9971    0.9975    0.9973     36422
           2     0.9971    0.9973    0.9972     36462
           3     0.9976    0.9969    0.9972     36210

    accuracy                         0.9973    145546
   macro avg     0.9973    0.9973    0.9973    145546
weighted avg     0.9973    0.9973    0.9973    145546

[[36361    25    46    20]
 [   24 36330    23    45]
 [   47    30 36362    23]
 [   28    50    35 36097]]
-------------------------------------------------------------------------------------
train_loss : 0.1071
eval_loss : 0.1195
acc : 0.9917, precision : 0.9852, recall : 0.9658, f1_score : 0.9754
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9295    0.9663    0.9475      9674
           1     0.9846    0.9670    0.9757     21515

    accuracy                         0.9668     31189
   macro avg     0.9570    0.9667    0.9616     31189
weighted avg     0.9675    0.9668    0.9670     31189

[[ 9348   326]
 [  709 20806]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9963    0.9982    0.9972      7745
           1     0.9978    0.9976    0.9977      7789
           2     0.9978    0.9970    0.9974      7869
           3     0.9986    0.9978    0.9982      7786

    accuracy                         0.9976     31189
   macro avg     0.9976    0.9976    0.9976     31189
weighted avg     0.9976    0.9976    0.9976     31189

[[7731    5    5    4]
 [   8 7770    8    3]
 [  16    4 7845    4]
 [   5    8    4 7769]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.66 mins
**************** | sota | loss : 0.1195 | f1_score : 0.9754 | ****************
epoch : 12|30, iter : 200|1138,  loss : 0.1059
epoch : 12|30, iter : 400|1138,  loss : 0.1031
epoch : 12|30, iter : 600|1138,  loss : 0.1042
epoch : 12|30, iter : 800|1138,  loss : 0.1026
epoch : 12|30, iter : 1000|1138,  loss : 0.1027
acc : 0.9931, precision : 0.9811, recall : 0.9791, f1_score : 0.9801
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9498    0.9584    0.9541     45524
           1     0.9810    0.9770    0.9790    100022

    accuracy                         0.9712    145546
   macro avg     0.9654    0.9677    0.9665    145546
weighted avg     0.9712    0.9712    0.9712    145546

[[43629  1895]
 [ 2304 97718]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9974    0.9975    0.9974     36452
           1     0.9976    0.9980    0.9978     36422
           2     0.9971    0.9975    0.9973     36462
           3     0.9980    0.9972    0.9976     36210

    accuracy                         0.9976    145546
   macro avg     0.9976    0.9976    0.9976    145546
weighted avg     0.9976    0.9976    0.9976    145546

[[36361    22    49    20]
 [   20 36349    25    28]
 [   42    26 36371    23]
 [   33    38    30 36109]]
-------------------------------------------------------------------------------------
train_loss : 0.1027
eval_loss : 0.1354
acc : 0.9900, precision : 0.9799, recall : 0.9612, f1_score : 0.9705
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9202    0.9658    0.9425      9674
           1     0.9843    0.9624    0.9732     21515

    accuracy                         0.9634     31189
   macro avg     0.9522    0.9641    0.9578     31189
weighted avg     0.9644    0.9634    0.9637     31189

[[ 9343   331]
 [  810 20705]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9957    0.9973    0.9965      7745
           1     0.9987    0.9833    0.9909      7789
           2     0.9976    0.9981    0.9978      7869
           3     0.9843    0.9974    0.9908      7786

    accuracy                         0.9940     31189
   macro avg     0.9941    0.9940    0.9940     31189
weighted avg     0.9941    0.9940    0.9940     31189

[[7724    5    6   10]
 [  14 7659    8  108]
 [   6    3 7854    6]
 [  13    2    5 7766]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.58 mins
epoch : 13|30, iter : 200|1138,  loss : 0.1120
epoch : 13|30, iter : 400|1138,  loss : 0.1075
epoch : 13|30, iter : 600|1138,  loss : 0.1044
epoch : 13|30, iter : 800|1138,  loss : 0.1037
epoch : 13|30, iter : 1000|1138,  loss : 0.1021
acc : 0.9932, precision : 0.9824, recall : 0.9783, f1_score : 0.9804
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9499    0.9598    0.9548     45524
           1     0.9816    0.9769    0.9793    100022

    accuracy                         0.9716    145546
   macro avg     0.9657    0.9684    0.9671    145546
weighted avg     0.9717    0.9716    0.9716    145546

[[43695  1829]
 [ 2306 97716]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9976    0.9978    0.9977     36452
           1     0.9972    0.9974    0.9973     36422
           2     0.9976    0.9976    0.9976     36462
           3     0.9975    0.9971    0.9973     36210

    accuracy                         0.9975    145546
   macro avg     0.9975    0.9975    0.9975    145546
weighted avg     0.9975    0.9975    0.9975    145546

[[36370    23    43    16]
 [   22 36329    22    49]
 [   36    27 36373    26]
 [   30    52    23 36105]]
-------------------------------------------------------------------------------------
train_loss : 0.1026
eval_loss : 0.1703
acc : 0.9855, precision : 0.9728, recall : 0.9411, f1_score : 0.9567
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8785    0.9441    0.9101      9674
           1     0.9740    0.9413    0.9574     21515

    accuracy                         0.9422     31189
   macro avg     0.9262    0.9427    0.9337     31189
weighted avg     0.9444    0.9422    0.9427     31189

[[ 9133   541]
 [ 1263 20252]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9988    0.9901    0.9944      7745
           1     0.9970    0.9914    0.9942      7789
           2     0.9915    0.9981    0.9948      7869
           3     0.9904    0.9981    0.9942      7786

    accuracy                         0.9944     31189
   macro avg     0.9945    0.9944    0.9944     31189
weighted avg     0.9944    0.9944    0.9944     31189

[[7668   11   55   11]
 [   2 7722    7   58]
 [   5    4 7854    6]
 [   2    8    5 7771]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.50 mins
epoch : 14|30, iter : 200|1138,  loss : 0.0945
epoch : 14|30, iter : 400|1138,  loss : 0.0981
epoch : 14|30, iter : 600|1138,  loss : 0.0985
epoch : 14|30, iter : 800|1138,  loss : 0.0994
epoch : 14|30, iter : 1000|1138,  loss : 0.0990
acc : 0.9934, precision : 0.9823, recall : 0.9796, f1_score : 0.9809
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9506    0.9604    0.9555     45524
           1     0.9819    0.9773    0.9796    100022

    accuracy                         0.9720    145546
   macro avg     0.9662    0.9688    0.9675    145546
weighted avg     0.9721    0.9720    0.9720    145546

[[43722  1802]
 [ 2273 97749]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9977    0.9979    0.9978     36452
           1     0.9978    0.9978    0.9978     36422
           2     0.9976    0.9978    0.9977     36462
           3     0.9980    0.9975    0.9977     36210

    accuracy                         0.9978    145546
   macro avg     0.9978    0.9978    0.9978    145546
weighted avg     0.9978    0.9978    0.9978    145546

[[36377    22    35    18]
 [   20 36343    24    35]
 [   38    24 36380    20]
 [   26    35    29 36120]]
-------------------------------------------------------------------------------------
train_loss : 0.0999
eval_loss : 0.1110
acc : 0.9915, precision : 0.9757, recall : 0.9744, f1_score : 0.9750
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9387    0.9599    0.9492      9674
           1     0.9818    0.9718    0.9768     21515

    accuracy                         0.9681     31189
   macro avg     0.9603    0.9659    0.9630     31189
weighted avg     0.9684    0.9681    0.9682     31189

[[ 9286   388]
 [  606 20909]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9983    0.9985      7745
           1     0.9983    0.9979    0.9981      7789
           2     0.9990    0.9976    0.9983      7869
           3     0.9969    0.9990    0.9979      7786

    accuracy                         0.9982     31189
   macro avg     0.9982    0.9982    0.9982     31189
weighted avg     0.9982    0.9982    0.9982     31189

[[7732    5    2    6]
 [   2 7773    4   10]
 [   6    5 7850    8]
 [   3    3    2 7778]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.54 mins
epoch : 15|30, iter : 200|1138,  loss : 0.0955
epoch : 15|30, iter : 400|1138,  loss : 0.0957
epoch : 15|30, iter : 600|1138,  loss : 0.0969
epoch : 15|30, iter : 800|1138,  loss : 0.0989
epoch : 15|30, iter : 1000|1138,  loss : 0.1001
acc : 0.9936, precision : 0.9829, recall : 0.9800, f1_score : 0.9815
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9502    0.9618    0.9560     45524
           1     0.9825    0.9771    0.9798    100022

    accuracy                         0.9723    145546
   macro avg     0.9664    0.9695    0.9679    145546
weighted avg     0.9724    0.9723    0.9724    145546

[[43787  1737]
 [ 2293 97729]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9975    0.9977    0.9976     36452
           1     0.9978    0.9978    0.9978     36422
           2     0.9973    0.9975    0.9974     36462
           3     0.9978    0.9973    0.9975     36210

    accuracy                         0.9976    145546
   macro avg     0.9976    0.9976    0.9976    145546
weighted avg     0.9976    0.9976    0.9976    145546

[[36369    19    44    20]
 [   21 36341    23    37]
 [   43    24 36372    23]
 [   28    38    32 36112]]
-------------------------------------------------------------------------------------
train_loss : 0.1000
eval_loss : 0.1566
acc : 0.9879, precision : 0.9500, recall : 0.9806, f1_score : 0.9651
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9660    0.8833    0.9228      9674
           1     0.9495    0.9860    0.9674     21515

    accuracy                         0.9542     31189
   macro avg     0.9577    0.9347    0.9451     31189
weighted avg     0.9546    0.9542    0.9536     31189

[[ 8545  1129]
 [  301 21214]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9950    0.9974    0.9962      7745
           1     0.9979    0.9959    0.9969      7789
           2     0.9978    0.9957    0.9968      7869
           3     0.9963    0.9981    0.9972      7786

    accuracy                         0.9968     31189
   macro avg     0.9968    0.9968    0.9968     31189
weighted avg     0.9968    0.9968    0.9968     31189

[[7725    6    6    8]
 [   8 7757    9   15]
 [  24    4 7835    6]
 [   7    6    2 7771]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.51 mins
epoch : 16|30, iter : 200|1138,  loss : 0.1169
epoch : 16|30, iter : 400|1138,  loss : 0.1070
epoch : 16|30, iter : 600|1138,  loss : 0.1042
epoch : 16|30, iter : 800|1138,  loss : 0.1030
epoch : 16|30, iter : 1000|1138,  loss : 0.1015
acc : 0.9933, precision : 0.9820, recall : 0.9793, f1_score : 0.9807
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9495    0.9609    0.9552     45524
           1     0.9821    0.9767    0.9794    100022

    accuracy                         0.9718    145546
   macro avg     0.9658    0.9688    0.9673    145546
weighted avg     0.9719    0.9718    0.9718    145546

[[43745  1779]
 [ 2328 97694]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9974    0.9974    0.9974     36452
           1     0.9970    0.9977    0.9973     36422
           2     0.9974    0.9973    0.9973     36462
           3     0.9975    0.9970    0.9973     36210

    accuracy                         0.9973    145546
   macro avg     0.9973    0.9973    0.9973    145546
weighted avg     0.9973    0.9973    0.9973    145546

[[36358    31    42    21]
 [   21 36337    24    40]
 [   39    33 36362    28]
 [   36    45    29 36100]]
-------------------------------------------------------------------------------------
train_loss : 0.1011
eval_loss : 0.1093
acc : 0.9909, precision : 0.9715, recall : 0.9752, f1_score : 0.9733
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9528    0.9430    0.9479      9674
           1     0.9745    0.9790    0.9767     21515

    accuracy                         0.9678     31189
   macro avg     0.9637    0.9610    0.9623     31189
weighted avg     0.9678    0.9678    0.9678     31189

[[ 9123   551]
 [  452 21063]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9978    0.9981      7745
           1     0.9986    0.9981    0.9983      7789
           2     0.9983    0.9971    0.9977      7869
           3     0.9968    0.9991    0.9979      7786

    accuracy                         0.9980     31189
   macro avg     0.9980    0.9980    0.9980     31189
weighted avg     0.9980    0.9980    0.9980     31189

[[7728    5    6    6]
 [   1 7774    5    9]
 [  10    3 7846   10]
 [   2    3    2 7779]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.61 mins
epoch : 17|30, iter : 200|1138,  loss : 0.0959
epoch : 17|30, iter : 400|1138,  loss : 0.0915
epoch : 17|30, iter : 600|1138,  loss : 0.0939
epoch : 17|30, iter : 800|1138,  loss : 0.0952
epoch : 17|30, iter : 1000|1138,  loss : 0.0955
acc : 0.9936, precision : 0.9828, recall : 0.9802, f1_score : 0.9815
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9527    0.9628    0.9577     45524
           1     0.9830    0.9782    0.9806    100022

    accuracy                         0.9734    145546
   macro avg     0.9678    0.9705    0.9691    145546
weighted avg     0.9735    0.9734    0.9734    145546

[[43829  1695]
 [ 2178 97844]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9979    0.9979    0.9979     36452
           1     0.9981    0.9981    0.9981     36422
           2     0.9978    0.9979    0.9979     36462
           3     0.9978    0.9976    0.9977     36210

    accuracy                         0.9979    145546
   macro avg     0.9979    0.9979    0.9979    145546
weighted avg     0.9979    0.9979    0.9979    145546

[[36376    18    35    23]
 [   21 36352    19    30]
 [   30    19 36387    26]
 [   27    32    27 36124]]
-------------------------------------------------------------------------------------
train_loss : 0.0963
eval_loss : 0.1288
acc : 0.9904, precision : 0.9801, recall : 0.9631, f1_score : 0.9715
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9157    0.9642    0.9393      9674
           1     0.9835    0.9601    0.9717     21515

    accuracy                         0.9614     31189
   macro avg     0.9496    0.9622    0.9555     31189
weighted avg     0.9625    0.9614    0.9616     31189

[[ 9328   346]
 [  859 20656]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9923    0.9979    0.9951      7745
           1     0.9982    0.9928    0.9955      7789
           2     0.9976    0.9962    0.9969      7869
           3     0.9970    0.9982    0.9976      7786

    accuracy                         0.9963     31189
   macro avg     0.9963    0.9963    0.9963     31189
weighted avg     0.9963    0.9963    0.9963     31189

[[7729    5    7    4]
 [  33 7733    8   15]
 [  21    5 7839    4]
 [   6    4    4 7772]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.49 mins
epoch : 18|30, iter : 200|1138,  loss : 0.1116
epoch : 18|30, iter : 400|1138,  loss : 0.1038
epoch : 18|30, iter : 600|1138,  loss : 0.1011
epoch : 18|30, iter : 800|1138,  loss : 0.0995
epoch : 18|30, iter : 1000|1138,  loss : 0.0981
acc : 0.9934, precision : 0.9826, recall : 0.9790, f1_score : 0.9808
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9511    0.9621    0.9566     45524
           1     0.9827    0.9775    0.9801    100022

    accuracy                         0.9727    145546
   macro avg     0.9669    0.9698    0.9683    145546
weighted avg     0.9728    0.9727    0.9727    145546

[[43799  1725]
 [ 2254 97768]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9975    0.9974    0.9975     36452
           1     0.9977    0.9979    0.9978     36422
           2     0.9972    0.9976    0.9974     36462
           3     0.9979    0.9975    0.9977     36210

    accuracy                         0.9976    145546
   macro avg     0.9976    0.9976    0.9976    145546
weighted avg     0.9976    0.9976    0.9976    145546

[[36359    21    49    23]
 [   23 36344    23    32]
 [   39    27 36376    20]
 [   28    35    29 36118]]
-------------------------------------------------------------------------------------
train_loss : 0.0986
eval_loss : 0.1061
acc : 0.9912, precision : 0.9831, recall : 0.9652, f1_score : 0.9741
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9412    0.9620    0.9515      9674
           1     0.9827    0.9730    0.9778     21515

    accuracy                         0.9696     31189
   macro avg     0.9620    0.9675    0.9647     31189
weighted avg     0.9699    0.9696    0.9697     31189

[[ 9306   368]
 [  581 20934]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9968    0.9977      7745
           1     0.9978    0.9987    0.9983      7789
           2     0.9964    0.9982    0.9973      7869
           3     0.9986    0.9978    0.9982      7786

    accuracy                         0.9979     31189
   macro avg     0.9979    0.9979    0.9979     31189
weighted avg     0.9979    0.9979    0.9979     31189

[[7720    5   16    4]
 [   1 7779    6    3]
 [   6    4 7855    4]
 [   3    8    6 7769]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.59 mins
epoch : 19|30, iter : 200|1138,  loss : 0.0858
epoch : 19|30, iter : 400|1138,  loss : 0.0819
epoch : 19|30, iter : 600|1138,  loss : 0.0812
epoch : 19|30, iter : 800|1138,  loss : 0.0803
epoch : 19|30, iter : 1000|1138,  loss : 0.0802
acc : 0.9952, precision : 0.9872, recall : 0.9850, f1_score : 0.9861
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9621    0.9708    0.9664     45524
           1     0.9867    0.9826    0.9846    100022

    accuracy                         0.9789    145546
   macro avg     0.9744    0.9767    0.9755    145546
weighted avg     0.9790    0.9789    0.9789    145546

[[44196  1328]
 [ 1742 98280]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9984    0.9983     36452
           1     0.9985    0.9985    0.9985     36422
           2     0.9982    0.9985    0.9983     36462
           3     0.9986    0.9981    0.9984     36210

    accuracy                         0.9984    145546
   macro avg     0.9984    0.9984    0.9984    145546
weighted avg     0.9984    0.9984    0.9984    145546

[[36394    12    27    19]
 [   18 36369    19    16]
 [   22    18 36408    14]
 [   23    24    21 36142]]
-------------------------------------------------------------------------------------
train_loss : 0.0797
eval_loss : 0.1008
acc : 0.9918, precision : 0.9696, recall : 0.9829, f1_score : 0.9762
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9455    0.9603    0.9528      9674
           1     0.9820    0.9751    0.9785     21515

    accuracy                         0.9705     31189
   macro avg     0.9637    0.9677    0.9657     31189
weighted avg     0.9707    0.9705    0.9706     31189

[[ 9290   384]
 [  536 20979]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9988    0.9985    0.9986      7745
           1     0.9979    0.9990    0.9985      7789
           2     0.9987    0.9983    0.9985      7869
           3     0.9987    0.9985    0.9986      7786

    accuracy                         0.9986     31189
   macro avg     0.9986    0.9986    0.9986     31189
weighted avg     0.9986    0.9986    0.9986     31189

[[7733    5    3    4]
 [   1 7781    4    3]
 [   6    4 7856    3]
 [   2    7    3 7774]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.56 mins
**************** | sota | loss : 0.1008 | f1_score : 0.9762 | ****************
epoch : 20|30, iter : 200|1138,  loss : 0.0730
epoch : 20|30, iter : 400|1138,  loss : 0.0727
epoch : 20|30, iter : 600|1138,  loss : 0.0740
epoch : 20|30, iter : 800|1138,  loss : 0.0760
epoch : 20|30, iter : 1000|1138,  loss : 0.0755
acc : 0.9953, precision : 0.9872, recall : 0.9853, f1_score : 0.9863
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9629    0.9729    0.9679     45524
           1     0.9876    0.9830    0.9853    100022

    accuracy                         0.9798    145546
   macro avg     0.9753    0.9779    0.9766    145546
weighted avg     0.9799    0.9798    0.9798    145546

[[44289  1235]
 [ 1705 98317]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9984    0.9984     36452
           1     0.9985    0.9987    0.9986     36422
           2     0.9981    0.9984    0.9983     36462
           3     0.9987    0.9981    0.9984     36210

    accuracy                         0.9984    145546
   macro avg     0.9984    0.9984    0.9984    145546
weighted avg     0.9984    0.9984    0.9984    145546

[[36393    13    31    15]
 [   14 36375    17    16]
 [   23    18 36404    17]
 [   23    25    20 36142]]
-------------------------------------------------------------------------------------
train_loss : 0.0764
eval_loss : 0.1147
acc : 0.9908, precision : 0.9883, recall : 0.9573, f1_score : 0.9726
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9322    0.9623    0.9470      9674
           1     0.9828    0.9685    0.9756     21515

    accuracy                         0.9666     31189
   macro avg     0.9575    0.9654    0.9613     31189
weighted avg     0.9671    0.9666    0.9667     31189

[[ 9309   365]
 [  677 20838]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9977    0.9980      7745
           1     0.9969    0.9992    0.9981      7789
           2     0.9989    0.9968    0.9978      7869
           3     0.9982    0.9986    0.9984      7786

    accuracy                         0.9981     31189
   macro avg     0.9981    0.9981    0.9981     31189
weighted avg     0.9981    0.9981    0.9981     31189

[[7727    9    3    6]
 [   1 7783    4    1]
 [  10    8 7844    7]
 [   2    7    2 7775]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.70 mins
epoch : 21|30, iter : 200|1138,  loss : 0.0802
epoch : 21|30, iter : 400|1138,  loss : 0.0779
epoch : 21|30, iter : 600|1138,  loss : 0.0749
epoch : 21|30, iter : 800|1138,  loss : 0.0760
epoch : 21|30, iter : 1000|1138,  loss : 0.0768
acc : 0.9954, precision : 0.9877, recall : 0.9856, f1_score : 0.9867
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9621    0.9730    0.9676     45524
           1     0.9877    0.9826    0.9851    100022

    accuracy                         0.9796    145546
   macro avg     0.9749    0.9778    0.9763    145546
weighted avg     0.9797    0.9796    0.9796    145546

[[44296  1228]
 [ 1743 98279]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9985    0.9984     36452
           1     0.9986    0.9985    0.9985     36422
           2     0.9981    0.9984    0.9982     36462
           3     0.9985    0.9980    0.9982     36210

    accuracy                         0.9983    145546
   macro avg     0.9983    0.9983    0.9983    145546
weighted avg     0.9983    0.9983    0.9983    145546

[[36398    14    25    15]
 [   20 36366    18    18]
 [   22    15 36402    23]
 [   24    23    25 36138]]
-------------------------------------------------------------------------------------
train_loss : 0.0766
eval_loss : 0.1034
acc : 0.9921, precision : 0.9821, recall : 0.9714, f1_score : 0.9767
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9508    0.9567    0.9537      9674
           1     0.9805    0.9777    0.9791     21515

    accuracy                         0.9712     31189
   macro avg     0.9656    0.9672    0.9664     31189
weighted avg     0.9713    0.9712    0.9712     31189

[[ 9255   419]
 [  479 21036]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9979    0.9983      7745
           1     0.9982    0.9986    0.9984      7789
           2     0.9982    0.9986    0.9984      7869
           3     0.9986    0.9985    0.9985      7786

    accuracy                         0.9984     31189
   macro avg     0.9984    0.9984    0.9984     31189
weighted avg     0.9984    0.9984    0.9984     31189

[[7729    5    7    4]
 [   3 7778    4    4]
 [   5    3 7858    3]
 [   3    6    3 7774]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.64 mins
epoch : 22|30, iter : 200|1138,  loss : 0.0719
epoch : 22|30, iter : 400|1138,  loss : 0.0716
epoch : 22|30, iter : 600|1138,  loss : 0.0719
epoch : 22|30, iter : 800|1138,  loss : 0.0710
epoch : 22|30, iter : 1000|1138,  loss : 0.0724
acc : 0.9955, precision : 0.9884, recall : 0.9858, f1_score : 0.9871
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9647    0.9751    0.9698     45524
           1     0.9886    0.9838    0.9862    100022

    accuracy                         0.9810    145546
   macro avg     0.9766    0.9794    0.9780    145546
weighted avg     0.9811    0.9810    0.9811    145546

[[44389  1135]
 [ 1625 98397]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9981    0.9984    0.9982     36452
           1     0.9983    0.9987    0.9985     36422
           2     0.9982    0.9983    0.9983     36462
           3     0.9988    0.9980    0.9984     36210

    accuracy                         0.9984    145546
   macro avg     0.9984    0.9984    0.9984    145546
weighted avg     0.9984    0.9984    0.9984    145546

[[36394    19    27    12]
 [   18 36373    15    16]
 [   27    20 36401    14]
 [   25    24    22 36139]]
-------------------------------------------------------------------------------------
train_loss : 0.0732
eval_loss : 0.1189
acc : 0.9907, precision : 0.9853, recall : 0.9599, f1_score : 0.9725
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9283    0.9692    0.9483      9674
           1     0.9859    0.9663    0.9760     21515

    accuracy                         0.9672     31189
   macro avg     0.9571    0.9678    0.9622     31189
weighted avg     0.9680    0.9672    0.9674     31189

[[ 9376   298]
 [  724 20791]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9929    0.9958      7745
           1     0.9969    0.9988    0.9979      7789
           2     0.9956    0.9967    0.9961      7869
           3     0.9958    0.9985    0.9971      7786

    accuracy                         0.9967     31189
   macro avg     0.9967    0.9967    0.9967     31189
weighted avg     0.9967    0.9967    0.9967     31189

[[7690    9   30   16]
 [   1 7780    3    5]
 [   7    7 7843   12]
 [   2    8    2 7774]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.59 mins
epoch : 23|30, iter : 200|1138,  loss : 0.0745
epoch : 23|30, iter : 400|1138,  loss : 0.0726
epoch : 23|30, iter : 600|1138,  loss : 0.0722
epoch : 23|30, iter : 800|1138,  loss : 0.0732
epoch : 23|30, iter : 1000|1138,  loss : 0.0739
acc : 0.9955, precision : 0.9885, recall : 0.9857, f1_score : 0.9871
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9651    0.9743    0.9697     45524
           1     0.9883    0.9840    0.9861    100022

    accuracy                         0.9809    145546
   macro avg     0.9767    0.9791    0.9779    145546
weighted avg     0.9810    0.9809    0.9810    145546

[[44354  1170]
 [ 1603 98419]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9982    0.9982     36452
           1     0.9985    0.9987    0.9986     36422
           2     0.9979    0.9983    0.9981     36462
           3     0.9986    0.9981    0.9984     36210

    accuracy                         0.9983    145546
   macro avg     0.9983    0.9983    0.9983    145546
weighted avg     0.9983    0.9983    0.9983    145546

[[36385    16    31    20]
 [   15 36375    19    13]
 [   24    21 36401    16]
 [   25    19    25 36141]]
-------------------------------------------------------------------------------------
train_loss : 0.0735
eval_loss : 0.1039
acc : 0.9922, precision : 0.9798, recall : 0.9744, f1_score : 0.9771
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9376    0.9699    0.9535      9674
           1     0.9863    0.9710    0.9786     21515

    accuracy                         0.9707     31189
   macro avg     0.9620    0.9705    0.9660     31189
weighted avg     0.9712    0.9707    0.9708     31189

[[ 9383   291]
 [  624 20891]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9988    0.9983    0.9986      7745
           1     0.9982    0.9986    0.9984      7789
           2     0.9990    0.9981    0.9985      7869
           3     0.9979    0.9990    0.9985      7786

    accuracy                         0.9985     31189
   macro avg     0.9985    0.9985    0.9985     31189
weighted avg     0.9985    0.9985    0.9985     31189

[[7732    5    3    5]
 [   1 7778    3    7]
 [   6    5 7854    4]
 [   2    4    2 7778]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.55 mins
epoch : 24|30, iter : 200|1138,  loss : 0.0722
epoch : 24|30, iter : 400|1138,  loss : 0.0681
epoch : 24|30, iter : 600|1138,  loss : 0.0710
epoch : 24|30, iter : 800|1138,  loss : 0.0717
epoch : 24|30, iter : 1000|1138,  loss : 0.0719
acc : 0.9957, precision : 0.9889, recall : 0.9862, f1_score : 0.9876
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9652    0.9749    0.9700     45524
           1     0.9885    0.9840    0.9863    100022

    accuracy                         0.9812    145546
   macro avg     0.9769    0.9795    0.9781    145546
weighted avg     0.9812    0.9812    0.9812    145546

[[44381  1143]
 [ 1599 98423]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9983    0.9983     36452
           1     0.9985    0.9985    0.9985     36422
           2     0.9981    0.9985    0.9983     36462
           3     0.9985    0.9981    0.9983     36210

    accuracy                         0.9984    145546
   macro avg     0.9984    0.9984    0.9984    145546
weighted avg     0.9984    0.9984    0.9984    145546

[[36391    15    29    17]
 [   18 36368    17    19]
 [   19    18 36408    17]
 [   24    21    25 36140]]
-------------------------------------------------------------------------------------
train_loss : 0.0715
eval_loss : 0.1021
acc : 0.9921, precision : 0.9849, recall : 0.9684, f1_score : 0.9766
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9484    0.9580    0.9532      9674
           1     0.9810    0.9766    0.9788     21515

    accuracy                         0.9708     31189
   macro avg     0.9647    0.9673    0.9660     31189
weighted avg     0.9709    0.9708    0.9709     31189

[[ 9268   406]
 [  504 21011]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9983    0.9986    0.9985      7745
           1     0.9979    0.9986    0.9983      7789
           2     0.9991    0.9971    0.9981      7869
           3     0.9979    0.9991    0.9985      7786

    accuracy                         0.9983     31189
   macro avg     0.9983    0.9983    0.9983     31189
weighted avg     0.9983    0.9983    0.9983     31189

[[7734    5    2    4]
 [   1 7778    3    7]
 [  10    8 7846    5]
 [   2    3    2 7779]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.61 mins
epoch : 25|30, iter : 200|1138,  loss : 0.0669
epoch : 25|30, iter : 400|1138,  loss : 0.0685
epoch : 25|30, iter : 600|1138,  loss : 0.0676
epoch : 25|30, iter : 800|1138,  loss : 0.0693
epoch : 25|30, iter : 1000|1138,  loss : 0.0706
acc : 0.9958, precision : 0.9889, recall : 0.9868, f1_score : 0.9878
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9657    0.9748    0.9703     45524
           1     0.9885    0.9843    0.9864    100022

    accuracy                         0.9813    145546
   macro avg     0.9771    0.9796    0.9783    145546
weighted avg     0.9814    0.9813    0.9813    145546

[[44379  1145]
 [ 1574 98448]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9984    0.9983     36452
           1     0.9987    0.9987    0.9987     36422
           2     0.9982    0.9982    0.9982     36462
           3     0.9984    0.9981    0.9983     36210

    accuracy                         0.9984    145546
   macro avg     0.9984    0.9984    0.9984    145546
weighted avg     0.9984    0.9984    0.9984    145546

[[36395    14    29    14]
 [   14 36373    14    21]
 [   28    13 36398    23]
 [   24    20    24 36142]]
-------------------------------------------------------------------------------------
train_loss : 0.0709
eval_loss : 0.1154
acc : 0.9925, precision : 0.9789, recall : 0.9770, f1_score : 0.9780
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9623    0.9358    0.9489      9674
           1     0.9715    0.9835    0.9775     21515

    accuracy                         0.9687     31189
   macro avg     0.9669    0.9597    0.9632     31189
weighted avg     0.9686    0.9687    0.9686     31189

[[ 9053   621]
 [  355 21160]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9981    0.9983    0.9982      7745
           1     0.9982    0.9988    0.9985      7789
           2     0.9987    0.9982    0.9985      7869
           3     0.9988    0.9985    0.9987      7786

    accuracy                         0.9985     31189
   macro avg     0.9985    0.9985    0.9985     31189
weighted avg     0.9985    0.9985    0.9985     31189

[[7732    5    4    4]
 [   3 7780    4    2]
 [   8    3 7855    3]
 [   4    6    2 7774]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.70 mins
epoch : 26|30, iter : 200|1138,  loss : 0.0559
epoch : 26|30, iter : 400|1138,  loss : 0.0570
epoch : 26|30, iter : 600|1138,  loss : 0.0556
epoch : 26|30, iter : 800|1138,  loss : 0.0557
epoch : 26|30, iter : 1000|1138,  loss : 0.0567
acc : 0.9968, precision : 0.9920, recall : 0.9896, f1_score : 0.9908
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9743    0.9822    0.9782     45524
           1     0.9919    0.9882    0.9900    100022

    accuracy                         0.9863    145546
   macro avg     0.9831    0.9852    0.9841    145546
weighted avg     0.9864    0.9863    0.9863    145546

[[44713   811]
 [ 1181 98841]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9987    0.9985     36452
           1     0.9988    0.9987    0.9988     36422
           2     0.9985    0.9987    0.9986     36462
           3     0.9988    0.9984    0.9986     36210

    accuracy                         0.9986    145546
   macro avg     0.9986    0.9986    0.9986    145546
weighted avg     0.9986    0.9986    0.9986    145546

[[36404    12    21    15]
 [   17 36376    15    14]
 [   17    16 36413    16]
 [   24    16    19 36151]]
-------------------------------------------------------------------------------------
train_loss : 0.0576
eval_loss : 0.1082
acc : 0.9922, precision : 0.9756, recall : 0.9785, f1_score : 0.9771
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9530    0.9515    0.9523      9674
           1     0.9782    0.9789    0.9786     21515

    accuracy                         0.9704     31189
   macro avg     0.9656    0.9652    0.9654     31189
weighted avg     0.9704    0.9704    0.9704     31189

[[ 9205   469]
 [  454 21061]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9988    0.9974    0.9981      7745
           1     0.9974    0.9991    0.9983      7789
           2     0.9981    0.9980    0.9980      7869
           3     0.9988    0.9987    0.9988      7786

    accuracy                         0.9983     31189
   macro avg     0.9983    0.9983    0.9983     31189
weighted avg     0.9983    0.9983    0.9983     31189

[[7725    7    9    4]
 [   1 7782    4    2]
 [   6    7 7853    3]
 [   2    6    2 7776]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.62 mins
epoch : 27|30, iter : 200|1138,  loss : 0.0562
epoch : 27|30, iter : 400|1138,  loss : 0.0550
epoch : 27|30, iter : 600|1138,  loss : 0.0546
epoch : 27|30, iter : 800|1138,  loss : 0.0541
epoch : 27|30, iter : 1000|1138,  loss : 0.0537
acc : 0.9971, precision : 0.9928, recall : 0.9906, f1_score : 0.9917
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9762    0.9836    0.9799     45524
           1     0.9925    0.9891    0.9908    100022

    accuracy                         0.9874    145546
   macro avg     0.9844    0.9864    0.9854    145546
weighted avg     0.9874    0.9874    0.9874    145546

[[44779   745]
 [ 1092 98930]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9985    0.9986     36452
           1     0.9987    0.9988    0.9988     36422
           2     0.9984    0.9987    0.9985     36462
           3     0.9987    0.9985    0.9986     36210

    accuracy                         0.9986    145546
   macro avg     0.9986    0.9986    0.9986    145546
weighted avg     0.9986    0.9986    0.9986    145546

[[36399    16    22    15]
 [   15 36379    14    14]
 [   15    16 36413    18]
 [   20    15    21 36154]]
-------------------------------------------------------------------------------------
train_loss : 0.0544
eval_loss : 0.1080
acc : 0.9925, precision : 0.9820, recall : 0.9740, f1_score : 0.9780
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9495    0.9591    0.9543      9674
           1     0.9815    0.9771    0.9793     21515

    accuracy                         0.9715     31189
   macro avg     0.9655    0.9681    0.9668     31189
weighted avg     0.9716    0.9715    0.9715     31189

[[ 9278   396]
 [  493 21022]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9986    0.9986      7745
           1     0.9976    0.9991    0.9983      7789
           2     0.9991    0.9980    0.9985      7869
           3     0.9987    0.9983    0.9985      7786

    accuracy                         0.9985     31189
   macro avg     0.9985    0.9985    0.9985     31189
weighted avg     0.9985    0.9985    0.9985     31189

[[7734    5    1    5]
 [   1 7782    4    2]
 [   8    5 7853    3]
 [   2    9    2 7773]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.65 mins
epoch : 28|30, iter : 200|1138,  loss : 0.0481
epoch : 28|30, iter : 400|1138,  loss : 0.0474
epoch : 28|30, iter : 600|1138,  loss : 0.0489
epoch : 28|30, iter : 800|1138,  loss : 0.0506
epoch : 28|30, iter : 1000|1138,  loss : 0.0510
acc : 0.9973, precision : 0.9932, recall : 0.9910, f1_score : 0.9921
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9769    0.9842    0.9805     45524
           1     0.9928    0.9894    0.9911    100022

    accuracy                         0.9878    145546
   macro avg     0.9848    0.9868    0.9858    145546
weighted avg     0.9878    0.9878    0.9878    145546

[[44805   719]
 [ 1059 98963]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9984    0.9987    0.9986     36452
           1     0.9988    0.9988    0.9988     36422
           2     0.9985    0.9987    0.9986     36462
           3     0.9988    0.9983    0.9986     36210

    accuracy                         0.9986    145546
   macro avg     0.9986    0.9986    0.9986    145546
weighted avg     0.9986    0.9986    0.9986    145546

[[36405    12    21    14]
 [   14 36377    16    15]
 [   19    15 36415    13]
 [   25    16    19 36150]]
-------------------------------------------------------------------------------------
train_loss : 0.0519
eval_loss : 0.1103
acc : 0.9920, precision : 0.9814, recall : 0.9712, f1_score : 0.9763
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9445    0.9592    0.9518      9674
           1     0.9815    0.9747    0.9781     21515

    accuracy                         0.9699     31189
   macro avg     0.9630    0.9669    0.9649     31189
weighted avg     0.9700    0.9699    0.9699     31189

[[ 9279   395]
 [  545 20970]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9988    0.9972    0.9980      7745
           1     0.9986    0.9988    0.9987      7789
           2     0.9972    0.9983    0.9978      7869
           3     0.9987    0.9990    0.9988      7786

    accuracy                         0.9983     31189
   macro avg     0.9983    0.9983    0.9983     31189
weighted avg     0.9983    0.9983    0.9983     31189

[[7723    5   13    4]
 [   1 7780    6    2]
 [   6    3 7856    4]
 [   2    3    3 7778]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.56 mins
epoch : 29|30, iter : 200|1138,  loss : 0.0442
epoch : 29|30, iter : 400|1138,  loss : 0.0475
epoch : 29|30, iter : 600|1138,  loss : 0.0480
epoch : 29|30, iter : 800|1138,  loss : 0.0488
epoch : 29|30, iter : 1000|1138,  loss : 0.0493
acc : 0.9972, precision : 0.9927, recall : 0.9912, f1_score : 0.9919
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9780    0.9849    0.9814     45524
           1     0.9931    0.9899    0.9915    100022

    accuracy                         0.9883    145546
   macro avg     0.9856    0.9874    0.9865    145546
weighted avg     0.9884    0.9883    0.9884    145546

[[44837   687]
 [ 1009 99013]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9987    0.9987    0.9987     36452
           1     0.9987    0.9988    0.9988     36422
           2     0.9984    0.9986    0.9985     36462
           3     0.9987    0.9984    0.9986     36210

    accuracy                         0.9986    145546
   macro avg     0.9986    0.9986    0.9986    145546
weighted avg     0.9986    0.9986    0.9986    145546

[[36403    12    22    15]
 [   14 36378    16    14]
 [   15    18 36412    17]
 [   19    17    22 36152]]
-------------------------------------------------------------------------------------
train_loss : 0.0499
eval_loss : 0.1163
acc : 0.9922, precision : 0.9796, recall : 0.9748, f1_score : 0.9772
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9343    0.9657    0.9497      9674
           1     0.9843    0.9695    0.9768     21515

    accuracy                         0.9683     31189
   macro avg     0.9593    0.9676    0.9633     31189
weighted avg     0.9688    0.9683    0.9684     31189

[[ 9342   332]
 [  657 20858]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9985    0.9982    0.9983      7745
           1     0.9981    0.9990    0.9985      7789
           2     0.9985    0.9976    0.9980      7869
           3     0.9987    0.9990    0.9988      7786

    accuracy                         0.9984     31189
   macro avg     0.9984    0.9984    0.9984     31189
weighted avg     0.9984    0.9984    0.9984     31189

[[7731    5    5    4]
 [   1 7781    5    2]
 [   8    7 7850    4]
 [   3    3    2 7778]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.65 mins
epoch : 30|30, iter : 200|1138,  loss : 0.0488
epoch : 30|30, iter : 400|1138,  loss : 0.0494
epoch : 30|30, iter : 600|1138,  loss : 0.0505
epoch : 30|30, iter : 800|1138,  loss : 0.0497
epoch : 30|30, iter : 1000|1138,  loss : 0.0485
acc : 0.9973, precision : 0.9930, recall : 0.9916, f1_score : 0.9923
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9785    0.9853    0.9819     45524
           1     0.9933    0.9902    0.9917    100022

    accuracy                         0.9886    145546
   macro avg     0.9859    0.9877    0.9868    145546
weighted avg     0.9887    0.9886    0.9886    145546

[[44854   670]
 [  985 99037]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9988    0.9987     36452
           1     0.9989    0.9988    0.9989     36422
           2     0.9985    0.9988    0.9986     36462
           3     0.9989    0.9984    0.9986     36210

    accuracy                         0.9987    145546
   macro avg     0.9987    0.9987    0.9987    145546
weighted avg     0.9987    0.9987    0.9987    145546

[[36408    12    19    13]
 [   15 36380    15    12]
 [   14    14 36418    16]
 [   22    15    22 36151]]
-------------------------------------------------------------------------------------
train_loss : 0.0489
eval_loss : 0.1207
acc : 0.9919, precision : 0.9759, recall : 0.9765, f1_score : 0.9762
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9370    0.9626    0.9496      9674
           1     0.9830    0.9709    0.9769     21515

    accuracy                         0.9683     31189
   macro avg     0.9600    0.9667    0.9633     31189
weighted avg     0.9687    0.9683    0.9684     31189

[[ 9312   362]
 [  626 20889]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9986    0.9986    0.9986      7745
           1     0.9986    0.9991    0.9988      7789
           2     0.9989    0.9983    0.9986      7869
           3     0.9988    0.9988    0.9988      7786

    accuracy                         0.9987     31189
   macro avg     0.9987    0.9987    0.9987     31189
weighted avg     0.9987    0.9987    0.9987     31189

[[7734    5    2    4]
 [   1 7782    4    2]
 [   7    3 7856    3]
 [   3    3    3 7777]]
-------------------------------------------------------------------------------------
Single epoch cost time : 6.59 mins
