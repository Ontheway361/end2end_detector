----------------Environment Versions----------------
- Python: 3.7.3 
- PyTorch: 1.1.0
- TorchVison: 0.3.0
- device: True
----------------------------------------------------
Parallel mode was going ...
Model loading was finished ...
After data augmentation, 18226 rows added.
After data augmentation,   0 rows added.
Data loading was finished ...
epoch :  1|21, iter : 200|711,  loss : 0.9899
epoch :  1|21, iter : 400|711,  loss : 0.6863
epoch :  1|21, iter : 600|711,  loss : 0.5452
acc : 0.9176, precision : 0.8088, recall : 0.9201, f1_score : 0.8609
train_loss : 0.4941
eval_loss : 0.2598
acc : 0.9835, precision : 0.9337, recall : 0.9720, f1_score : 0.9524
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8789    0.8940    0.8864      9674
           1     0.9520    0.9446    0.9483     21515

    accuracy                         0.9289     31189
   macro avg     0.9154    0.9193    0.9173     31189
weighted avg     0.9293    0.9289    0.9291     31189

[[ 8649  1025]
 [ 1192 20323]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9921    0.9921    0.9921      7745
           1     0.9983    0.9571    0.9773      7789
           2     0.9755    0.9980    0.9866      7869
           3     0.9780    0.9956    0.9868      7786

    accuracy                         0.9857     31189
   macro avg     0.9860    0.9857    0.9857     31189
weighted avg     0.9860    0.9857    0.9857     31189

[[7684    5   43   13]
 [  48 7455  129  157]
 [   9    3 7853    4]
 [   4    5   25 7752]]
-------------------------------------------------------------------------------------
Single epoch cost time : 13.92 mins
****************ota | loss : 0.2598 | f1_score : 0.9524****************
epoch :  2|21, iter : 200|711,  loss : 0.1909
epoch :  2|21, iter : 400|711,  loss : 0.1856
epoch :  2|21, iter : 600|711,  loss : 0.1803
acc : 0.9818, precision : 0.9672, recall : 0.9673, f1_score : 0.9672
train_loss : 0.1791
eval_loss : 0.2457
acc : 0.9853, precision : 0.9751, recall : 0.9373, f1_score : 0.9559
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8230    0.9807    0.8950      9674
           1     0.9905    0.9052    0.9459     21515

    accuracy                         0.9286     31189
   macro avg     0.9068    0.9429    0.9204     31189
weighted avg     0.9385    0.9286    0.9301     31189

[[ 9487   187]
 [ 2040 19475]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9772    0.9965    0.9868      7745
           1     0.9978    0.9828    0.9902      7789
           2     0.9888    0.9910    0.9899      7869
           3     0.9960    0.9892    0.9926      7786

    accuracy                         0.9899     31189
   macro avg     0.9900    0.9899    0.9899     31189
weighted avg     0.9900    0.9899    0.9899     31189

[[7718    5   18    4]
 [  75 7655   35   24]
 [  64    4 7798    3]
 [  41    8   35 7702]]
-------------------------------------------------------------------------------------
Single epoch cost time : 12.73 mins
****************ota | loss : 0.2457 | f1_score : 0.9559****************
epoch :  3|21, iter : 200|711,  loss : 0.1621
epoch :  3|21, iter : 400|711,  loss : 0.1571
epoch :  3|21, iter : 600|711,  loss : 0.1548
acc : 0.9845, precision : 0.9719, recall : 0.9720, f1_score : 0.9720
train_loss : 0.1544
eval_loss : 0.2609
acc : 0.9819, precision : 0.9139, recall : 0.9868, f1_score : 0.9490
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9734    0.7936    0.8743      9674
           1     0.9143    0.9902    0.9508     21515

    accuracy                         0.9292     31189
   macro avg     0.9438    0.8919    0.9125     31189
weighted avg     0.9326    0.9292    0.9270     31189

[[ 7677  1997]
 [  210 21305]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9825    0.9982    0.9903      7745
           1     0.9983    0.9755    0.9868      7789
           2     0.9986    0.9834    0.9909      7869
           3     0.9769    0.9987    0.9877      7786

    accuracy                         0.9889     31189
   macro avg     0.9891    0.9889    0.9889     31189
weighted avg     0.9891    0.9889    0.9889     31189

[[7731    5    1    8]
 [  44 7598    8  139]
 [  89    5 7738   37]
 [   5    3    2 7776]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.23 mins
epoch :  4|21, iter : 200|711,  loss : 0.1373
epoch :  4|21, iter : 400|711,  loss : 0.1412
epoch :  4|21, iter : 600|711,  loss : 0.1443
acc : 0.9862, precision : 0.9749, recall : 0.9753, f1_score : 0.9751
train_loss : 0.1442
eval_loss : 0.1511
acc : 0.9876, precision : 0.9893, recall : 0.9371, f1_score : 0.9625
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9056    0.9636    0.9337      9674
           1     0.9832    0.9548    0.9688     21515

    accuracy                         0.9575     31189
   macro avg     0.9444    0.9592    0.9512     31189
weighted avg     0.9591    0.9575    0.9579     31189

[[ 9322   352]
 [  972 20543]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9982    0.9933    0.9957      7745
           1     0.9911    0.9982    0.9946      7789
           2     0.9913    0.9977    0.9945      7869
           3     0.9978    0.9890    0.9934      7786

    accuracy                         0.9945     31189
   macro avg     0.9946    0.9945    0.9946     31189
weighted avg     0.9946    0.9945    0.9945     31189

[[7693    7   37    8]
 [   4 7775    7    3]
 [   8    4 7851    6]
 [   2   59   25 7700]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.08 mins
****************ota | loss : 0.1511 | f1_score : 0.9625****************
epoch :  5|21, iter : 200|711,  loss : 0.1380
epoch :  5|21, iter : 400|711,  loss : 0.1362
epoch :  5|21, iter : 600|711,  loss : 0.1363
acc : 0.9863, precision : 0.9758, recall : 0.9749, f1_score : 0.9753
train_loss : 0.1356
eval_loss : 0.1635
acc : 0.9862, precision : 0.9422, recall : 0.9789, f1_score : 0.9602
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8982    0.9517    0.9242      9674
           1     0.9777    0.9515    0.9644     21515

    accuracy                         0.9516     31189
   macro avg     0.9379    0.9516    0.9443     31189
weighted avg     0.9530    0.9516    0.9519     31189

[[ 9207   467]
 [ 1044 20471]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9866    0.9981    0.9923      7745
           1     0.9978    0.9938    0.9958      7789
           2     0.9978    0.9966    0.9972      7869
           3     0.9966    0.9904    0.9935      7786

    accuracy                         0.9947     31189
   macro avg     0.9947    0.9947    0.9947     31189
weighted avg     0.9947    0.9947    0.9947     31189

[[7730    5    6    4]
 [  23 7741    7   18]
 [  19    4 7842    4]
 [  63    8    4 7711]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.06 mins
epoch :  6|21, iter : 200|711,  loss : 0.1247
epoch :  6|21, iter : 400|711,  loss : 0.1273
epoch :  6|21, iter : 600|711,  loss : 0.1289
acc : 0.9867, precision : 0.9758, recall : 0.9761, f1_score : 0.9759
train_loss : 0.1301
eval_loss : 0.1609
acc : 0.9891, precision : 0.9869, recall : 0.9488, f1_score : 0.9675
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9108    0.9455    0.9278      9674
           1     0.9751    0.9584    0.9666     21515

    accuracy                         0.9544     31189
   macro avg     0.9429    0.9519    0.9472     31189
weighted avg     0.9551    0.9544    0.9546     31189

[[ 9147   527]
 [  896 20619]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9955    0.9978    0.9966      7745
           1     0.9974    0.9827    0.9900      7789
           2     0.9841    0.9962    0.9901      7869
           3     0.9951    0.9951    0.9951      7786

    accuracy                         0.9929     31189
   macro avg     0.9930    0.9929    0.9930     31189
weighted avg     0.9930    0.9929    0.9929     31189

[[7728    5    7    5]
 [   8 7654   98   29]
 [  23    3 7839    4]
 [   4   12   22 7748]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.06 mins
epoch :  7|21, iter : 200|711,  loss : 0.1229
epoch :  7|21, iter : 400|711,  loss : 0.1269
epoch :  7|21, iter : 600|711,  loss : 0.1241
acc : 0.9881, precision : 0.9788, recall : 0.9783, f1_score : 0.9786
train_loss : 0.1220
eval_loss : 0.1704
acc : 0.9851, precision : 0.9850, recall : 0.9264, f1_score : 0.9548
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.8995    0.9523    0.9252      9674
           1     0.9780    0.9522    0.9649     21515

    accuracy                         0.9522     31189
   macro avg     0.9388    0.9523    0.9450     31189
weighted avg     0.9537    0.9522    0.9526     31189

[[ 9213   461]
 [ 1029 20486]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9847    0.9979    0.9913      7745
           1     0.9974    0.9904    0.9939      7789
           2     0.9943    0.9919    0.9931      7869
           3     0.9965    0.9927    0.9946      7786

    accuracy                         0.9932     31189
   macro avg     0.9932    0.9932    0.9932     31189
weighted avg     0.9932    0.9932    0.9932     31189

[[7729    5    7    4]
 [  36 7714   21   18]
 [  55    4 7805    5]
 [  29   11   17 7729]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.06 mins
