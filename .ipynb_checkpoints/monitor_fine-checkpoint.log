----------------Environment Versions----------------
- Python: 3.7.3 
- PyTorch: 1.1.0
- TorchVison: 0.3.0
- device: True
----------------------------------------------------
Parallel mode was going ...
Resuming the train process at  13 epoches ...
Model loading was finished ...
After data augmentation, 18226 rows added.
After data augmentation,   0 rows added.
Data loading was finished ...
epoch : 13|21, iter : 200|711,  loss : 0.1116
epoch : 13|21, iter : 400|711,  loss : 0.1186
epoch : 13|21, iter : 600|711,  loss : 0.1203
acc : 0.9897, precision : 0.9817, recall : 0.9810, f1_score : 0.9813
train_loss : 0.1205
eval_loss : 0.1454
acc : 0.9907, precision : 0.9758, recall : 0.9695, f1_score : 0.9726
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9362    0.9476    0.9418      9674
           1     0.9763    0.9710    0.9736     21515

    accuracy                         0.9637     31189
   macro avg     0.9562    0.9593    0.9577     31189
weighted avg     0.9639    0.9637    0.9638     31189

[[ 9167   507]
 [  625 20890]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9977    0.9974    0.9975      7745
           1     0.9973    0.9974    0.9974      7789
           2     0.9977    0.9972    0.9975      7869
           3     0.9974    0.9981    0.9978      7786

    accuracy                         0.9975     31189
   macro avg     0.9975    0.9975    0.9975     31189
weighted avg     0.9975    0.9975    0.9975     31189

[[7725    5   10    5]
 [   4 7769    5   11]
 [  12    6 7847    4]
 [   2   10    3 7771]]
-------------------------------------------------------------------------------------
Single epoch cost time : 13.56 mins
****************sota | loss : 0.1454 | f1_score : 0.9726****************
epoch : 14|21, iter : 200|711,  loss : 0.1160
epoch : 14|21, iter : 400|711,  loss : 0.1166
epoch : 14|21, iter : 600|711,  loss : 0.1186
acc : 0.9900, precision : 0.9821, recall : 0.9819, f1_score : 0.9820
train_loss : 0.1183
eval_loss : 0.1459
acc : 0.9909, precision : 0.9833, recall : 0.9629, f1_score : 0.9730
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9215    0.9630    0.9418      9674
           1     0.9830    0.9631    0.9730     21515

    accuracy                         0.9631     31189
   macro avg     0.9522    0.9630    0.9574     31189
weighted avg     0.9639    0.9631    0.9633     31189

[[ 9316   358]
 [  794 20721]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9977    0.9972    0.9974      7745
           1     0.9979    0.9958    0.9969      7789
           2     0.9981    0.9973    0.9977      7869
           3     0.9954    0.9988    0.9971      7786

    accuracy                         0.9973     31189
   macro avg     0.9973    0.9973    0.9973     31189
weighted avg     0.9973    0.9973    0.9973     31189

[[7723    7    5   10]
 [   5 7756    7   21]
 [  11    5 7848    5]
 [   2    4    3 7777]]
-------------------------------------------------------------------------------------
Single epoch cost time : 38.86 mins
epoch : 15|21, iter : 200|711,  loss : 0.1063
epoch : 15|21, iter : 400|711,  loss : 0.1084
epoch : 15|21, iter : 600|711,  loss : 0.1102
acc : 0.9906, precision : 0.9833, recall : 0.9827, f1_score : 0.9830
train_loss : 0.1122
eval_loss : 0.1595
acc : 0.9903, precision : 0.9665, recall : 0.9769, f1_score : 0.9716
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9500    0.9171    0.9333      9674
           1     0.9633    0.9783    0.9707     21515

    accuracy                         0.9593     31189
   macro avg     0.9566    0.9477    0.9520     31189
weighted avg     0.9592    0.9593    0.9591     31189

[[ 8872   802]
 [  467 21048]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9981    0.9948    0.9964      7745
           1     0.9962    0.9969    0.9965      7789
           2     0.9990    0.9949    0.9969      7869
           3     0.9923    0.9988    0.9956      7786

    accuracy                         0.9964     31189
   macro avg     0.9964    0.9964    0.9964     31189
weighted avg     0.9964    0.9964    0.9964     31189

[[7705   16    3   21]
 [   1 7765    3   20]
 [  12    9 7829   19]
 [   2    5    2 7777]]
-------------------------------------------------------------------------------------
Single epoch cost time : 27.62 mins
epoch : 16|21, iter : 200|711,  loss : 0.1021
epoch : 16|21, iter : 400|711,  loss : 0.1056
epoch : 16|21, iter : 600|711,  loss : 0.1090
acc : 0.9904, precision : 0.9830, recall : 0.9823, f1_score : 0.9826
train_loss : 0.1110
eval_loss : 0.1378
acc : 0.9914, precision : 0.9653, recall : 0.9849, f1_score : 0.9750
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9604    0.9246    0.9422      9674
           1     0.9667    0.9828    0.9747     21515

    accuracy                         0.9648     31189
   macro avg     0.9635    0.9537    0.9584     31189
weighted avg     0.9647    0.9648    0.9646     31189

[[ 8945   729]
 [  369 21146]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9977    0.9975    0.9976      7745
           1     0.9976    0.9981    0.9978      7789
           2     0.9985    0.9967    0.9976      7869
           3     0.9969    0.9983    0.9976      7786

    accuracy                         0.9977     31189
   macro avg     0.9977    0.9977    0.9977     31189
weighted avg     0.9977    0.9977    0.9977     31189

[[7726    6    6    7]
 [   2 7774    4    9]
 [  14    4 7843    8]
 [   2    9    2 7773]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.81 mins
****************sota | loss : 0.1378 | f1_score : 0.9750****************
epoch : 17|21, iter : 200|711,  loss : 0.1055
epoch : 17|21, iter : 400|711,  loss : 0.1063
epoch : 17|21, iter : 600|711,  loss : 0.1071
acc : 0.9912, precision : 0.9846, recall : 0.9836, f1_score : 0.9841
train_loss : 0.1081
eval_loss : 0.1461
acc : 0.9916, precision : 0.9892, recall : 0.9610, f1_score : 0.9749
------------------------------------ gt vs. pred ------------------------------------
              precision    recall  f1-score   support

           0     0.9144    0.9764    0.9444      9674
           1     0.9891    0.9589    0.9738     21515

    accuracy                         0.9643     31189
   macro avg     0.9517    0.9677    0.9591     31189
weighted avg     0.9659    0.9643    0.9647     31189

[[ 9446   228]
 [  884 20631]]
-------------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0     0.9979    0.9979    0.9979      7745
           1     0.9981    0.9981    0.9981      7789
           2     0.9985    0.9978    0.9982      7869
           3     0.9977    0.9983    0.9980      7786

    accuracy                         0.9980     31189
   macro avg     0.9980    0.9980    0.9980     31189
weighted avg     0.9980    0.9980    0.9980     31189

[[7729    5    6    5]
 [   4 7774    3    8]
 [   9    3 7852    5]
 [   3    7    3 7773]]
-------------------------------------------------------------------------------------
Single epoch cost time : 4.38 mins
epoch : 18|21, iter : 200|711,  loss : 0.1027
